[0m12:15:13.916047 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104d18710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104d194d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104d9aa50>]}


============================== 12:15:13.919737 | 503210c9-8edb-4835-8791-7be6743cfc93 ==============================
[0m12:15:13.919737 [info ] [MainThread]: Running with dbt=1.9.2
[0m12:15:13.920095 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/juliusrechenbach/API ProHandelTest/dbt_mercurios', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt debug', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:15:13.931377 [info ] [MainThread]: dbt version: 1.9.2
[0m12:15:13.931673 [info ] [MainThread]: python version: 3.11.1
[0m12:15:13.931859 [info ] [MainThread]: python path: /Users/juliusrechenbach/API ProHandelTest/.venv/bin/python
[0m12:15:13.932058 [info ] [MainThread]: os info: macOS-15.3.1-arm64-arm-64bit
[0m12:15:14.694731 [info ] [MainThread]: Using profiles dir at /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios
[0m12:15:14.695050 [info ] [MainThread]: Using profiles.yml file at /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/profiles.yml
[0m12:15:14.695203 [info ] [MainThread]: Using dbt_project.yml file at /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/dbt_project.yml
[0m12:15:14.695749 [info ] [MainThread]: adapter type: snowflake
[0m12:15:14.696027 [info ] [MainThread]: adapter version: 1.9.1
[0m12:15:14.783831 [info ] [MainThread]: Configuration:
[0m12:15:14.784162 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m12:15:14.784316 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m12:15:14.784456 [info ] [MainThread]: Required dependencies:
[0m12:15:14.784655 [debug] [MainThread]: Executing "git --help"
[0m12:15:14.800449 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m12:15:14.801126 [debug] [MainThread]: STDERR: "b''"
[0m12:15:14.801351 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m12:15:14.801641 [info ] [MainThread]: Connection:
[0m12:15:14.801935 [info ] [MainThread]:   account: VRXDFZX-ZZ95717
[0m12:15:14.802152 [info ] [MainThread]:   user: JULIUSRECHENBACH
[0m12:15:14.802298 [info ] [MainThread]:   database: MERCURIOS_DATA
[0m12:15:14.802443 [info ] [MainThread]:   warehouse: MERCURIOS_DEV_WH
[0m12:15:14.802581 [info ] [MainThread]:   role: MERCURIOS_DEVELOPER
[0m12:15:14.802717 [info ] [MainThread]:   schema: staging
[0m12:15:14.802853 [info ] [MainThread]:   authenticator: None
[0m12:15:14.802992 [info ] [MainThread]:   oauth_client_id: None
[0m12:15:14.803124 [info ] [MainThread]:   query_tag: dbt_mercurios_dev
[0m12:15:14.803260 [info ] [MainThread]:   client_session_keep_alive: True
[0m12:15:14.803398 [info ] [MainThread]:   host: None
[0m12:15:14.803529 [info ] [MainThread]:   port: None
[0m12:15:14.803661 [info ] [MainThread]:   proxy_host: None
[0m12:15:14.803798 [info ] [MainThread]:   proxy_port: None
[0m12:15:14.803928 [info ] [MainThread]:   protocol: None
[0m12:15:14.804059 [info ] [MainThread]:   connect_retries: 1
[0m12:15:14.804181 [info ] [MainThread]:   connect_timeout: None
[0m12:15:14.804305 [info ] [MainThread]:   retry_on_database_errors: False
[0m12:15:14.804429 [info ] [MainThread]:   retry_all: False
[0m12:15:14.804555 [info ] [MainThread]:   insecure_mode: False
[0m12:15:14.804679 [info ] [MainThread]:   reuse_connections: None
[0m12:15:14.805002 [info ] [MainThread]: Registered adapter: snowflake=1.9.1
[0m12:15:14.909049 [debug] [MainThread]: Acquiring new snowflake connection 'debug'
[0m12:15:14.939704 [debug] [MainThread]: Using snowflake connection "debug"
[0m12:15:14.940010 [debug] [MainThread]: On debug: select 1 as id
[0m12:15:14.940179 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:15:15.349457 [debug] [MainThread]: Snowflake adapter: Error running SQL: select 1 as id
[0m12:15:15.349947 [debug] [MainThread]: Snowflake adapter: Rolling back transaction.
[0m12:15:15.350799 [debug] [MainThread]: On debug: No close available on handle
[0m12:15:15.351882 [info ] [MainThread]:   Connection test: [[31mERROR[0m]

[0m12:15:15.353277 [info ] [MainThread]: [31m1 check failed:[0m
[0m12:15:15.353868 [info ] [MainThread]: dbt was unable to connect to the specified database.
The database returned the following error:

  >Database Error
  250001 (08001): Failed to connect to DB: VRXDFZX-ZZ95717.snowflakecomputing.com:443. Incorrect username or password was specified.

Check your database credentials and try again. For more information, visit:
https://docs.getdbt.com/docs/configure-your-profile


[0m12:15:15.394304 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 1.5304565, "process_in_blocks": "0", "process_kernel_time": 1.40047, "process_mem_max_rss": "182403072", "process_out_blocks": "0", "process_user_time": 2.038114}
[0m12:15:15.395366 [debug] [MainThread]: Command `dbt debug` failed at 12:15:15.395056 after 1.53 seconds
[0m12:15:15.397772 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m12:15:15.399128 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1292a4f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102d88a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1008f9cd0>]}
[0m12:15:15.401160 [debug] [MainThread]: Flushing usage events
[0m12:15:15.969471 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:15:28.547526 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10674c550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10674c150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10676aed0>]}


============================== 12:15:28.550553 | f9726f73-f7ef-4e51-b523-33c0ca07196d ==============================
[0m12:15:28.550553 [info ] [MainThread]: Running with dbt=1.9.2
[0m12:15:28.550927 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/juliusrechenbach/API ProHandelTest/dbt_mercurios', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m12:15:29.123759 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f9726f73-f7ef-4e51-b523-33c0ca07196d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1066f6910>]}
[0m12:15:29.159781 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f9726f73-f7ef-4e51-b523-33c0ca07196d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10672d910>]}
[0m12:15:29.160554 [info ] [MainThread]: Registered adapter: snowflake=1.9.1
[0m12:15:29.242084 [debug] [MainThread]: checksum: 12b12750b70de726cfd89136b8e24afc3f3e77597a97bff40ab7e5f9b39d5e18, vars: {}, profile: , target: , version: 1.9.2
[0m12:15:29.242572 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m12:15:29.242790 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'f9726f73-f7ef-4e51-b523-33c0ca07196d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e263090>]}
[0m12:15:30.054487 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.mercurios.marts.sales
[0m12:15:30.061154 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f9726f73-f7ef-4e51-b523-33c0ca07196d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fe93b50>]}
[0m12:15:30.108601 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/target/manifest.json
[0m12:15:30.110922 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/target/semantic_manifest.json
[0m12:15:30.123513 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f9726f73-f7ef-4e51-b523-33c0ca07196d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12e088f10>]}
[0m12:15:30.123845 [info ] [MainThread]: Found 9 models, 40 data tests, 9 sources, 472 macros
[0m12:15:30.124049 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f9726f73-f7ef-4e51-b523-33c0ca07196d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fe8fc50>]}
[0m12:15:30.125393 [info ] [MainThread]: 
[0m12:15:30.125587 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:15:30.125736 [info ] [MainThread]: 
[0m12:15:30.125986 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m12:15:30.128371 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_MERCURIOS_DATA'
[0m12:15:30.128660 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_MERCURIOS_DATA'
[0m12:15:30.135064 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_MERCURIOS_DATA'
[0m12:15:30.163575 [debug] [ThreadPool]: Using snowflake connection "list_MERCURIOS_DATA"
[0m12:15:30.163888 [debug] [ThreadPool]: Using snowflake connection "list_MERCURIOS_DATA"
[0m12:15:30.164166 [debug] [ThreadPool]: Using snowflake connection "list_MERCURIOS_DATA"
[0m12:15:30.164340 [debug] [ThreadPool]: On list_MERCURIOS_DATA: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "list_MERCURIOS_DATA"} */
show terse schemas in database MERCURIOS_DATA
    limit 10000
[0m12:15:30.164517 [debug] [ThreadPool]: On list_MERCURIOS_DATA: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "list_MERCURIOS_DATA"} */
show terse schemas in database MERCURIOS_DATA
    limit 10000
[0m12:15:30.164695 [debug] [ThreadPool]: On list_MERCURIOS_DATA: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "list_MERCURIOS_DATA"} */
show terse schemas in database MERCURIOS_DATA
    limit 10000
[0m12:15:30.164857 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:15:30.165010 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:15:30.165158 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:15:38.647433 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 8.482 seconds
[0m12:15:38.652050 [debug] [ThreadPool]: On list_MERCURIOS_DATA: Close
[0m12:15:42.213200 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 12.048 seconds
[0m12:15:42.214159 [debug] [ThreadPool]: On list_MERCURIOS_DATA: Close
[0m12:15:45.606677 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 15.442 seconds
[0m12:15:45.607881 [debug] [ThreadPool]: On list_MERCURIOS_DATA: Close
[0m12:15:45.793838 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_MERCURIOS_DATA, now create_MERCURIOS_DATA_staging_intermediate)
[0m12:15:45.794160 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_MERCURIOS_DATA, now create_MERCURIOS_DATA_staging_staging)
[0m12:15:45.794388 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_MERCURIOS_DATA, now create_MERCURIOS_DATA_staging_marts_inventory)
[0m12:15:45.795405 [debug] [ThreadPool]: Creating schema "database: "MERCURIOS_DATA"
schema: "staging_intermediate"
"
[0m12:15:45.795656 [debug] [ThreadPool]: Creating schema "database: "MERCURIOS_DATA"
schema: "staging_staging"
"
[0m12:15:45.795882 [debug] [ThreadPool]: Creating schema "database: "MERCURIOS_DATA"
schema: "staging_marts_inventory"
"
[0m12:15:45.798803 [debug] [ThreadPool]: Using snowflake connection "create_MERCURIOS_DATA_staging_intermediate"
[0m12:15:45.800046 [debug] [ThreadPool]: Using snowflake connection "create_MERCURIOS_DATA_staging_staging"
[0m12:15:45.801216 [debug] [ThreadPool]: Using snowflake connection "create_MERCURIOS_DATA_staging_marts_inventory"
[0m12:15:45.801413 [debug] [ThreadPool]: On create_MERCURIOS_DATA_staging_intermediate: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "create_MERCURIOS_DATA_staging_intermediate"} */
create schema if not exists MERCURIOS_DATA.staging_intermediate
[0m12:15:45.801593 [debug] [ThreadPool]: On create_MERCURIOS_DATA_staging_staging: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "create_MERCURIOS_DATA_staging_staging"} */
create schema if not exists MERCURIOS_DATA.staging_staging
[0m12:15:45.801759 [debug] [ThreadPool]: On create_MERCURIOS_DATA_staging_marts_inventory: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "create_MERCURIOS_DATA_staging_marts_inventory"} */
create schema if not exists MERCURIOS_DATA.staging_marts_inventory
[0m12:15:45.801930 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:15:45.802073 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:15:45.802228 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:15:49.625037 [debug] [ThreadPool]: Snowflake adapter: Snowflake query id: 01baef63-0204-28bf-0003-4bde0007170e
[0m12:15:49.625510 [debug] [ThreadPool]: Snowflake adapter: Snowflake error: 003001 (42501): SQL access control error:
Insufficient privileges to operate on database 'MERCURIOS_DATA'
[0m12:15:49.625793 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro create_schema
[0m12:15:49.625970 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
[0m12:15:49.626166 [debug] [ThreadPool]: On create_MERCURIOS_DATA_staging_intermediate: Close
[0m12:15:53.451596 [debug] [ThreadPool]: Snowflake adapter: Snowflake query id: 01baef63-0204-2b29-0003-4bde00066cae
[0m12:15:53.452662 [debug] [ThreadPool]: Snowflake adapter: Snowflake error: 003001 (42501): SQL access control error:
Insufficient privileges to operate on database 'MERCURIOS_DATA'
[0m12:15:53.453520 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro create_schema
[0m12:15:53.454078 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
[0m12:15:53.454550 [debug] [ThreadPool]: On create_MERCURIOS_DATA_staging_marts_inventory: Close
[0m12:15:56.667657 [debug] [ThreadPool]: Snowflake adapter: Snowflake query id: 01baef63-0204-2b31-0003-4bde00065cd2
[0m12:15:56.667934 [debug] [ThreadPool]: Snowflake adapter: Snowflake error: 003001 (42501): SQL access control error:
Insufficient privileges to operate on database 'MERCURIOS_DATA'
[0m12:15:56.668207 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro create_schema
[0m12:15:56.668413 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
[0m12:15:56.668580 [debug] [ThreadPool]: On create_MERCURIOS_DATA_staging_staging: Close
[0m12:15:56.770644 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:15:56.771017 [debug] [MainThread]: Connection 'create_MERCURIOS_DATA_staging_marts_inventory' was properly closed.
[0m12:15:56.771281 [debug] [MainThread]: Connection 'create_MERCURIOS_DATA_staging_intermediate' was properly closed.
[0m12:15:56.771520 [debug] [MainThread]: Connection 'create_MERCURIOS_DATA_staging_staging' was properly closed.
[0m12:15:56.771724 [info ] [MainThread]: 
[0m12:15:56.771958 [info ] [MainThread]: Finished running  in 0 hours 0 minutes and 26.65 seconds (26.65s).
[0m12:15:56.772357 [error] [MainThread]: Encountered an error:
Database Error
  003001 (42501): SQL access control error:
  Insufficient privileges to operate on database 'MERCURIOS_DATA'
[0m12:15:56.775433 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 28.2705, "process_in_blocks": "0", "process_kernel_time": 1.811794, "process_mem_max_rss": "200245248", "process_out_blocks": "0", "process_user_time": 3.003742}
[0m12:15:56.775752 [debug] [MainThread]: Command `dbt run` failed at 12:15:56.775695 after 28.27 seconds
[0m12:15:56.776008 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x13855e890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x13854fed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x100e3dbd0>]}
[0m12:15:56.776347 [debug] [MainThread]: Flushing usage events
[0m12:15:57.286900 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:25:10.318429 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1099de1d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109a4ce50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109a4d7d0>]}


============================== 12:25:10.321787 | 1e683ce2-46d5-4eb5-affd-934541b8cda3 ==============================
[0m12:25:10.321787 [info ] [MainThread]: Running with dbt=1.9.2
[0m12:25:10.322135 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/juliusrechenbach/API ProHandelTest/dbt_mercurios', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m12:25:11.330522 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1e683ce2-46d5-4eb5-affd-934541b8cda3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119895550>]}
[0m12:25:11.366153 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1e683ce2-46d5-4eb5-affd-934541b8cda3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1089e6790>]}
[0m12:25:11.366969 [info ] [MainThread]: Registered adapter: snowflake=1.9.1
[0m12:25:11.477049 [debug] [MainThread]: checksum: 12b12750b70de726cfd89136b8e24afc3f3e77597a97bff40ab7e5f9b39d5e18, vars: {}, profile: , target: , version: 1.9.2
[0m12:25:11.553978 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m12:25:11.554275 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m12:25:11.557310 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.mercurios.marts.sales
[0m12:25:11.579424 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1e683ce2-46d5-4eb5-affd-934541b8cda3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11986bcd0>]}
[0m12:25:11.630624 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/target/manifest.json
[0m12:25:11.633444 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/target/semantic_manifest.json
[0m12:25:11.648263 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1e683ce2-46d5-4eb5-affd-934541b8cda3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119dee710>]}
[0m12:25:11.648662 [info ] [MainThread]: Found 9 models, 40 data tests, 9 sources, 472 macros
[0m12:25:11.648863 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1e683ce2-46d5-4eb5-affd-934541b8cda3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119b3ff50>]}
[0m12:25:11.650293 [info ] [MainThread]: 
[0m12:25:11.650527 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:25:11.650680 [info ] [MainThread]: 
[0m12:25:11.650975 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m12:25:11.653558 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_MERCURIOS_DATA'
[0m12:25:11.653915 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_MERCURIOS_DATA'
[0m12:25:11.654395 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_MERCURIOS_DATA'
[0m12:25:11.745394 [debug] [ThreadPool]: Using snowflake connection "list_MERCURIOS_DATA"
[0m12:25:11.745935 [debug] [ThreadPool]: Using snowflake connection "list_MERCURIOS_DATA"
[0m12:25:11.746249 [debug] [ThreadPool]: Using snowflake connection "list_MERCURIOS_DATA"
[0m12:25:11.746442 [debug] [ThreadPool]: On list_MERCURIOS_DATA: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "list_MERCURIOS_DATA"} */
show terse schemas in database MERCURIOS_DATA
    limit 10000
[0m12:25:11.746662 [debug] [ThreadPool]: On list_MERCURIOS_DATA: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "list_MERCURIOS_DATA"} */
show terse schemas in database MERCURIOS_DATA
    limit 10000
[0m12:25:11.746843 [debug] [ThreadPool]: On list_MERCURIOS_DATA: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "list_MERCURIOS_DATA"} */
show terse schemas in database MERCURIOS_DATA
    limit 10000
[0m12:25:11.747009 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:25:11.747159 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:25:11.747306 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:25:14.789194 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 3.042 seconds
[0m12:25:14.790377 [debug] [ThreadPool]: On list_MERCURIOS_DATA: Close
[0m12:25:25.947432 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 14.200 seconds
[0m12:25:25.949661 [debug] [ThreadPool]: On list_MERCURIOS_DATA: Close
[0m12:25:30.854214 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 19.107 seconds
[0m12:25:30.855410 [debug] [ThreadPool]: On list_MERCURIOS_DATA: Close
[0m12:25:30.967792 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_MERCURIOS_DATA, now create_MERCURIOS_DATA_staging_intermediate)
[0m12:25:30.968290 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_MERCURIOS_DATA, now create_MERCURIOS_DATA_staging_staging)
[0m12:25:30.968672 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_MERCURIOS_DATA, now create_MERCURIOS_DATA_staging_marts_inventory)
[0m12:25:30.969432 [debug] [ThreadPool]: Creating schema "database: "MERCURIOS_DATA"
schema: "staging_intermediate"
"
[0m12:25:30.969802 [debug] [ThreadPool]: Creating schema "database: "MERCURIOS_DATA"
schema: "staging_staging"
"
[0m12:25:30.970164 [debug] [ThreadPool]: Creating schema "database: "MERCURIOS_DATA"
schema: "staging_marts_inventory"
"
[0m12:25:30.975288 [debug] [ThreadPool]: Using snowflake connection "create_MERCURIOS_DATA_staging_intermediate"
[0m12:25:30.977448 [debug] [ThreadPool]: Using snowflake connection "create_MERCURIOS_DATA_staging_staging"
[0m12:25:30.980818 [debug] [ThreadPool]: Using snowflake connection "create_MERCURIOS_DATA_staging_marts_inventory"
[0m12:25:30.981258 [debug] [ThreadPool]: On create_MERCURIOS_DATA_staging_intermediate: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "create_MERCURIOS_DATA_staging_intermediate"} */
create schema if not exists MERCURIOS_DATA.staging_intermediate
[0m12:25:30.981703 [debug] [ThreadPool]: On create_MERCURIOS_DATA_staging_staging: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "create_MERCURIOS_DATA_staging_staging"} */
create schema if not exists MERCURIOS_DATA.staging_staging
[0m12:25:30.982069 [debug] [ThreadPool]: On create_MERCURIOS_DATA_staging_marts_inventory: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "create_MERCURIOS_DATA_staging_marts_inventory"} */
create schema if not exists MERCURIOS_DATA.staging_marts_inventory
[0m12:25:30.982327 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:25:30.982579 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:25:30.982800 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:25:38.186029 [debug] [ThreadPool]: Snowflake adapter: Snowflake query id: 01baef6d-0204-2b29-0003-4bde00066cf2
[0m12:25:38.190639 [debug] [ThreadPool]: Snowflake adapter: Snowflake error: 003001 (42501): SQL access control error:
Insufficient privileges to operate on database 'MERCURIOS_DATA'
[0m12:25:38.191558 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro create_schema
[0m12:25:38.191891 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
[0m12:25:38.192357 [debug] [ThreadPool]: On create_MERCURIOS_DATA_staging_marts_inventory: Close
[0m12:25:42.162922 [debug] [ThreadPool]: Snowflake adapter: Snowflake query id: 01baef6d-0204-2cd7-0003-4bde0007e24a
[0m12:25:42.163429 [debug] [ThreadPool]: Snowflake adapter: Snowflake error: 003001 (42501): SQL access control error:
Insufficient privileges to operate on database 'MERCURIOS_DATA'
[0m12:25:42.163937 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro create_schema
[0m12:25:42.164256 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
[0m12:25:42.164573 [debug] [ThreadPool]: On create_MERCURIOS_DATA_staging_staging: Close
[0m12:25:47.810716 [debug] [ThreadPool]: Snowflake adapter: Snowflake query id: 01baef6d-0204-2af5-0003-4bde00064b1a
[0m12:25:47.812772 [debug] [ThreadPool]: Snowflake adapter: Snowflake error: 003001 (42501): SQL access control error:
Insufficient privileges to operate on database 'MERCURIOS_DATA'
[0m12:25:47.813247 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro create_schema
[0m12:25:47.813429 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
[0m12:25:47.827561 [debug] [ThreadPool]: On create_MERCURIOS_DATA_staging_intermediate: Close
[0m12:25:47.946548 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:25:47.946859 [debug] [MainThread]: Connection 'create_MERCURIOS_DATA_staging_intermediate' was properly closed.
[0m12:25:47.947020 [debug] [MainThread]: Connection 'create_MERCURIOS_DATA_staging_staging' was properly closed.
[0m12:25:47.947156 [debug] [MainThread]: Connection 'create_MERCURIOS_DATA_staging_marts_inventory' was properly closed.
[0m12:25:47.947446 [info ] [MainThread]: 
[0m12:25:47.947690 [info ] [MainThread]: Finished running  in 0 hours 0 minutes and 36.30 seconds (36.30s).
[0m12:25:47.948473 [error] [MainThread]: Encountered an error:
Database Error
  003001 (42501): SQL access control error:
  Insufficient privileges to operate on database 'MERCURIOS_DATA'
[0m12:25:47.993540 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 37.72022, "process_in_blocks": "0", "process_kernel_time": 1.848714, "process_mem_max_rss": "188547072", "process_out_blocks": "0", "process_user_time": 2.660891}
[0m12:25:47.994132 [debug] [MainThread]: Command `dbt run` failed at 12:25:47.994045 after 37.72 seconds
[0m12:25:47.994883 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109a66dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104bede90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11993bed0>]}
[0m12:25:47.995624 [debug] [MainThread]: Flushing usage events
[0m12:25:48.580951 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:26:46.412714 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x125ae4410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x125b48890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x125b6b310>]}


============================== 12:26:46.416164 | 24cb450a-a3b2-42c8-9f61-ccb58f40c22e ==============================
[0m12:26:46.416164 [info ] [MainThread]: Running with dbt=1.9.2
[0m12:26:46.416532 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/Users/juliusrechenbach/API ProHandelTest/dbt_mercurios', 'log_path': '/Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt run', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m12:26:46.997056 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '24cb450a-a3b2-42c8-9f61-ccb58f40c22e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1730cff90>]}
[0m12:26:47.032030 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '24cb450a-a3b2-42c8-9f61-ccb58f40c22e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x124c36a50>]}
[0m12:26:47.032824 [info ] [MainThread]: Registered adapter: snowflake=1.9.1
[0m12:26:47.116331 [debug] [MainThread]: checksum: 12b12750b70de726cfd89136b8e24afc3f3e77597a97bff40ab7e5f9b39d5e18, vars: {}, profile: , target: , version: 1.9.2
[0m12:26:47.195997 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m12:26:47.196302 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m12:26:47.199888 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.mercurios.marts.sales
[0m12:26:47.223680 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '24cb450a-a3b2-42c8-9f61-ccb58f40c22e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x173081910>]}
[0m12:26:47.273202 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/target/manifest.json
[0m12:26:47.276010 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/target/semantic_manifest.json
[0m12:26:47.290483 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '24cb450a-a3b2-42c8-9f61-ccb58f40c22e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x16b6df150>]}
[0m12:26:47.290824 [info ] [MainThread]: Found 9 models, 40 data tests, 9 sources, 472 macros
[0m12:26:47.291006 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '24cb450a-a3b2-42c8-9f61-ccb58f40c22e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x16b835950>]}
[0m12:26:47.292338 [info ] [MainThread]: 
[0m12:26:47.292527 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:26:47.292672 [info ] [MainThread]: 
[0m12:26:47.292944 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m12:26:47.297357 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_MERCURIOS_DATA'
[0m12:26:47.297784 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_MERCURIOS_DATA'
[0m12:26:47.299492 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_MERCURIOS_DATA'
[0m12:26:47.387299 [debug] [ThreadPool]: Using snowflake connection "list_MERCURIOS_DATA"
[0m12:26:47.387683 [debug] [ThreadPool]: Using snowflake connection "list_MERCURIOS_DATA"
[0m12:26:47.387932 [debug] [ThreadPool]: Using snowflake connection "list_MERCURIOS_DATA"
[0m12:26:47.388137 [debug] [ThreadPool]: On list_MERCURIOS_DATA: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "list_MERCURIOS_DATA"} */
show terse schemas in database MERCURIOS_DATA
    limit 10000
[0m12:26:47.388433 [debug] [ThreadPool]: On list_MERCURIOS_DATA: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "list_MERCURIOS_DATA"} */
show terse schemas in database MERCURIOS_DATA
    limit 10000
[0m12:26:47.388641 [debug] [ThreadPool]: On list_MERCURIOS_DATA: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "list_MERCURIOS_DATA"} */
show terse schemas in database MERCURIOS_DATA
    limit 10000
[0m12:26:47.388825 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:26:47.389003 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:26:47.389209 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:26:51.199959 [debug] [ThreadPool]: SQL status: SUCCESS 28 in 3.811 seconds
[0m12:26:51.201299 [debug] [ThreadPool]: On list_MERCURIOS_DATA: Close
[0m12:26:55.797849 [debug] [ThreadPool]: SQL status: SUCCESS 28 in 8.409 seconds
[0m12:26:55.799700 [debug] [ThreadPool]: On list_MERCURIOS_DATA: Close
[0m12:27:00.274149 [debug] [ThreadPool]: SQL status: SUCCESS 28 in 12.885 seconds
[0m12:27:00.275544 [debug] [ThreadPool]: On list_MERCURIOS_DATA: Close
[0m12:27:00.392891 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_MERCURIOS_DATA, now create_MERCURIOS_DATA_staging_intermediate)
[0m12:27:00.393410 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_MERCURIOS_DATA, now create_MERCURIOS_DATA_staging_staging)
[0m12:27:00.393769 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_MERCURIOS_DATA, now create_MERCURIOS_DATA_staging_marts_inventory)
[0m12:27:00.394601 [debug] [ThreadPool]: Creating schema "database: "MERCURIOS_DATA"
schema: "staging_intermediate"
"
[0m12:27:00.395150 [debug] [ThreadPool]: Creating schema "database: "MERCURIOS_DATA"
schema: "staging_staging"
"
[0m12:27:00.395544 [debug] [ThreadPool]: Creating schema "database: "MERCURIOS_DATA"
schema: "staging_marts_inventory"
"
[0m12:27:00.399879 [debug] [ThreadPool]: Using snowflake connection "create_MERCURIOS_DATA_staging_intermediate"
[0m12:27:00.401900 [debug] [ThreadPool]: Using snowflake connection "create_MERCURIOS_DATA_staging_staging"
[0m12:27:00.404728 [debug] [ThreadPool]: Using snowflake connection "create_MERCURIOS_DATA_staging_marts_inventory"
[0m12:27:00.405060 [debug] [ThreadPool]: On create_MERCURIOS_DATA_staging_intermediate: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "create_MERCURIOS_DATA_staging_intermediate"} */
create schema if not exists MERCURIOS_DATA.staging_intermediate
[0m12:27:00.405298 [debug] [ThreadPool]: On create_MERCURIOS_DATA_staging_staging: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "create_MERCURIOS_DATA_staging_staging"} */
create schema if not exists MERCURIOS_DATA.staging_staging
[0m12:27:00.405515 [debug] [ThreadPool]: On create_MERCURIOS_DATA_staging_marts_inventory: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "create_MERCURIOS_DATA_staging_marts_inventory"} */
create schema if not exists MERCURIOS_DATA.staging_marts_inventory
[0m12:27:00.405720 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:27:00.405965 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:27:00.406187 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:27:04.450071 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 4.044 seconds
[0m12:27:04.451658 [debug] [ThreadPool]: On create_MERCURIOS_DATA_staging_staging: Close
[0m12:27:08.732396 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 8.326 seconds
[0m12:27:08.733313 [debug] [ThreadPool]: On create_MERCURIOS_DATA_staging_intermediate: Close
[0m12:27:13.056562 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 12.650 seconds
[0m12:27:13.060904 [debug] [ThreadPool]: On create_MERCURIOS_DATA_staging_marts_inventory: Close
[0m12:27:13.153625 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_MERCURIOS_DATA_staging_staging, now list_MERCURIOS_DATA_staging_intermediate)
[0m12:27:13.154081 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_MERCURIOS_DATA_staging_intermediate, now list_MERCURIOS_DATA_staging_staging)
[0m12:27:13.154488 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_MERCURIOS_DATA_staging_marts_inventory, now list_MERCURIOS_DATA_staging_marts_inventory)
[0m12:27:13.175952 [debug] [ThreadPool]: Using snowflake connection "list_MERCURIOS_DATA_staging_staging"
[0m12:27:13.176434 [debug] [ThreadPool]: Using snowflake connection "list_MERCURIOS_DATA_staging_intermediate"
[0m12:27:13.177937 [debug] [ThreadPool]: Using snowflake connection "list_MERCURIOS_DATA_staging_marts_inventory"
[0m12:27:13.178168 [debug] [ThreadPool]: On list_MERCURIOS_DATA_staging_staging: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "list_MERCURIOS_DATA_staging_staging"} */
show objects in MERCURIOS_DATA.staging_staging limit 10000;
[0m12:27:13.178381 [debug] [ThreadPool]: On list_MERCURIOS_DATA_staging_intermediate: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "list_MERCURIOS_DATA_staging_intermediate"} */
show objects in MERCURIOS_DATA.staging_intermediate limit 10000;
[0m12:27:13.178624 [debug] [ThreadPool]: On list_MERCURIOS_DATA_staging_marts_inventory: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "list_MERCURIOS_DATA_staging_marts_inventory"} */
show objects in MERCURIOS_DATA.staging_marts_inventory limit 10000;
[0m12:27:13.178880 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:27:13.179043 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:27:13.179185 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:27:22.387260 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 9.208 seconds
[0m12:27:22.388705 [debug] [ThreadPool]: On list_MERCURIOS_DATA_staging_marts_inventory: Close
[0m12:27:25.842223 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 12.663 seconds
[0m12:27:25.843303 [debug] [ThreadPool]: On list_MERCURIOS_DATA_staging_staging: Close
[0m12:27:29.289221 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 16.110 seconds
[0m12:27:29.290912 [debug] [ThreadPool]: On list_MERCURIOS_DATA_staging_intermediate: Close
[0m12:27:29.455054 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '24cb450a-a3b2-42c8-9f61-ccb58f40c22e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12209d590>]}
[0m12:27:29.456773 [debug] [Thread-10 ]: Began running node model.mercurios.stg_prohandel__articles
[0m12:27:29.457047 [debug] [Thread-11 ]: Began running node model.mercurios.stg_prohandel__inventory
[0m12:27:29.457302 [debug] [Thread-12 ]: Began running node model.mercurios.stg_prohandel__sales
[0m12:27:29.457683 [info ] [Thread-10 ]: 1 of 9 START sql view model staging_staging.stg_prohandel__articles ............ [RUN]
[0m12:27:29.458016 [info ] [Thread-11 ]: 2 of 9 START sql view model staging_staging.stg_prohandel__inventory ........... [RUN]
[0m12:27:29.458296 [info ] [Thread-12 ]: 3 of 9 START sql view model staging_staging.stg_prohandel__sales ............... [RUN]
[0m12:27:29.458597 [debug] [Thread-10 ]: Re-using an available connection from the pool (formerly list_MERCURIOS_DATA_staging_intermediate, now model.mercurios.stg_prohandel__articles)
[0m12:27:29.458820 [debug] [Thread-11 ]: Re-using an available connection from the pool (formerly list_MERCURIOS_DATA_staging_staging, now model.mercurios.stg_prohandel__inventory)
[0m12:27:29.459026 [debug] [Thread-12 ]: Re-using an available connection from the pool (formerly list_MERCURIOS_DATA_staging_marts_inventory, now model.mercurios.stg_prohandel__sales)
[0m12:27:29.459243 [debug] [Thread-10 ]: Began compiling node model.mercurios.stg_prohandel__articles
[0m12:27:29.459438 [debug] [Thread-11 ]: Began compiling node model.mercurios.stg_prohandel__inventory
[0m12:27:29.459622 [debug] [Thread-12 ]: Began compiling node model.mercurios.stg_prohandel__sales
[0m12:27:29.464989 [debug] [Thread-11 ]: Writing injected SQL for node "model.mercurios.stg_prohandel__inventory"
[0m12:27:29.472341 [debug] [Thread-10 ]: Writing injected SQL for node "model.mercurios.stg_prohandel__articles"
[0m12:27:29.474257 [debug] [Thread-12 ]: Writing injected SQL for node "model.mercurios.stg_prohandel__sales"
[0m12:27:29.475416 [debug] [Thread-11 ]: Began executing node model.mercurios.stg_prohandel__inventory
[0m12:27:29.475715 [debug] [Thread-12 ]: Began executing node model.mercurios.stg_prohandel__sales
[0m12:27:29.475967 [debug] [Thread-10 ]: Began executing node model.mercurios.stg_prohandel__articles
[0m12:27:29.499721 [debug] [Thread-11 ]: Writing runtime sql for node "model.mercurios.stg_prohandel__inventory"
[0m12:27:29.501530 [debug] [Thread-12 ]: Writing runtime sql for node "model.mercurios.stg_prohandel__sales"
[0m12:27:29.503022 [debug] [Thread-10 ]: Writing runtime sql for node "model.mercurios.stg_prohandel__articles"
[0m12:27:29.504533 [debug] [Thread-11 ]: Using snowflake connection "model.mercurios.stg_prohandel__inventory"
[0m12:27:29.505417 [debug] [Thread-12 ]: Using snowflake connection "model.mercurios.stg_prohandel__sales"
[0m12:27:29.505673 [debug] [Thread-11 ]: On model.mercurios.stg_prohandel__inventory: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "node_id": "model.mercurios.stg_prohandel__inventory"} */
create or replace   view MERCURIOS_DATA.staging_staging.stg_prohandel__inventory
  
   as (
    with source as (
    select * from MERCURIOS_DATA.RAW.inventory
),

renamed as (
    select
        inventory_id,
        article_id,
        warehouse_id,
        quantity,
        
        -- Add stock level categorization
        case
            when quantity <= 0 then 'Out of Stock'
            when quantity <= 5 then 'Low Stock'
            when quantity <= 20 then 'Medium Stock'
            when quantity > 20 then 'High Stock'
            else 'Unknown'
        end as stock_level,
        
        -- Add reorder flag
        case
            when quantity <= 5 then true
            else false
        end as needs_reorder,
        
        location,
        bin_number,
        last_count_date,
        last_received_date,
        last_shipped_date,
        
        -- Fivetran metadata
        _fivetran_synced,
        
        -- Add data quality flags
        case when quantity < 0 then true else false end as is_negative_quantity
    from source
)

select * from renamed
  );
[0m12:27:29.506671 [debug] [Thread-10 ]: Using snowflake connection "model.mercurios.stg_prohandel__articles"
[0m12:27:29.506964 [debug] [Thread-12 ]: On model.mercurios.stg_prohandel__sales: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "node_id": "model.mercurios.stg_prohandel__sales"} */
create or replace   view MERCURIOS_DATA.staging_staging.stg_prohandel__sales
  
   as (
    with source as (
    select * from MERCURIOS_DATA.RAW.sale
),

renamed as (
    select
        sale_id,
        order_id,
        article_id,
        quantity,
        price,
        discount,
        
        -- Calculate net price and revenue
        (price - coalesce(discount, 0)) as net_price,
        (price - coalesce(discount, 0)) * quantity as revenue,
        
        -- Add sale type categorization
        case
            when discount is null or discount = 0 then 'Regular'
            when discount > 0 and discount < (price * 0.1) then 'Small Discount'
            when discount >= (price * 0.1) and discount < (price * 0.3) then 'Medium Discount'
            when discount >= (price * 0.3) then 'Large Discount'
            else 'Unknown'
        end as sale_type,
        
        sale_date,
        customer_id,
        shop_id,
        
        -- Fivetran metadata
        _fivetran_synced,
        
        -- Add data quality flags
        case when quantity <= 0 then true else false end as is_invalid_quantity,
        case when price <= 0 then true else false end as is_invalid_price,
        case when discount > price then true else false end as is_discount_greater_than_price
    from source
)

select * from renamed
  );
[0m12:27:29.507216 [debug] [Thread-11 ]: Opening a new connection, currently in state closed
[0m12:27:29.507517 [debug] [Thread-10 ]: On model.mercurios.stg_prohandel__articles: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "node_id": "model.mercurios.stg_prohandel__articles"} */
create or replace   view MERCURIOS_DATA.staging_staging.stg_prohandel__articles
  
   as (
    with source as (
    select * from MERCURIOS_DATA.RAW.article
),

renamed as (
    select
        article_id,
        article_number,
        description,
        category,
        subcategory,
        brand,
        supplier,
        purchase_price,
        retail_price,
        
        -- Calculate profit margin
        (retail_price - purchase_price) as profit_margin,
        case 
            when (purchase_price > 0) then ((retail_price - purchase_price) / purchase_price) * 100 
            else null 
        end as profit_margin_percent,
        
        -- Add price tier categorization
        case
            when retail_price < 10 then 'Budget'
            when retail_price >= 10 and retail_price < 50 then 'Standard'
            when retail_price >= 50 and retail_price < 100 then 'Premium'
            when retail_price >= 100 then 'Luxury'
            else 'Uncategorized'
        end as price_tier,
        
        weight,
        dimensions,
        color,
        size,
        status,
        created_at,
        updated_at,
        
        -- Fivetran metadata
        _fivetran_synced,
        
        -- Add data quality flags
        case when description is null or description = '' then true else false end as is_missing_description,
        case when purchase_price is null or purchase_price = 0 then true else false end as is_missing_purchase_price,
        case when retail_price is null or retail_price = 0 then true else false end as is_missing_retail_price
    from source
)

select * from renamed
  );
[0m12:27:29.507769 [debug] [Thread-12 ]: Opening a new connection, currently in state closed
[0m12:27:29.508031 [debug] [Thread-10 ]: Opening a new connection, currently in state closed
[0m12:27:32.878591 [debug] [Thread-10 ]: Snowflake adapter: Snowflake query id: 01baef6f-0204-2b29-0003-4bde00066d02
[0m12:27:32.879140 [debug] [Thread-10 ]: Snowflake adapter: Snowflake error: 002003 (42S02): SQL compilation error:
Object 'MERCURIOS_DATA.RAW.ARTICLE' does not exist or not authorized.
[0m12:27:32.879847 [debug] [Thread-10 ]: On model.mercurios.stg_prohandel__articles: Close
[0m12:27:33.057424 [debug] [Thread-10 ]: Database Error in model stg_prohandel__articles (models/staging/stg_prohandel__articles.sql)
  002003 (42S02): SQL compilation error:
  Object 'MERCURIOS_DATA.RAW.ARTICLE' does not exist or not authorized.
  compiled code at target/run/mercurios/models/staging/stg_prohandel__articles.sql
[0m12:27:33.061211 [debug] [Thread-10 ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '24cb450a-a3b2-42c8-9f61-ccb58f40c22e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x17ba83b90>]}
[0m12:27:33.062017 [error] [Thread-10 ]: 1 of 9 ERROR creating sql view model staging_staging.stg_prohandel__articles ... [[31mERROR[0m in 3.60s]
[0m12:27:33.062381 [debug] [Thread-10 ]: Finished running node model.mercurios.stg_prohandel__articles
[0m12:27:33.062783 [debug] [Thread-16 ]: Marking all children of 'model.mercurios.stg_prohandel__articles' to be skipped because of status 'error'.  Reason: Database Error in model stg_prohandel__articles (models/staging/stg_prohandel__articles.sql)
  002003 (42S02): SQL compilation error:
  Object 'MERCURIOS_DATA.RAW.ARTICLE' does not exist or not authorized.
  compiled code at target/run/mercurios/models/staging/stg_prohandel__articles.sql.
[0m12:27:36.349029 [debug] [Thread-12 ]: Snowflake adapter: Snowflake query id: 01baef6f-0204-2b31-0003-4bde00065d2e
[0m12:27:36.350590 [debug] [Thread-12 ]: Snowflake adapter: Snowflake error: 002003 (42S02): SQL compilation error:
Object 'MERCURIOS_DATA.RAW.SALE' does not exist or not authorized.
[0m12:27:36.351263 [debug] [Thread-12 ]: On model.mercurios.stg_prohandel__sales: Close
[0m12:27:36.463707 [debug] [Thread-12 ]: Database Error in model stg_prohandel__sales (models/staging/stg_prohandel__sales.sql)
  002003 (42S02): SQL compilation error:
  Object 'MERCURIOS_DATA.RAW.SALE' does not exist or not authorized.
  compiled code at target/run/mercurios/models/staging/stg_prohandel__sales.sql
[0m12:27:36.464269 [debug] [Thread-12 ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '24cb450a-a3b2-42c8-9f61-ccb58f40c22e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1766695d0>]}
[0m12:27:36.464653 [error] [Thread-12 ]: 3 of 9 ERROR creating sql view model staging_staging.stg_prohandel__sales ...... [[31mERROR[0m in 7.01s]
[0m12:27:36.464961 [debug] [Thread-12 ]: Finished running node model.mercurios.stg_prohandel__sales
[0m12:27:36.465290 [debug] [Thread-16 ]: Marking all children of 'model.mercurios.stg_prohandel__sales' to be skipped because of status 'error'.  Reason: Database Error in model stg_prohandel__sales (models/staging/stg_prohandel__sales.sql)
  002003 (42S02): SQL compilation error:
  Object 'MERCURIOS_DATA.RAW.SALE' does not exist or not authorized.
  compiled code at target/run/mercurios/models/staging/stg_prohandel__sales.sql.
[0m12:27:36.465968 [debug] [Thread-13 ]: Began running node model.mercurios.demand_forecast
[0m12:27:36.466258 [info ] [Thread-13 ]: 4 of 9 SKIP relation staging_marts_inventory.demand_forecast ................... [[33mSKIP[0m]
[0m12:27:36.466605 [debug] [Thread-13 ]: Finished running node model.mercurios.demand_forecast
[0m12:27:40.199573 [debug] [Thread-11 ]: Snowflake adapter: Snowflake query id: 01baef6f-0204-2b31-0003-4bde00065d32
[0m12:27:40.199881 [debug] [Thread-11 ]: Snowflake adapter: Snowflake error: 002003 (42S02): SQL compilation error:
Object 'MERCURIOS_DATA.RAW.INVENTORY' does not exist or not authorized.
[0m12:27:40.200214 [debug] [Thread-11 ]: On model.mercurios.stg_prohandel__inventory: Close
[0m12:27:40.309093 [debug] [Thread-11 ]: Database Error in model stg_prohandel__inventory (models/staging/stg_prohandel__inventory.sql)
  002003 (42S02): SQL compilation error:
  Object 'MERCURIOS_DATA.RAW.INVENTORY' does not exist or not authorized.
  compiled code at target/run/mercurios/models/staging/stg_prohandel__inventory.sql
[0m12:27:40.309876 [debug] [Thread-11 ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '24cb450a-a3b2-42c8-9f61-ccb58f40c22e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x176650310>]}
[0m12:27:40.310494 [error] [Thread-11 ]: 2 of 9 ERROR creating sql view model staging_staging.stg_prohandel__inventory .. [[31mERROR[0m in 10.85s]
[0m12:27:40.311115 [debug] [Thread-11 ]: Finished running node model.mercurios.stg_prohandel__inventory
[0m12:27:40.311440 [debug] [Thread-16 ]: Marking all children of 'model.mercurios.stg_prohandel__inventory' to be skipped because of status 'error'.  Reason: Database Error in model stg_prohandel__inventory (models/staging/stg_prohandel__inventory.sql)
  002003 (42S02): SQL compilation error:
  Object 'MERCURIOS_DATA.RAW.INVENTORY' does not exist or not authorized.
  compiled code at target/run/mercurios/models/staging/stg_prohandel__inventory.sql.
[0m12:27:40.312240 [debug] [Thread-12 ]: Began running node model.mercurios.int_inventory_with_metrics
[0m12:27:40.312704 [info ] [Thread-12 ]: 5 of 9 SKIP relation staging_intermediate.int_inventory_with_metrics ........... [[33mSKIP[0m]
[0m12:27:40.313109 [debug] [Thread-12 ]: Finished running node model.mercurios.int_inventory_with_metrics
[0m12:27:40.313515 [debug] [Thread-13 ]: Began running node model.mercurios.inventory_status
[0m12:27:40.313780 [info ] [Thread-13 ]: 6 of 9 SKIP relation staging_marts_inventory.inventory_status .................. [[33mSKIP[0m]
[0m12:27:40.314172 [debug] [Thread-13 ]: Finished running node model.mercurios.inventory_status
[0m12:27:40.314571 [debug] [Thread-10 ]: Began running node model.mercurios.reorder_recommendations
[0m12:27:40.314956 [debug] [Thread-12 ]: Began running node model.mercurios.stock_levels
[0m12:27:40.315151 [info ] [Thread-10 ]: 7 of 9 SKIP relation staging_marts_inventory.reorder_recommendations ........... [[33mSKIP[0m]
[0m12:27:40.315398 [info ] [Thread-12 ]: 8 of 9 SKIP relation staging_marts_inventory.stock_levels ...................... [[33mSKIP[0m]
[0m12:27:40.315619 [debug] [Thread-10 ]: Finished running node model.mercurios.reorder_recommendations
[0m12:27:40.315803 [debug] [Thread-12 ]: Finished running node model.mercurios.stock_levels
[0m12:27:40.316208 [debug] [Thread-13 ]: Began running node model.mercurios.tenant_inventory_dashboard
[0m12:27:40.316613 [info ] [Thread-13 ]: 9 of 9 SKIP relation staging_marts_inventory.tenant_inventory_dashboard ........ [[33mSKIP[0m]
[0m12:27:40.316830 [debug] [Thread-13 ]: Finished running node model.mercurios.tenant_inventory_dashboard
[0m12:27:40.321632 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:27:40.321965 [debug] [MainThread]: Connection 'model.mercurios.stg_prohandel__articles' was properly closed.
[0m12:27:40.322117 [debug] [MainThread]: Connection 'model.mercurios.stg_prohandel__inventory' was properly closed.
[0m12:27:40.322257 [debug] [MainThread]: Connection 'model.mercurios.stg_prohandel__sales' was properly closed.
[0m12:27:40.322580 [info ] [MainThread]: 
[0m12:27:40.322803 [info ] [MainThread]: Finished running 5 table models, 4 view models in 0 hours 0 minutes and 53.03 seconds (53.03s).
[0m12:27:40.323661 [debug] [MainThread]: Command end result
[0m12:27:40.349980 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/target/manifest.json
[0m12:27:40.352966 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/target/semantic_manifest.json
[0m12:27:40.359634 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/target/run_results.json
[0m12:27:40.359910 [info ] [MainThread]: 
[0m12:27:40.360146 [info ] [MainThread]: [31mCompleted with 3 errors, 0 partial successes, and 0 warnings:[0m
[0m12:27:40.360321 [info ] [MainThread]: 
[0m12:27:40.360607 [error] [MainThread]:   Database Error in model stg_prohandel__articles (models/staging/stg_prohandel__articles.sql)
  002003 (42S02): SQL compilation error:
  Object 'MERCURIOS_DATA.RAW.ARTICLE' does not exist or not authorized.
  compiled code at target/run/mercurios/models/staging/stg_prohandel__articles.sql
[0m12:27:40.360776 [info ] [MainThread]: 
[0m12:27:40.360958 [error] [MainThread]:   Database Error in model stg_prohandel__sales (models/staging/stg_prohandel__sales.sql)
  002003 (42S02): SQL compilation error:
  Object 'MERCURIOS_DATA.RAW.SALE' does not exist or not authorized.
  compiled code at target/run/mercurios/models/staging/stg_prohandel__sales.sql
[0m12:27:40.361128 [info ] [MainThread]: 
[0m12:27:40.361308 [error] [MainThread]:   Database Error in model stg_prohandel__inventory (models/staging/stg_prohandel__inventory.sql)
  002003 (42S02): SQL compilation error:
  Object 'MERCURIOS_DATA.RAW.INVENTORY' does not exist or not authorized.
  compiled code at target/run/mercurios/models/staging/stg_prohandel__inventory.sql
[0m12:27:40.361469 [info ] [MainThread]: 
[0m12:27:40.361657 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=3 SKIP=6 TOTAL=9
[0m12:27:40.367655 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 53.999, "process_in_blocks": "0", "process_kernel_time": 1.766649, "process_mem_max_rss": "188891136", "process_out_blocks": "0", "process_user_time": 2.794199}
[0m12:27:40.368151 [debug] [MainThread]: Command `dbt run` failed at 12:27:40.368078 after 54.00 seconds
[0m12:27:40.368563 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x125b49410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x125b6a9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104ec1f50>]}
[0m12:27:40.368799 [debug] [MainThread]: Flushing usage events
[0m12:27:40.930463 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:31:04.613131 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106ce8350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106ceac50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106d72fd0>]}


============================== 12:31:04.616448 | 5bcf8713-4a96-464d-bf6b-43fbb5bb79c8 ==============================
[0m12:31:04.616448 [info ] [MainThread]: Running with dbt=1.9.2
[0m12:31:04.616843 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/juliusrechenbach/API ProHandelTest/dbt_mercurios', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'invocation_command': 'dbt run', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:31:05.532830 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5bcf8713-4a96-464d-bf6b-43fbb5bb79c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106cf6450>]}
[0m12:31:05.569839 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5bcf8713-4a96-464d-bf6b-43fbb5bb79c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10448d150>]}
[0m12:31:05.570669 [info ] [MainThread]: Registered adapter: snowflake=1.9.1
[0m12:31:05.661311 [debug] [MainThread]: checksum: 12b12750b70de726cfd89136b8e24afc3f3e77597a97bff40ab7e5f9b39d5e18, vars: {}, profile: , target: , version: 1.9.2
[0m12:31:05.738507 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m12:31:05.739545 [debug] [MainThread]: Partial parsing: updated file: mercurios://models/staging/src_prohandel.yml
[0m12:31:06.085868 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.mercurios.marts.sales
[0m12:31:06.092540 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5bcf8713-4a96-464d-bf6b-43fbb5bb79c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x14e1a2390>]}
[0m12:31:06.139589 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/target/manifest.json
[0m12:31:06.142358 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/target/semantic_manifest.json
[0m12:31:06.155841 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5bcf8713-4a96-464d-bf6b-43fbb5bb79c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x14e31a490>]}
[0m12:31:06.156209 [info ] [MainThread]: Found 9 models, 17 data tests, 3 sources, 472 macros
[0m12:31:06.156407 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5bcf8713-4a96-464d-bf6b-43fbb5bb79c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x14e31bb90>]}
[0m12:31:06.157800 [info ] [MainThread]: 
[0m12:31:06.158090 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:31:06.158257 [info ] [MainThread]: 
[0m12:31:06.158520 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m12:31:06.161066 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_MERCURIOS_DATA'
[0m12:31:06.161469 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_MERCURIOS_DATA'
[0m12:31:06.161972 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_MERCURIOS_DATA'
[0m12:31:06.202469 [debug] [ThreadPool]: Using snowflake connection "list_MERCURIOS_DATA"
[0m12:31:06.202786 [debug] [ThreadPool]: Using snowflake connection "list_MERCURIOS_DATA"
[0m12:31:06.203038 [debug] [ThreadPool]: Using snowflake connection "list_MERCURIOS_DATA"
[0m12:31:06.203265 [debug] [ThreadPool]: On list_MERCURIOS_DATA: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "list_MERCURIOS_DATA"} */
show terse schemas in database MERCURIOS_DATA
    limit 10000
[0m12:31:06.203464 [debug] [ThreadPool]: On list_MERCURIOS_DATA: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "list_MERCURIOS_DATA"} */
show terse schemas in database MERCURIOS_DATA
    limit 10000
[0m12:31:06.203656 [debug] [ThreadPool]: On list_MERCURIOS_DATA: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "list_MERCURIOS_DATA"} */
show terse schemas in database MERCURIOS_DATA
    limit 10000
[0m12:31:06.203846 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:31:06.204012 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:31:06.204162 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:31:17.659094 [debug] [ThreadPool]: SQL status: SUCCESS 31 in 11.455 seconds
[0m12:31:17.661664 [debug] [ThreadPool]: On list_MERCURIOS_DATA: Close
[0m12:31:21.517152 [debug] [ThreadPool]: SQL status: SUCCESS 31 in 15.313 seconds
[0m12:31:21.518761 [debug] [ThreadPool]: On list_MERCURIOS_DATA: Close
[0m12:31:26.521181 [debug] [ThreadPool]: SQL status: SUCCESS 31 in 20.317 seconds
[0m12:31:26.522608 [debug] [ThreadPool]: On list_MERCURIOS_DATA: Close
[0m12:31:26.659586 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_MERCURIOS_DATA, now list_MERCURIOS_DATA_staging_staging)
[0m12:31:26.660127 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_MERCURIOS_DATA, now list_MERCURIOS_DATA_staging_intermediate)
[0m12:31:26.660572 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_MERCURIOS_DATA, now list_MERCURIOS_DATA_staging_marts_inventory)
[0m12:31:26.669055 [debug] [ThreadPool]: Using snowflake connection "list_MERCURIOS_DATA_staging_staging"
[0m12:31:26.670752 [debug] [ThreadPool]: Using snowflake connection "list_MERCURIOS_DATA_staging_intermediate"
[0m12:31:26.672272 [debug] [ThreadPool]: Using snowflake connection "list_MERCURIOS_DATA_staging_marts_inventory"
[0m12:31:26.672507 [debug] [ThreadPool]: On list_MERCURIOS_DATA_staging_staging: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "list_MERCURIOS_DATA_staging_staging"} */
show objects in MERCURIOS_DATA.staging_staging limit 10000;
[0m12:31:26.672725 [debug] [ThreadPool]: On list_MERCURIOS_DATA_staging_intermediate: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "list_MERCURIOS_DATA_staging_intermediate"} */
show objects in MERCURIOS_DATA.staging_intermediate limit 10000;
[0m12:31:26.672925 [debug] [ThreadPool]: On list_MERCURIOS_DATA_staging_marts_inventory: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "list_MERCURIOS_DATA_staging_marts_inventory"} */
show objects in MERCURIOS_DATA.staging_marts_inventory limit 10000;
[0m12:31:26.673129 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:31:26.673304 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:31:26.673473 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:31:30.415698 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 3.742 seconds
[0m12:31:30.418071 [debug] [ThreadPool]: On list_MERCURIOS_DATA_staging_intermediate: Close
[0m12:31:34.798873 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 8.125 seconds
[0m12:31:34.801924 [debug] [ThreadPool]: On list_MERCURIOS_DATA_staging_marts_inventory: Close
[0m12:31:38.624080 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 11.951 seconds
[0m12:31:38.625556 [debug] [ThreadPool]: On list_MERCURIOS_DATA_staging_staging: Close
[0m12:31:38.727229 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5bcf8713-4a96-464d-bf6b-43fbb5bb79c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x14e36f990>]}
[0m12:31:38.730690 [debug] [Thread-7 (]: Began running node model.mercurios.stg_prohandel__articles
[0m12:31:38.731219 [debug] [Thread-8 (]: Began running node model.mercurios.stg_prohandel__inventory
[0m12:31:38.731663 [debug] [Thread-9 (]: Began running node model.mercurios.stg_prohandel__sales
[0m12:31:38.732917 [info ] [Thread-7 (]: 1 of 9 START sql view model staging_staging.stg_prohandel__articles ............ [RUN]
[0m12:31:38.733450 [info ] [Thread-8 (]: 2 of 9 START sql view model staging_staging.stg_prohandel__inventory ........... [RUN]
[0m12:31:38.734057 [info ] [Thread-9 (]: 3 of 9 START sql view model staging_staging.stg_prohandel__sales ............... [RUN]
[0m12:31:38.734657 [debug] [Thread-7 (]: Re-using an available connection from the pool (formerly list_MERCURIOS_DATA_staging_staging, now model.mercurios.stg_prohandel__articles)
[0m12:31:38.735051 [debug] [Thread-8 (]: Re-using an available connection from the pool (formerly list_MERCURIOS_DATA_staging_intermediate, now model.mercurios.stg_prohandel__inventory)
[0m12:31:38.735428 [debug] [Thread-9 (]: Re-using an available connection from the pool (formerly list_MERCURIOS_DATA_staging_marts_inventory, now model.mercurios.stg_prohandel__sales)
[0m12:31:38.735771 [debug] [Thread-7 (]: Began compiling node model.mercurios.stg_prohandel__articles
[0m12:31:38.736080 [debug] [Thread-8 (]: Began compiling node model.mercurios.stg_prohandel__inventory
[0m12:31:38.736377 [debug] [Thread-9 (]: Began compiling node model.mercurios.stg_prohandel__sales
[0m12:31:38.751785 [debug] [Thread-7 (]: Writing injected SQL for node "model.mercurios.stg_prohandel__articles"
[0m12:31:38.753085 [debug] [Thread-8 (]: Writing injected SQL for node "model.mercurios.stg_prohandel__inventory"
[0m12:31:38.755531 [debug] [Thread-9 (]: Writing injected SQL for node "model.mercurios.stg_prohandel__sales"
[0m12:31:38.756350 [debug] [Thread-7 (]: Began executing node model.mercurios.stg_prohandel__articles
[0m12:31:38.756804 [debug] [Thread-8 (]: Began executing node model.mercurios.stg_prohandel__inventory
[0m12:31:38.776053 [debug] [Thread-7 (]: Writing runtime sql for node "model.mercurios.stg_prohandel__articles"
[0m12:31:38.778116 [debug] [Thread-8 (]: Writing runtime sql for node "model.mercurios.stg_prohandel__inventory"
[0m12:31:38.778374 [debug] [Thread-9 (]: Began executing node model.mercurios.stg_prohandel__sales
[0m12:31:38.781135 [debug] [Thread-9 (]: Writing runtime sql for node "model.mercurios.stg_prohandel__sales"
[0m12:31:38.782834 [debug] [Thread-7 (]: Using snowflake connection "model.mercurios.stg_prohandel__articles"
[0m12:31:38.783596 [debug] [Thread-8 (]: Using snowflake connection "model.mercurios.stg_prohandel__inventory"
[0m12:31:38.783942 [debug] [Thread-7 (]: On model.mercurios.stg_prohandel__articles: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "node_id": "model.mercurios.stg_prohandel__articles"} */
create or replace   view MERCURIOS_DATA.staging_staging.stg_prohandel__articles
  
   as (
    with source as (
    select * from MERCURIOS_DATA.RAW.article
),

renamed as (
    select
        article_id,
        article_number,
        description,
        category,
        subcategory,
        brand,
        supplier,
        purchase_price,
        retail_price,
        
        -- Calculate profit margin
        (retail_price - purchase_price) as profit_margin,
        case 
            when (purchase_price > 0) then ((retail_price - purchase_price) / purchase_price) * 100 
            else null 
        end as profit_margin_percent,
        
        -- Add price tier categorization
        case
            when retail_price < 10 then 'Budget'
            when retail_price >= 10 and retail_price < 50 then 'Standard'
            when retail_price >= 50 and retail_price < 100 then 'Premium'
            when retail_price >= 100 then 'Luxury'
            else 'Uncategorized'
        end as price_tier,
        
        weight,
        dimensions,
        color,
        size,
        status,
        created_at,
        updated_at,
        
        -- Fivetran metadata
        _fivetran_synced,
        
        -- Add data quality flags
        case when description is null or description = '' then true else false end as is_missing_description,
        case when purchase_price is null or purchase_price = 0 then true else false end as is_missing_purchase_price,
        case when retail_price is null or retail_price = 0 then true else false end as is_missing_retail_price
    from source
)

select * from renamed
  );
[0m12:31:38.784777 [debug] [Thread-9 (]: Using snowflake connection "model.mercurios.stg_prohandel__sales"
[0m12:31:38.785011 [debug] [Thread-8 (]: On model.mercurios.stg_prohandel__inventory: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "node_id": "model.mercurios.stg_prohandel__inventory"} */
create or replace   view MERCURIOS_DATA.staging_staging.stg_prohandel__inventory
  
   as (
    with source as (
    select * from MERCURIOS_DATA.RAW.inventory
),

renamed as (
    select
        inventory_id,
        article_id,
        warehouse_id,
        quantity,
        
        -- Add stock level categorization
        case
            when quantity <= 0 then 'Out of Stock'
            when quantity <= 5 then 'Low Stock'
            when quantity <= 20 then 'Medium Stock'
            when quantity > 20 then 'High Stock'
            else 'Unknown'
        end as stock_level,
        
        -- Add reorder flag
        case
            when quantity <= 5 then true
            else false
        end as needs_reorder,
        
        location,
        bin_number,
        last_count_date,
        last_received_date,
        last_shipped_date,
        
        -- Fivetran metadata
        _fivetran_synced,
        
        -- Add data quality flags
        case when quantity < 0 then true else false end as is_negative_quantity
    from source
)

select * from renamed
  );
[0m12:31:38.785284 [debug] [Thread-7 (]: Opening a new connection, currently in state closed
[0m12:31:38.785527 [debug] [Thread-9 (]: On model.mercurios.stg_prohandel__sales: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "node_id": "model.mercurios.stg_prohandel__sales"} */
create or replace   view MERCURIOS_DATA.staging_staging.stg_prohandel__sales
  
   as (
    with source as (
    select * from MERCURIOS_DATA.RAW.sale
),

renamed as (
    select
        sale_id,
        order_id,
        article_id,
        quantity,
        price,
        discount,
        
        -- Calculate net price and revenue
        (price - coalesce(discount, 0)) as net_price,
        (price - coalesce(discount, 0)) * quantity as revenue,
        
        -- Add sale type categorization
        case
            when discount is null or discount = 0 then 'Regular'
            when discount > 0 and discount < (price * 0.1) then 'Small Discount'
            when discount >= (price * 0.1) and discount < (price * 0.3) then 'Medium Discount'
            when discount >= (price * 0.3) then 'Large Discount'
            else 'Unknown'
        end as sale_type,
        
        sale_date,
        customer_id,
        shop_id,
        
        -- Fivetran metadata
        _fivetran_synced,
        
        -- Add data quality flags
        case when quantity <= 0 then true else false end as is_invalid_quantity,
        case when price <= 0 then true else false end as is_invalid_price,
        case when discount > price then true else false end as is_discount_greater_than_price
    from source
)

select * from renamed
  );
[0m12:31:38.785751 [debug] [Thread-8 (]: Opening a new connection, currently in state closed
[0m12:31:38.786074 [debug] [Thread-9 (]: Opening a new connection, currently in state closed
[0m12:31:42.301510 [debug] [Thread-7 (]: Snowflake adapter: Snowflake query id: 01baef73-0204-2b31-0003-4bde00065d56
[0m12:31:42.302180 [debug] [Thread-7 (]: Snowflake adapter: Snowflake error: 000904 (42000): SQL compilation error: error line 36 at position 8
invalid identifier 'WEIGHT'
[0m12:31:42.303080 [debug] [Thread-7 (]: On model.mercurios.stg_prohandel__articles: Close
[0m12:31:42.400828 [debug] [Thread-7 (]: Database Error in model stg_prohandel__articles (models/staging/stg_prohandel__articles.sql)
  000904 (42000): SQL compilation error: error line 36 at position 8
  invalid identifier 'WEIGHT'
  compiled code at target/run/mercurios/models/staging/stg_prohandel__articles.sql
[0m12:31:42.405644 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5bcf8713-4a96-464d-bf6b-43fbb5bb79c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x14e7cd310>]}
[0m12:31:42.406433 [error] [Thread-7 (]: 1 of 9 ERROR creating sql view model staging_staging.stg_prohandel__articles ... [[31mERROR[0m in 3.67s]
[0m12:31:42.406884 [debug] [Thread-7 (]: Finished running node model.mercurios.stg_prohandel__articles
[0m12:31:42.407413 [debug] [Thread-13 ]: Marking all children of 'model.mercurios.stg_prohandel__articles' to be skipped because of status 'error'.  Reason: Database Error in model stg_prohandel__articles (models/staging/stg_prohandel__articles.sql)
  000904 (42000): SQL compilation error: error line 36 at position 8
  invalid identifier 'WEIGHT'
  compiled code at target/run/mercurios/models/staging/stg_prohandel__articles.sql.
[0m12:31:45.748167 [debug] [Thread-8 (]: Snowflake adapter: Snowflake query id: 01baef73-0204-2b29-0003-4bde00066d26
[0m12:31:45.748496 [debug] [Thread-8 (]: Snowflake adapter: Snowflake error: 000904 (42000): SQL compilation error: error line 31 at position 8
invalid identifier 'BIN_NUMBER'
[0m12:31:45.748814 [debug] [Thread-8 (]: On model.mercurios.stg_prohandel__inventory: Close
[0m12:31:45.925519 [debug] [Thread-8 (]: Database Error in model stg_prohandel__inventory (models/staging/stg_prohandel__inventory.sql)
  000904 (42000): SQL compilation error: error line 31 at position 8
  invalid identifier 'BIN_NUMBER'
  compiled code at target/run/mercurios/models/staging/stg_prohandel__inventory.sql
[0m12:31:45.926046 [debug] [Thread-8 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5bcf8713-4a96-464d-bf6b-43fbb5bb79c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x14e7c56d0>]}
[0m12:31:45.926541 [error] [Thread-8 (]: 2 of 9 ERROR creating sql view model staging_staging.stg_prohandel__inventory .. [[31mERROR[0m in 7.19s]
[0m12:31:45.926947 [debug] [Thread-8 (]: Finished running node model.mercurios.stg_prohandel__inventory
[0m12:31:45.927364 [debug] [Thread-13 ]: Marking all children of 'model.mercurios.stg_prohandel__inventory' to be skipped because of status 'error'.  Reason: Database Error in model stg_prohandel__inventory (models/staging/stg_prohandel__inventory.sql)
  000904 (42000): SQL compilation error: error line 31 at position 8
  invalid identifier 'BIN_NUMBER'
  compiled code at target/run/mercurios/models/staging/stg_prohandel__inventory.sql.
[0m12:31:49.276964 [debug] [Thread-9 (]: Snowflake adapter: Snowflake query id: 01baef73-0204-29a8-0003-4bde0007b232
[0m12:31:49.278405 [debug] [Thread-9 (]: Snowflake adapter: Snowflake error: 000904 (42000): SQL compilation error: error line 31 at position 8
invalid identifier 'CUSTOMER_ID'
[0m12:31:49.279373 [debug] [Thread-9 (]: On model.mercurios.stg_prohandel__sales: Close
[0m12:31:49.383873 [debug] [Thread-9 (]: Database Error in model stg_prohandel__sales (models/staging/stg_prohandel__sales.sql)
  000904 (42000): SQL compilation error: error line 31 at position 8
  invalid identifier 'CUSTOMER_ID'
  compiled code at target/run/mercurios/models/staging/stg_prohandel__sales.sql
[0m12:31:49.384342 [debug] [Thread-9 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5bcf8713-4a96-464d-bf6b-43fbb5bb79c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x14e444450>]}
[0m12:31:49.384841 [error] [Thread-9 (]: 3 of 9 ERROR creating sql view model staging_staging.stg_prohandel__sales ...... [[31mERROR[0m in 10.65s]
[0m12:31:49.385180 [debug] [Thread-9 (]: Finished running node model.mercurios.stg_prohandel__sales
[0m12:31:49.385438 [debug] [Thread-13 ]: Marking all children of 'model.mercurios.stg_prohandel__sales' to be skipped because of status 'error'.  Reason: Database Error in model stg_prohandel__sales (models/staging/stg_prohandel__sales.sql)
  000904 (42000): SQL compilation error: error line 31 at position 8
  invalid identifier 'CUSTOMER_ID'
  compiled code at target/run/mercurios/models/staging/stg_prohandel__sales.sql.
[0m12:31:49.386103 [debug] [Thread-10 ]: Began running node model.mercurios.demand_forecast
[0m12:31:49.386380 [debug] [Thread-7 (]: Began running node model.mercurios.int_inventory_with_metrics
[0m12:31:49.386667 [info ] [Thread-10 ]: 4 of 9 SKIP relation staging_marts_inventory.demand_forecast ................... [[33mSKIP[0m]
[0m12:31:49.386960 [info ] [Thread-7 (]: 5 of 9 SKIP relation staging_intermediate.int_inventory_with_metrics ........... [[33mSKIP[0m]
[0m12:31:49.387226 [debug] [Thread-10 ]: Finished running node model.mercurios.demand_forecast
[0m12:31:49.387458 [debug] [Thread-7 (]: Finished running node model.mercurios.int_inventory_with_metrics
[0m12:31:49.387868 [debug] [Thread-9 (]: Began running node model.mercurios.inventory_status
[0m12:31:49.388107 [info ] [Thread-9 (]: 6 of 9 SKIP relation staging_marts_inventory.inventory_status .................. [[33mSKIP[0m]
[0m12:31:49.388318 [debug] [Thread-9 (]: Finished running node model.mercurios.inventory_status
[0m12:31:49.388645 [debug] [Thread-10 ]: Began running node model.mercurios.reorder_recommendations
[0m12:31:49.388849 [info ] [Thread-10 ]: 7 of 9 SKIP relation staging_marts_inventory.reorder_recommendations ........... [[33mSKIP[0m]
[0m12:31:49.389042 [debug] [Thread-7 (]: Began running node model.mercurios.stock_levels
[0m12:31:49.389219 [debug] [Thread-10 ]: Finished running node model.mercurios.reorder_recommendations
[0m12:31:49.389425 [info ] [Thread-7 (]: 8 of 9 SKIP relation staging_marts_inventory.stock_levels ...................... [[33mSKIP[0m]
[0m12:31:49.389791 [debug] [Thread-7 (]: Finished running node model.mercurios.stock_levels
[0m12:31:49.390024 [debug] [Thread-9 (]: Began running node model.mercurios.tenant_inventory_dashboard
[0m12:31:49.390322 [info ] [Thread-9 (]: 9 of 9 SKIP relation staging_marts_inventory.tenant_inventory_dashboard ........ [[33mSKIP[0m]
[0m12:31:49.390653 [debug] [Thread-9 (]: Finished running node model.mercurios.tenant_inventory_dashboard
[0m12:31:49.391663 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:31:49.391878 [debug] [MainThread]: Connection 'model.mercurios.stg_prohandel__articles' was properly closed.
[0m12:31:49.392091 [debug] [MainThread]: Connection 'model.mercurios.stg_prohandel__inventory' was properly closed.
[0m12:31:49.392266 [debug] [MainThread]: Connection 'model.mercurios.stg_prohandel__sales' was properly closed.
[0m12:31:49.392504 [info ] [MainThread]: 
[0m12:31:49.392676 [info ] [MainThread]: Finished running 5 table models, 4 view models in 0 hours 0 minutes and 43.23 seconds (43.23s).
[0m12:31:49.393181 [debug] [MainThread]: Command end result
[0m12:31:49.407510 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/target/manifest.json
[0m12:31:49.409223 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/target/semantic_manifest.json
[0m12:31:49.412410 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/target/run_results.json
[0m12:31:49.412609 [info ] [MainThread]: 
[0m12:31:49.412815 [info ] [MainThread]: [31mCompleted with 3 errors, 0 partial successes, and 0 warnings:[0m
[0m12:31:49.412980 [info ] [MainThread]: 
[0m12:31:49.413185 [error] [MainThread]:   Database Error in model stg_prohandel__articles (models/staging/stg_prohandel__articles.sql)
  000904 (42000): SQL compilation error: error line 36 at position 8
  invalid identifier 'WEIGHT'
  compiled code at target/run/mercurios/models/staging/stg_prohandel__articles.sql
[0m12:31:49.413340 [info ] [MainThread]: 
[0m12:31:49.413513 [error] [MainThread]:   Database Error in model stg_prohandel__inventory (models/staging/stg_prohandel__inventory.sql)
  000904 (42000): SQL compilation error: error line 31 at position 8
  invalid identifier 'BIN_NUMBER'
  compiled code at target/run/mercurios/models/staging/stg_prohandel__inventory.sql
[0m12:31:49.413666 [info ] [MainThread]: 
[0m12:31:49.413840 [error] [MainThread]:   Database Error in model stg_prohandel__sales (models/staging/stg_prohandel__sales.sql)
  000904 (42000): SQL compilation error: error line 31 at position 8
  invalid identifier 'CUSTOMER_ID'
  compiled code at target/run/mercurios/models/staging/stg_prohandel__sales.sql
[0m12:31:49.413990 [info ] [MainThread]: 
[0m12:31:49.414162 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=3 SKIP=6 TOTAL=9
[0m12:31:49.416035 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 44.84675, "process_in_blocks": "0", "process_kernel_time": 0.833815, "process_mem_max_rss": "192954368", "process_out_blocks": "0", "process_user_time": 2.968871}
[0m12:31:49.416283 [debug] [MainThread]: Command `dbt run` failed at 12:31:49.416245 after 44.85 seconds
[0m12:31:49.416575 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x14ec17490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x100ad6290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x100ad5f10>]}
[0m12:31:49.416762 [debug] [MainThread]: Flushing usage events
[0m12:31:49.978770 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:34:54.715717 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1405de3d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x14066e4d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x14066ec50>]}


============================== 12:34:54.719266 | d64c999f-8b3b-4efa-9326-221a10fd2f76 ==============================
[0m12:34:54.719266 [info ] [MainThread]: Running with dbt=1.9.2
[0m12:34:54.719626 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/juliusrechenbach/API ProHandelTest/dbt_mercurios', 'debug': 'False', 'version_check': 'True', 'log_path': '/Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt run', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m12:34:55.514474 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd64c999f-8b3b-4efa-9326-221a10fd2f76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1405f6ed0>]}
[0m12:34:55.549809 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd64c999f-8b3b-4efa-9326-221a10fd2f76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105b86810>]}
[0m12:34:55.550728 [info ] [MainThread]: Registered adapter: snowflake=1.9.1
[0m12:34:55.647343 [debug] [MainThread]: checksum: 12b12750b70de726cfd89136b8e24afc3f3e77597a97bff40ab7e5f9b39d5e18, vars: {}, profile: , target: , version: 1.9.2
[0m12:34:55.724594 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 3 files changed.
[0m12:34:55.725041 [debug] [MainThread]: Partial parsing: updated file: mercurios://models/staging/stg_prohandel__articles.sql
[0m12:34:55.725250 [debug] [MainThread]: Partial parsing: updated file: mercurios://models/staging/stg_prohandel__inventory.sql
[0m12:34:55.725449 [debug] [MainThread]: Partial parsing: updated file: mercurios://models/staging/stg_prohandel__sales.sql
[0m12:34:55.877744 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.mercurios.marts.sales
[0m12:34:55.933693 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd64c999f-8b3b-4efa-9326-221a10fd2f76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1465425d0>]}
[0m12:34:55.978581 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/target/manifest.json
[0m12:34:55.981234 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/target/semantic_manifest.json
[0m12:34:55.998623 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd64c999f-8b3b-4efa-9326-221a10fd2f76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x14062ca50>]}
[0m12:34:55.999063 [info ] [MainThread]: Found 9 models, 17 data tests, 3 sources, 472 macros
[0m12:34:55.999390 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd64c999f-8b3b-4efa-9326-221a10fd2f76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f9d950>]}
[0m12:34:56.000972 [info ] [MainThread]: 
[0m12:34:56.001283 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:34:56.001573 [info ] [MainThread]: 
[0m12:34:56.001914 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m12:34:56.004384 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_MERCURIOS_DATA'
[0m12:34:56.004791 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_MERCURIOS_DATA'
[0m12:34:56.010542 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_MERCURIOS_DATA'
[0m12:34:56.044255 [debug] [ThreadPool]: Using snowflake connection "list_MERCURIOS_DATA"
[0m12:34:56.044566 [debug] [ThreadPool]: Using snowflake connection "list_MERCURIOS_DATA"
[0m12:34:56.044842 [debug] [ThreadPool]: Using snowflake connection "list_MERCURIOS_DATA"
[0m12:34:56.045110 [debug] [ThreadPool]: On list_MERCURIOS_DATA: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "list_MERCURIOS_DATA"} */
show terse schemas in database MERCURIOS_DATA
    limit 10000
[0m12:34:56.045391 [debug] [ThreadPool]: On list_MERCURIOS_DATA: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "list_MERCURIOS_DATA"} */
show terse schemas in database MERCURIOS_DATA
    limit 10000
[0m12:34:56.045701 [debug] [ThreadPool]: On list_MERCURIOS_DATA: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "list_MERCURIOS_DATA"} */
show terse schemas in database MERCURIOS_DATA
    limit 10000
[0m12:34:56.045949 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:34:56.046160 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:34:56.046405 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:35:03.047344 [debug] [ThreadPool]: SQL status: SUCCESS 31 in 7.001 seconds
[0m12:35:03.048796 [debug] [ThreadPool]: On list_MERCURIOS_DATA: Close
[0m12:35:06.530314 [debug] [ThreadPool]: SQL status: SUCCESS 31 in 10.484 seconds
[0m12:35:06.531518 [debug] [ThreadPool]: On list_MERCURIOS_DATA: Close
[0m12:35:10.091116 [debug] [ThreadPool]: SQL status: SUCCESS 31 in 14.045 seconds
[0m12:35:10.092388 [debug] [ThreadPool]: On list_MERCURIOS_DATA: Close
[0m12:35:10.321432 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_MERCURIOS_DATA, now list_MERCURIOS_DATA_staging_marts_inventory)
[0m12:35:10.321984 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_MERCURIOS_DATA, now list_MERCURIOS_DATA_staging_staging)
[0m12:35:10.322566 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_MERCURIOS_DATA, now list_MERCURIOS_DATA_staging_intermediate)
[0m12:35:10.332446 [debug] [ThreadPool]: Using snowflake connection "list_MERCURIOS_DATA_staging_marts_inventory"
[0m12:35:10.334644 [debug] [ThreadPool]: Using snowflake connection "list_MERCURIOS_DATA_staging_staging"
[0m12:35:10.336354 [debug] [ThreadPool]: Using snowflake connection "list_MERCURIOS_DATA_staging_intermediate"
[0m12:35:10.336609 [debug] [ThreadPool]: On list_MERCURIOS_DATA_staging_marts_inventory: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "list_MERCURIOS_DATA_staging_marts_inventory"} */
show objects in MERCURIOS_DATA.staging_marts_inventory limit 10000;
[0m12:35:10.336841 [debug] [ThreadPool]: On list_MERCURIOS_DATA_staging_staging: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "list_MERCURIOS_DATA_staging_staging"} */
show objects in MERCURIOS_DATA.staging_staging limit 10000;
[0m12:35:10.337064 [debug] [ThreadPool]: On list_MERCURIOS_DATA_staging_intermediate: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "list_MERCURIOS_DATA_staging_intermediate"} */
show objects in MERCURIOS_DATA.staging_intermediate limit 10000;
[0m12:35:10.337298 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:35:10.337540 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:35:10.337743 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:35:13.597034 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 3.259 seconds
[0m12:35:13.598178 [debug] [ThreadPool]: On list_MERCURIOS_DATA_staging_staging: Close
[0m12:35:17.520127 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 7.183 seconds
[0m12:35:17.521361 [debug] [ThreadPool]: On list_MERCURIOS_DATA_staging_marts_inventory: Close
[0m12:35:20.728427 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 10.390 seconds
[0m12:35:20.729962 [debug] [ThreadPool]: On list_MERCURIOS_DATA_staging_intermediate: Close
[0m12:35:20.834989 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd64c999f-8b3b-4efa-9326-221a10fd2f76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10520d190>]}
[0m12:35:20.837037 [debug] [Thread-7 (]: Began running node model.mercurios.stg_prohandel__articles
[0m12:35:20.837481 [debug] [Thread-8 (]: Began running node model.mercurios.stg_prohandel__inventory
[0m12:35:20.837918 [debug] [Thread-9 (]: Began running node model.mercurios.stg_prohandel__sales
[0m12:35:20.838442 [info ] [Thread-7 (]: 1 of 9 START sql view model staging_staging.stg_prohandel__articles ............ [RUN]
[0m12:35:20.838839 [info ] [Thread-8 (]: 2 of 9 START sql view model staging_staging.stg_prohandel__inventory ........... [RUN]
[0m12:35:20.839205 [info ] [Thread-9 (]: 3 of 9 START sql view model staging_staging.stg_prohandel__sales ............... [RUN]
[0m12:35:20.839654 [debug] [Thread-7 (]: Re-using an available connection from the pool (formerly list_MERCURIOS_DATA_staging_marts_inventory, now model.mercurios.stg_prohandel__articles)
[0m12:35:20.839956 [debug] [Thread-8 (]: Re-using an available connection from the pool (formerly list_MERCURIOS_DATA_staging_staging, now model.mercurios.stg_prohandel__inventory)
[0m12:35:20.840231 [debug] [Thread-9 (]: Re-using an available connection from the pool (formerly list_MERCURIOS_DATA_staging_intermediate, now model.mercurios.stg_prohandel__sales)
[0m12:35:20.840551 [debug] [Thread-7 (]: Began compiling node model.mercurios.stg_prohandel__articles
[0m12:35:20.840854 [debug] [Thread-8 (]: Began compiling node model.mercurios.stg_prohandel__inventory
[0m12:35:20.841102 [debug] [Thread-9 (]: Began compiling node model.mercurios.stg_prohandel__sales
[0m12:35:20.849193 [debug] [Thread-8 (]: Writing injected SQL for node "model.mercurios.stg_prohandel__inventory"
[0m12:35:20.853907 [debug] [Thread-7 (]: Writing injected SQL for node "model.mercurios.stg_prohandel__articles"
[0m12:35:20.856046 [debug] [Thread-9 (]: Writing injected SQL for node "model.mercurios.stg_prohandel__sales"
[0m12:35:20.856991 [debug] [Thread-9 (]: Began executing node model.mercurios.stg_prohandel__sales
[0m12:35:20.857358 [debug] [Thread-8 (]: Began executing node model.mercurios.stg_prohandel__inventory
[0m12:35:20.869302 [debug] [Thread-7 (]: Began executing node model.mercurios.stg_prohandel__articles
[0m12:35:20.875446 [debug] [Thread-9 (]: Writing runtime sql for node "model.mercurios.stg_prohandel__sales"
[0m12:35:20.877638 [debug] [Thread-8 (]: Writing runtime sql for node "model.mercurios.stg_prohandel__inventory"
[0m12:35:20.879341 [debug] [Thread-7 (]: Writing runtime sql for node "model.mercurios.stg_prohandel__articles"
[0m12:35:20.880933 [debug] [Thread-7 (]: Using snowflake connection "model.mercurios.stg_prohandel__articles"
[0m12:35:20.881815 [debug] [Thread-9 (]: Using snowflake connection "model.mercurios.stg_prohandel__sales"
[0m12:35:20.882511 [debug] [Thread-8 (]: Using snowflake connection "model.mercurios.stg_prohandel__inventory"
[0m12:35:20.882786 [debug] [Thread-7 (]: On model.mercurios.stg_prohandel__articles: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "node_id": "model.mercurios.stg_prohandel__articles"} */
create or replace   view MERCURIOS_DATA.staging_staging.stg_prohandel__articles
  
   as (
    with source as (
    select * from MERCURIOS_DATA.RAW.article
),

renamed as (
    select
        article_id,
        article_number,
        description,
        category,
        subcategory,
        brand,
        supplier,
        purchase_price,
        retail_price,
        min_stock_level,
        max_stock_level,
        reorder_point,
        lead_time_days,
        is_active,
        
        -- Calculate profit margin
        (retail_price - purchase_price) as profit_margin,
        case 
            when (purchase_price > 0) then ((retail_price - purchase_price) / purchase_price) * 100 
            else null 
        end as profit_margin_percent,
        
        -- Add price tier categorization
        case
            when retail_price < 10 then 'Budget'
            when retail_price >= 10 and retail_price < 50 then 'Standard'
            when retail_price >= 50 and retail_price < 100 then 'Premium'
            when retail_price >= 100 then 'Luxury'
            else 'Uncategorized'
        end as price_tier,
        
        created_at,
        updated_at,
        tenant_id,
        
        -- Fivetran metadata
        _fivetran_synced,
        
        -- Add data quality flags
        case when description is null or description = '' then true else false end as is_missing_description,
        case when purchase_price is null or purchase_price = 0 then true else false end as is_missing_purchase_price,
        case when retail_price is null or retail_price = 0 then true else false end as is_missing_retail_price
    from source
)

select * from renamed
  );
[0m12:35:20.883089 [debug] [Thread-9 (]: On model.mercurios.stg_prohandel__sales: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "node_id": "model.mercurios.stg_prohandel__sales"} */
create or replace   view MERCURIOS_DATA.staging_staging.stg_prohandel__sales
  
   as (
    with source as (
    select * from MERCURIOS_DATA.RAW.sale
),

renamed as (
    select
        sale_id,
        order_id,
        article_id,
        quantity,
        price,
        discount,
        
        -- Calculate net price and revenue
        (price - coalesce(discount, 0)) as net_price,
        (price - coalesce(discount, 0)) * quantity as revenue,
        
        -- Add sale type categorization
        case
            when discount is null or discount = 0 then 'Regular'
            when discount > 0 and discount < (price * 0.1) then 'Small Discount'
            when discount >= (price * 0.1) and discount < (price * 0.3) then 'Medium Discount'
            when discount >= (price * 0.3) then 'Large Discount'
            else 'Unknown'
        end as sale_type,
        
        sale_date,
        shop_id,
        tenant_id,
        
        -- Fivetran metadata
        _fivetran_synced,
        
        -- Add data quality flags
        case when quantity <= 0 then true else false end as is_invalid_quantity,
        case when price <= 0 then true else false end as is_invalid_price,
        case when discount > price then true else false end as is_discount_greater_than_price
    from source
)

select * from renamed
  );
[0m12:35:20.883401 [debug] [Thread-8 (]: On model.mercurios.stg_prohandel__inventory: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "node_id": "model.mercurios.stg_prohandel__inventory"} */
create or replace   view MERCURIOS_DATA.staging_staging.stg_prohandel__inventory
  
   as (
    with source as (
    select * from MERCURIOS_DATA.RAW.inventory
),

renamed as (
    select
        inventory_id,
        article_id,
        warehouse_id,
        quantity,
        
        -- Add stock level categorization
        case
            when quantity <= 0 then 'Out of Stock'
            when quantity <= 5 then 'Low Stock'
            when quantity <= 20 then 'Medium Stock'
            when quantity > 20 then 'High Stock'
            else 'Unknown'
        end as stock_level,
        
        -- Add reorder flag
        case
            when quantity <= 5 then true
            else false
        end as needs_reorder,
        
        location,
        last_count_date,
        is_available,
        tenant_id,
        
        -- Fivetran metadata
        _fivetran_synced,
        
        -- Add data quality flags
        case when quantity < 0 then true else false end as is_negative_quantity
    from source
)

select * from renamed
  );
[0m12:35:20.883628 [debug] [Thread-7 (]: Opening a new connection, currently in state closed
[0m12:35:20.883842 [debug] [Thread-9 (]: Opening a new connection, currently in state closed
[0m12:35:20.884031 [debug] [Thread-8 (]: Opening a new connection, currently in state closed
[0m12:35:24.638341 [debug] [Thread-7 (]: SQL status: SUCCESS 1 in 3.754 seconds
[0m12:35:24.663747 [debug] [Thread-7 (]: On model.mercurios.stg_prohandel__articles: Close
[0m12:35:24.757396 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd64c999f-8b3b-4efa-9326-221a10fd2f76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x14648eb90>]}
[0m12:35:24.757820 [info ] [Thread-7 (]: 1 of 9 OK created sql view model staging_staging.stg_prohandel__articles ....... [[32mSUCCESS 1[0m in 3.92s]
[0m12:35:24.758105 [debug] [Thread-7 (]: Finished running node model.mercurios.stg_prohandel__articles
[0m12:35:28.013805 [debug] [Thread-8 (]: SQL status: SUCCESS 1 in 7.130 seconds
[0m12:35:28.015810 [debug] [Thread-8 (]: On model.mercurios.stg_prohandel__inventory: Close
[0m12:35:28.126950 [debug] [Thread-8 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd64c999f-8b3b-4efa-9326-221a10fd2f76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1465bfe90>]}
[0m12:35:28.127465 [info ] [Thread-8 (]: 2 of 9 OK created sql view model staging_staging.stg_prohandel__inventory ...... [[32mSUCCESS 1[0m in 7.29s]
[0m12:35:28.127776 [debug] [Thread-8 (]: Finished running node model.mercurios.stg_prohandel__inventory
[0m12:35:32.008329 [debug] [Thread-9 (]: SQL status: SUCCESS 1 in 11.124 seconds
[0m12:35:32.009893 [debug] [Thread-9 (]: On model.mercurios.stg_prohandel__sales: Close
[0m12:35:32.112003 [debug] [Thread-9 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd64c999f-8b3b-4efa-9326-221a10fd2f76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x150c0de50>]}
[0m12:35:32.112556 [info ] [Thread-9 (]: 3 of 9 OK created sql view model staging_staging.stg_prohandel__sales .......... [[32mSUCCESS 1[0m in 11.27s]
[0m12:35:32.112871 [debug] [Thread-9 (]: Finished running node model.mercurios.stg_prohandel__sales
[0m12:35:32.113588 [debug] [Thread-10 ]: Began running node model.mercurios.demand_forecast
[0m12:35:32.113868 [debug] [Thread-7 (]: Began running node model.mercurios.int_inventory_with_metrics
[0m12:35:32.114244 [info ] [Thread-10 ]: 4 of 9 START sql table model staging_marts_inventory.demand_forecast ........... [RUN]
[0m12:35:32.114530 [info ] [Thread-7 (]: 5 of 9 START sql view model staging_intermediate.int_inventory_with_metrics .... [RUN]
[0m12:35:32.114902 [debug] [Thread-10 ]: Acquiring new snowflake connection 'model.mercurios.demand_forecast'
[0m12:35:32.115152 [debug] [Thread-7 (]: Re-using an available connection from the pool (formerly model.mercurios.stg_prohandel__articles, now model.mercurios.int_inventory_with_metrics)
[0m12:35:32.115358 [debug] [Thread-10 ]: Began compiling node model.mercurios.demand_forecast
[0m12:35:32.115544 [debug] [Thread-7 (]: Began compiling node model.mercurios.int_inventory_with_metrics
[0m12:35:32.122197 [debug] [Thread-7 (]: Writing injected SQL for node "model.mercurios.int_inventory_with_metrics"
[0m12:35:32.122947 [debug] [Thread-7 (]: Began executing node model.mercurios.int_inventory_with_metrics
[0m12:35:32.130625 [debug] [Thread-7 (]: Writing runtime sql for node "model.mercurios.int_inventory_with_metrics"
[0m12:35:32.133435 [debug] [Thread-7 (]: Using snowflake connection "model.mercurios.int_inventory_with_metrics"
[0m12:35:32.133862 [debug] [Thread-7 (]: On model.mercurios.int_inventory_with_metrics: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "node_id": "model.mercurios.int_inventory_with_metrics"} */
create or replace   view MERCURIOS_DATA.staging_intermediate.int_inventory_with_metrics
  
   as (
    with inventory as (
    select * from MERCURIOS_DATA.staging_staging.stg_prohandel__inventory
),

articles as (
    select * from MERCURIOS_DATA.staging_staging.stg_prohandel__articles
),

sales_last_30_days as (
    select
        article_id,
        sum(quantity) as quantity_sold_30d,
        count(distinct sale_id) as num_orders_30d
    from MERCURIOS_DATA.staging_staging.stg_prohandel__sales
    where sale_date >= dateadd('day', -30, current_date())
    group by article_id
),

sales_last_90_days as (
    select
        article_id,
        sum(quantity) as quantity_sold_90d,
        count(distinct sale_id) as num_orders_90d
    from MERCURIOS_DATA.staging_staging.stg_prohandel__sales
    where sale_date >= dateadd('day', -90, current_date())
    group by article_id
),

inventory_with_metrics as (
    select
        -- Inventory fields
        i.inventory_id,
        i.article_id,
        i.warehouse_id,
        i.quantity,
        i.stock_level,
        i.needs_reorder,
        i.location,
        i.bin_number,
        i.last_count_date,
        i.last_received_date,
        i.last_shipped_date,
        
        -- Article fields
        a.article_number,
        a.description,
        a.category,
        a.subcategory,
        a.brand,
        a.supplier,
        a.purchase_price,
        a.retail_price,
        a.profit_margin,
        a.profit_margin_percent,
        a.price_tier,
        
        -- Sales metrics
        coalesce(s30.quantity_sold_30d, 0) as quantity_sold_30d,
        coalesce(s30.num_orders_30d, 0) as num_orders_30d,
        coalesce(s90.quantity_sold_90d, 0) as quantity_sold_90d,
        coalesce(s90.num_orders_90d, 0) as num_orders_90d,
        
        -- Calculate days of supply
        case
            when coalesce(s30.quantity_sold_30d, 0) > 0 then 
                (i.quantity / (s30.quantity_sold_30d / 30.0))
            else null
        end as days_of_supply_30d,
        
        case
            when coalesce(s90.quantity_sold_90d, 0) > 0 then 
                (i.quantity / (s90.quantity_sold_90d / 90.0))
            else null
        end as days_of_supply_90d,
        
        -- Calculate stock turnover rate (annualized)
        case
            when i.quantity > 0 and coalesce(s30.quantity_sold_30d, 0) > 0 then 
                (s30.quantity_sold_30d * (365.0 / 30.0)) / i.quantity
            else null
        end as turnover_rate_30d,
        
        case
            when i.quantity > 0 and coalesce(s90.quantity_sold_90d, 0) > 0 then 
                (s90.quantity_sold_90d * (365.0 / 90.0)) / i.quantity
            else null
        end as turnover_rate_90d,
        
        -- Calculate inventory value
        i.quantity * a.purchase_price as inventory_value,
        i.quantity * a.retail_price as potential_revenue,
        
        -- Calculate excess inventory flag
        case
            when coalesce(s90.quantity_sold_90d, 0) = 0 and i.quantity > 10 then true
            when coalesce(s90.quantity_sold_90d, 0) > 0 and 
                 (i.quantity / (s90.quantity_sold_90d / 90.0)) > 180 then true
            else false
        end as is_excess_inventory,
        
        -- Calculate slow-moving inventory flag
        case
            when coalesce(s90.quantity_sold_90d, 0) = 0 and i.quantity > 0 then true
            when coalesce(s90.quantity_sold_90d, 0) > 0 and 
                 (s90.quantity_sold_90d * (365.0 / 90.0)) / i.quantity < 1 then true
            else false
        end as is_slow_moving,
        
        -- Calculate stockout risk flag
        case
            when i.quantity = 0 then 'Stockout'
            when coalesce(s30.quantity_sold_30d, 0) > 0 and 
                 (i.quantity / (s30.quantity_sold_30d / 30.0)) < 3 then 'Critical'
            when coalesce(s30.quantity_sold_30d, 0) > 0 and 
                 (i.quantity / (s30.quantity_sold_30d / 30.0)) < 7 then 'Warning'
            else 'Normal'
        end as stockout_risk,
        
        -- Fivetran metadata
        i._fivetran_synced
    from inventory i
    left join articles a on i.article_id = a.article_id
    left join sales_last_30_days s30 on i.article_id = s30.article_id
    left join sales_last_90_days s90 on i.article_id = s90.article_id
)

select * from inventory_with_metrics
  );
[0m12:35:32.134281 [debug] [Thread-7 (]: Opening a new connection, currently in state closed
[0m12:35:32.139450 [debug] [Thread-10 ]: Compilation Error in model demand_forecast (models/marts/inventory/demand_forecast.sql)
  'dbt_utils' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m12:35:32.139896 [debug] [Thread-10 ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd64c999f-8b3b-4efa-9326-221a10fd2f76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x15590fbd0>]}
[0m12:35:32.140280 [error] [Thread-10 ]: 4 of 9 ERROR creating sql table model staging_marts_inventory.demand_forecast .. [[31mERROR[0m in 0.03s]
[0m12:35:32.140549 [debug] [Thread-10 ]: Finished running node model.mercurios.demand_forecast
[0m12:35:32.140879 [debug] [Thread-13 ]: Marking all children of 'model.mercurios.demand_forecast' to be skipped because of status 'error'.  Reason: Compilation Error in model demand_forecast (models/marts/inventory/demand_forecast.sql)
  'dbt_utils' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps"..
[0m12:35:35.085065 [debug] [Thread-7 (]: Snowflake adapter: Snowflake query id: 01baef77-0204-2b31-0003-4bde00065d5a
[0m12:35:35.085357 [debug] [Thread-7 (]: Snowflake adapter: Snowflake error: 000904 (42000): SQL compilation error: error line 42 at position 8
invalid identifier 'I.BIN_NUMBER'
[0m12:35:35.085631 [debug] [Thread-7 (]: On model.mercurios.int_inventory_with_metrics: Close
[0m12:35:35.202997 [debug] [Thread-7 (]: Database Error in model int_inventory_with_metrics (models/intermediate/int_inventory_with_metrics.sql)
  000904 (42000): SQL compilation error: error line 42 at position 8
  invalid identifier 'I.BIN_NUMBER'
  compiled code at target/run/mercurios/models/intermediate/int_inventory_with_metrics.sql
[0m12:35:35.203605 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd64c999f-8b3b-4efa-9326-221a10fd2f76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x146553050>]}
[0m12:35:35.204051 [error] [Thread-7 (]: 5 of 9 ERROR creating sql view model staging_intermediate.int_inventory_with_metrics  [[31mERROR[0m in 3.09s]
[0m12:35:35.204444 [debug] [Thread-7 (]: Finished running node model.mercurios.int_inventory_with_metrics
[0m12:35:35.204874 [debug] [Thread-13 ]: Marking all children of 'model.mercurios.int_inventory_with_metrics' to be skipped because of status 'error'.  Reason: Database Error in model int_inventory_with_metrics (models/intermediate/int_inventory_with_metrics.sql)
  000904 (42000): SQL compilation error: error line 42 at position 8
  invalid identifier 'I.BIN_NUMBER'
  compiled code at target/run/mercurios/models/intermediate/int_inventory_with_metrics.sql.
[0m12:35:35.205490 [debug] [Thread-9 (]: Began running node model.mercurios.inventory_status
[0m12:35:35.205859 [info ] [Thread-9 (]: 6 of 9 SKIP relation staging_marts_inventory.inventory_status .................. [[33mSKIP[0m]
[0m12:35:35.206247 [debug] [Thread-9 (]: Finished running node model.mercurios.inventory_status
[0m12:35:35.206705 [debug] [Thread-10 ]: Began running node model.mercurios.reorder_recommendations
[0m12:35:35.206974 [debug] [Thread-7 (]: Began running node model.mercurios.stock_levels
[0m12:35:35.207259 [info ] [Thread-10 ]: 7 of 9 SKIP relation staging_marts_inventory.reorder_recommendations ........... [[33mSKIP[0m]
[0m12:35:35.207618 [info ] [Thread-7 (]: 8 of 9 SKIP relation staging_marts_inventory.stock_levels ...................... [[33mSKIP[0m]
[0m12:35:35.207927 [debug] [Thread-10 ]: Finished running node model.mercurios.reorder_recommendations
[0m12:35:35.208204 [debug] [Thread-7 (]: Finished running node model.mercurios.stock_levels
[0m12:35:35.208557 [debug] [Thread-9 (]: Began running node model.mercurios.tenant_inventory_dashboard
[0m12:35:35.208894 [info ] [Thread-9 (]: 9 of 9 SKIP relation staging_marts_inventory.tenant_inventory_dashboard ........ [[33mSKIP[0m]
[0m12:35:35.209264 [debug] [Thread-9 (]: Finished running node model.mercurios.tenant_inventory_dashboard
[0m12:35:35.210094 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:35:35.210332 [debug] [MainThread]: Connection 'model.mercurios.int_inventory_with_metrics' was properly closed.
[0m12:35:35.210595 [debug] [MainThread]: Connection 'model.mercurios.stg_prohandel__inventory' was properly closed.
[0m12:35:35.210809 [debug] [MainThread]: Connection 'model.mercurios.stg_prohandel__sales' was properly closed.
[0m12:35:35.211285 [debug] [MainThread]: Connection 'model.mercurios.demand_forecast' was properly closed.
[0m12:35:35.211646 [info ] [MainThread]: 
[0m12:35:35.211860 [info ] [MainThread]: Finished running 5 table models, 4 view models in 0 hours 0 minutes and 39.21 seconds (39.21s).
[0m12:35:35.212552 [debug] [MainThread]: Command end result
[0m12:35:35.233019 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/target/manifest.json
[0m12:35:35.235794 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/target/semantic_manifest.json
[0m12:35:35.239669 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/target/run_results.json
[0m12:35:35.239915 [info ] [MainThread]: 
[0m12:35:35.240172 [info ] [MainThread]: [31mCompleted with 2 errors, 0 partial successes, and 0 warnings:[0m
[0m12:35:35.240434 [info ] [MainThread]: 
[0m12:35:35.240683 [error] [MainThread]:   Compilation Error in model demand_forecast (models/marts/inventory/demand_forecast.sql)
  'dbt_utils' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m12:35:35.240940 [info ] [MainThread]: 
[0m12:35:35.241189 [error] [MainThread]:   Database Error in model int_inventory_with_metrics (models/intermediate/int_inventory_with_metrics.sql)
  000904 (42000): SQL compilation error: error line 42 at position 8
  invalid identifier 'I.BIN_NUMBER'
  compiled code at target/run/mercurios/models/intermediate/int_inventory_with_metrics.sql
[0m12:35:35.241366 [info ] [MainThread]: 
[0m12:35:35.241543 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=2 SKIP=4 TOTAL=9
[0m12:35:35.243969 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 40.57925, "process_in_blocks": "0", "process_kernel_time": 1.06438, "process_mem_max_rss": "194936832", "process_out_blocks": "0", "process_user_time": 2.866203}
[0m12:35:35.244257 [debug] [MainThread]: Command `dbt run` failed at 12:35:35.244213 after 40.58 seconds
[0m12:35:35.244667 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x14066f0d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1023e6290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105a01e50>]}
[0m12:35:35.244888 [debug] [MainThread]: Flushing usage events
[0m12:35:35.968132 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:35:43.415432 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a4e51d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a56a090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a56a810>]}


============================== 12:35:43.418793 | 61245eaa-cdc6-428c-8a9a-5203068de54c ==============================
[0m12:35:43.418793 [info ] [MainThread]: Running with dbt=1.9.2
[0m12:35:43.419264 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/logs', 'fail_fast': 'False', 'profiles_dir': '/Users/juliusrechenbach/API ProHandelTest/dbt_mercurios', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt deps', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:35:43.518228 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '61245eaa-cdc6-428c-8a9a-5203068de54c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a56a7d0>]}
[0m12:35:43.531543 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m12:35:43.532169 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m12:35:43.533375 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.16526671, "process_in_blocks": "0", "process_kernel_time": 0.194885, "process_mem_max_rss": "109674496", "process_out_blocks": "0", "process_user_time": 0.767246}
[0m12:35:43.533725 [debug] [MainThread]: Command `dbt deps` succeeded at 12:35:43.533658 after 0.17 seconds
[0m12:35:43.533960 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a20e450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a5878d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a587bd0>]}
[0m12:35:43.534251 [debug] [MainThread]: Flushing usage events
[0m12:35:44.057508 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:35:57.572423 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ce56750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ce54290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ce73090>]}


============================== 12:35:57.575688 | 5ff9a40d-1321-4157-9eb8-63f510831bad ==============================
[0m12:35:57.575688 [info ] [MainThread]: Running with dbt=1.9.2
[0m12:35:57.576046 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/logs', 'fail_fast': 'False', 'profiles_dir': '/Users/juliusrechenbach/API ProHandelTest/dbt_mercurios', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt deps', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m12:35:57.647505 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5ff9a40d-1321-4157-9eb8-63f510831bad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ced2850>]}
[0m12:35:57.661104 [debug] [MainThread]: Set downloads directory='/var/folders/41/fgfhmfrx04584bv_ztsg5_2m0000gn/T/dbt-downloads-uxxke9w2'
[0m12:35:57.661496 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m12:35:57.823816 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m12:35:57.824407 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m12:35:57.917343 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m12:35:57.923891 [info ] [MainThread]: Updating lock file in file path: /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/package-lock.yml
[0m12:35:57.925343 [debug] [MainThread]: Set downloads directory='/var/folders/41/fgfhmfrx04584bv_ztsg5_2m0000gn/T/dbt-downloads-jgbv8c2u'
[0m12:35:57.927178 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m12:35:58.393199 [info ] [MainThread]: Installed from version 1.1.1
[0m12:35:58.393520 [info ] [MainThread]: Updated version available: 1.3.0
[0m12:35:58.393736 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '5ff9a40d-1321-4157-9eb8-63f510831bad', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c9ed250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ceaac10>]}
[0m12:35:58.393963 [info ] [MainThread]: 
[0m12:35:58.394314 [info ] [MainThread]: Updates available for packages: ['dbt-labs/dbt_utils']                 
Update your versions in packages.yml, then run dbt deps
[0m12:35:58.396338 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.86836094, "process_in_blocks": "0", "process_kernel_time": 0.326637, "process_mem_max_rss": "113147904", "process_out_blocks": "0", "process_user_time": 0.806798}
[0m12:35:58.396594 [debug] [MainThread]: Command `dbt deps` succeeded at 12:35:58.396546 after 0.87 seconds
[0m12:35:58.396826 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ce55f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ce55450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1050d9610>]}
[0m12:35:58.397035 [debug] [MainThread]: Flushing usage events
[0m12:35:59.256399 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:37:34.687153 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c14a810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c148890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c1484d0>]}


============================== 12:37:34.690641 | f3784bb2-502a-4138-ad09-b401897ffcae ==============================
[0m12:37:34.690641 [info ] [MainThread]: Running with dbt=1.9.2
[0m12:37:34.691072 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/logs', 'profiles_dir': '/Users/juliusrechenbach/API ProHandelTest/dbt_mercurios', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:37:35.432971 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f3784bb2-502a-4138-ad09-b401897ffcae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c0f7c90>]}
[0m12:37:35.468794 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f3784bb2-502a-4138-ad09-b401897ffcae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ac19850>]}
[0m12:37:35.469624 [info ] [MainThread]: Registered adapter: snowflake=1.9.1
[0m12:37:35.551872 [debug] [MainThread]: checksum: 12b12750b70de726cfd89136b8e24afc3f3e77597a97bff40ab7e5f9b39d5e18, vars: {}, profile: , target: , version: 1.9.2
[0m12:37:35.601961 [info ] [MainThread]: Unable to do partial parsing because a project dependency has been added
[0m12:37:35.602328 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'f3784bb2-502a-4138-ad09-b401897ffcae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b7f7950>]}
[0m12:37:36.493162 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.mercurios.marts.sales
[0m12:37:36.499483 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f3784bb2-502a-4138-ad09-b401897ffcae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1261ac310>]}
[0m12:37:36.573818 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/target/manifest.json
[0m12:37:36.576357 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/target/semantic_manifest.json
[0m12:37:36.590535 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f3784bb2-502a-4138-ad09-b401897ffcae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12647ff50>]}
[0m12:37:36.590893 [info ] [MainThread]: Found 9 models, 17 data tests, 3 sources, 586 macros
[0m12:37:36.591091 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f3784bb2-502a-4138-ad09-b401897ffcae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x126407590>]}
[0m12:37:36.592534 [info ] [MainThread]: 
[0m12:37:36.592818 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:37:36.592984 [info ] [MainThread]: 
[0m12:37:36.593263 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m12:37:36.595691 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_MERCURIOS_DATA'
[0m12:37:36.596042 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_MERCURIOS_DATA'
[0m12:37:36.596336 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_MERCURIOS_DATA'
[0m12:37:36.630299 [debug] [ThreadPool]: Using snowflake connection "list_MERCURIOS_DATA"
[0m12:37:36.630656 [debug] [ThreadPool]: Using snowflake connection "list_MERCURIOS_DATA"
[0m12:37:36.630943 [debug] [ThreadPool]: Using snowflake connection "list_MERCURIOS_DATA"
[0m12:37:36.631230 [debug] [ThreadPool]: On list_MERCURIOS_DATA: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "list_MERCURIOS_DATA"} */
show terse schemas in database MERCURIOS_DATA
    limit 10000
[0m12:37:36.631465 [debug] [ThreadPool]: On list_MERCURIOS_DATA: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "list_MERCURIOS_DATA"} */
show terse schemas in database MERCURIOS_DATA
    limit 10000
[0m12:37:36.631652 [debug] [ThreadPool]: On list_MERCURIOS_DATA: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "list_MERCURIOS_DATA"} */
show terse schemas in database MERCURIOS_DATA
    limit 10000
[0m12:37:36.631837 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:37:36.632001 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:37:36.632154 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:37:40.563268 [debug] [ThreadPool]: SQL status: SUCCESS 31 in 3.931 seconds
[0m12:37:40.564916 [debug] [ThreadPool]: On list_MERCURIOS_DATA: Close
[0m12:37:44.133242 [debug] [ThreadPool]: SQL status: SUCCESS 31 in 7.501 seconds
[0m12:37:44.135211 [debug] [ThreadPool]: On list_MERCURIOS_DATA: Close
[0m12:37:48.485927 [debug] [ThreadPool]: SQL status: SUCCESS 31 in 11.854 seconds
[0m12:37:48.487054 [debug] [ThreadPool]: On list_MERCURIOS_DATA: Close
[0m12:37:48.580146 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_MERCURIOS_DATA, now list_MERCURIOS_DATA_staging_intermediate)
[0m12:37:48.580570 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_MERCURIOS_DATA, now list_MERCURIOS_DATA_staging_marts_inventory)
[0m12:37:48.580851 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_MERCURIOS_DATA, now list_MERCURIOS_DATA_staging_staging)
[0m12:37:48.586839 [debug] [ThreadPool]: Using snowflake connection "list_MERCURIOS_DATA_staging_intermediate"
[0m12:37:48.588372 [debug] [ThreadPool]: Using snowflake connection "list_MERCURIOS_DATA_staging_marts_inventory"
[0m12:37:48.589521 [debug] [ThreadPool]: Using snowflake connection "list_MERCURIOS_DATA_staging_staging"
[0m12:37:48.589695 [debug] [ThreadPool]: On list_MERCURIOS_DATA_staging_intermediate: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "list_MERCURIOS_DATA_staging_intermediate"} */
show objects in MERCURIOS_DATA.staging_intermediate limit 10000;
[0m12:37:48.589863 [debug] [ThreadPool]: On list_MERCURIOS_DATA_staging_marts_inventory: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "list_MERCURIOS_DATA_staging_marts_inventory"} */
show objects in MERCURIOS_DATA.staging_marts_inventory limit 10000;
[0m12:37:48.590019 [debug] [ThreadPool]: On list_MERCURIOS_DATA_staging_staging: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "list_MERCURIOS_DATA_staging_staging"} */
show objects in MERCURIOS_DATA.staging_staging limit 10000;
[0m12:37:48.590168 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:37:48.590306 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:37:48.590441 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:37:52.071895 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 3.481 seconds
[0m12:37:52.073365 [debug] [ThreadPool]: On list_MERCURIOS_DATA_staging_staging: Close
[0m12:37:55.583635 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 6.993 seconds
[0m12:37:55.584621 [debug] [ThreadPool]: On list_MERCURIOS_DATA_staging_intermediate: Close
[0m12:37:58.968095 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 10.378 seconds
[0m12:37:58.969117 [debug] [ThreadPool]: On list_MERCURIOS_DATA_staging_marts_inventory: Close
[0m12:37:59.090656 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f3784bb2-502a-4138-ad09-b401897ffcae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11ed186d0>]}
[0m12:37:59.091905 [debug] [Thread-7 (]: Began running node model.mercurios.stg_prohandel__articles
[0m12:37:59.092184 [debug] [Thread-8 (]: Began running node model.mercurios.stg_prohandel__inventory
[0m12:37:59.092653 [debug] [Thread-9 (]: Began running node model.mercurios.stg_prohandel__sales
[0m12:37:59.092472 [info ] [Thread-7 (]: 1 of 9 START sql view model staging_staging.stg_prohandel__articles ............ [RUN]
[0m12:37:59.093081 [info ] [Thread-8 (]: 2 of 9 START sql view model staging_staging.stg_prohandel__inventory ........... [RUN]
[0m12:37:59.093413 [info ] [Thread-9 (]: 3 of 9 START sql view model staging_staging.stg_prohandel__sales ............... [RUN]
[0m12:37:59.093678 [debug] [Thread-7 (]: Re-using an available connection from the pool (formerly list_MERCURIOS_DATA_staging_intermediate, now model.mercurios.stg_prohandel__articles)
[0m12:37:59.093932 [debug] [Thread-8 (]: Re-using an available connection from the pool (formerly list_MERCURIOS_DATA_staging_marts_inventory, now model.mercurios.stg_prohandel__inventory)
[0m12:37:59.094166 [debug] [Thread-9 (]: Re-using an available connection from the pool (formerly list_MERCURIOS_DATA_staging_staging, now model.mercurios.stg_prohandel__sales)
[0m12:37:59.094383 [debug] [Thread-7 (]: Began compiling node model.mercurios.stg_prohandel__articles
[0m12:37:59.094569 [debug] [Thread-8 (]: Began compiling node model.mercurios.stg_prohandel__inventory
[0m12:37:59.094741 [debug] [Thread-9 (]: Began compiling node model.mercurios.stg_prohandel__sales
[0m12:37:59.099710 [debug] [Thread-8 (]: Writing injected SQL for node "model.mercurios.stg_prohandel__inventory"
[0m12:37:59.101730 [debug] [Thread-7 (]: Writing injected SQL for node "model.mercurios.stg_prohandel__articles"
[0m12:37:59.103376 [debug] [Thread-9 (]: Writing injected SQL for node "model.mercurios.stg_prohandel__sales"
[0m12:37:59.104003 [debug] [Thread-8 (]: Began executing node model.mercurios.stg_prohandel__inventory
[0m12:37:59.109459 [debug] [Thread-9 (]: Began executing node model.mercurios.stg_prohandel__sales
[0m12:37:59.109728 [debug] [Thread-7 (]: Began executing node model.mercurios.stg_prohandel__articles
[0m12:37:59.120896 [debug] [Thread-8 (]: Writing runtime sql for node "model.mercurios.stg_prohandel__inventory"
[0m12:37:59.123162 [debug] [Thread-9 (]: Writing runtime sql for node "model.mercurios.stg_prohandel__sales"
[0m12:37:59.124929 [debug] [Thread-7 (]: Writing runtime sql for node "model.mercurios.stg_prohandel__articles"
[0m12:37:59.126189 [debug] [Thread-9 (]: Using snowflake connection "model.mercurios.stg_prohandel__sales"
[0m12:37:59.126974 [debug] [Thread-8 (]: Using snowflake connection "model.mercurios.stg_prohandel__inventory"
[0m12:37:59.128005 [debug] [Thread-7 (]: Using snowflake connection "model.mercurios.stg_prohandel__articles"
[0m12:37:59.128252 [debug] [Thread-9 (]: On model.mercurios.stg_prohandel__sales: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "node_id": "model.mercurios.stg_prohandel__sales"} */
create or replace   view MERCURIOS_DATA.staging_staging.stg_prohandel__sales
  
   as (
    with source as (
    select * from MERCURIOS_DATA.RAW.sale
),

renamed as (
    select
        sale_id,
        order_id,
        article_id,
        quantity,
        price,
        discount,
        
        -- Calculate net price and revenue
        (price - coalesce(discount, 0)) as net_price,
        (price - coalesce(discount, 0)) * quantity as revenue,
        
        -- Add sale type categorization
        case
            when discount is null or discount = 0 then 'Regular'
            when discount > 0 and discount < (price * 0.1) then 'Small Discount'
            when discount >= (price * 0.1) and discount < (price * 0.3) then 'Medium Discount'
            when discount >= (price * 0.3) then 'Large Discount'
            else 'Unknown'
        end as sale_type,
        
        sale_date,
        shop_id,
        tenant_id,
        
        -- Fivetran metadata
        _fivetran_synced,
        
        -- Add data quality flags
        case when quantity <= 0 then true else false end as is_invalid_quantity,
        case when price <= 0 then true else false end as is_invalid_price,
        case when discount > price then true else false end as is_discount_greater_than_price
    from source
)

select * from renamed
  );
[0m12:37:59.128563 [debug] [Thread-8 (]: On model.mercurios.stg_prohandel__inventory: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "node_id": "model.mercurios.stg_prohandel__inventory"} */
create or replace   view MERCURIOS_DATA.staging_staging.stg_prohandel__inventory
  
   as (
    with source as (
    select * from MERCURIOS_DATA.RAW.inventory
),

renamed as (
    select
        inventory_id,
        article_id,
        warehouse_id,
        quantity,
        
        -- Add stock level categorization
        case
            when quantity <= 0 then 'Out of Stock'
            when quantity <= 5 then 'Low Stock'
            when quantity <= 20 then 'Medium Stock'
            when quantity > 20 then 'High Stock'
            else 'Unknown'
        end as stock_level,
        
        -- Add reorder flag
        case
            when quantity <= 5 then true
            else false
        end as needs_reorder,
        
        location,
        last_count_date,
        is_available,
        tenant_id,
        
        -- Fivetran metadata
        _fivetran_synced,
        
        -- Add data quality flags
        case when quantity < 0 then true else false end as is_negative_quantity
    from source
)

select * from renamed
  );
[0m12:37:59.128912 [debug] [Thread-7 (]: On model.mercurios.stg_prohandel__articles: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "node_id": "model.mercurios.stg_prohandel__articles"} */
create or replace   view MERCURIOS_DATA.staging_staging.stg_prohandel__articles
  
   as (
    with source as (
    select * from MERCURIOS_DATA.RAW.article
),

renamed as (
    select
        article_id,
        article_number,
        description,
        category,
        subcategory,
        brand,
        supplier,
        purchase_price,
        retail_price,
        min_stock_level,
        max_stock_level,
        reorder_point,
        lead_time_days,
        is_active,
        
        -- Calculate profit margin
        (retail_price - purchase_price) as profit_margin,
        case 
            when (purchase_price > 0) then ((retail_price - purchase_price) / purchase_price) * 100 
            else null 
        end as profit_margin_percent,
        
        -- Add price tier categorization
        case
            when retail_price < 10 then 'Budget'
            when retail_price >= 10 and retail_price < 50 then 'Standard'
            when retail_price >= 50 and retail_price < 100 then 'Premium'
            when retail_price >= 100 then 'Luxury'
            else 'Uncategorized'
        end as price_tier,
        
        created_at,
        updated_at,
        tenant_id,
        
        -- Fivetran metadata
        _fivetran_synced,
        
        -- Add data quality flags
        case when description is null or description = '' then true else false end as is_missing_description,
        case when purchase_price is null or purchase_price = 0 then true else false end as is_missing_purchase_price,
        case when retail_price is null or retail_price = 0 then true else false end as is_missing_retail_price
    from source
)

select * from renamed
  );
[0m12:37:59.129198 [debug] [Thread-9 (]: Opening a new connection, currently in state closed
[0m12:37:59.129392 [debug] [Thread-8 (]: Opening a new connection, currently in state closed
[0m12:37:59.129582 [debug] [Thread-7 (]: Opening a new connection, currently in state closed
[0m12:38:02.745638 [debug] [Thread-8 (]: SQL status: SUCCESS 1 in 3.616 seconds
[0m12:38:02.766275 [debug] [Thread-8 (]: On model.mercurios.stg_prohandel__inventory: Close
[0m12:38:02.868484 [debug] [Thread-8 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f3784bb2-502a-4138-ad09-b401897ffcae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b7f5710>]}
[0m12:38:02.868993 [info ] [Thread-8 (]: 2 of 9 OK created sql view model staging_staging.stg_prohandel__inventory ...... [[32mSUCCESS 1[0m in 3.77s]
[0m12:38:02.869321 [debug] [Thread-8 (]: Finished running node model.mercurios.stg_prohandel__inventory
[0m12:38:06.430152 [debug] [Thread-7 (]: SQL status: SUCCESS 1 in 7.300 seconds
[0m12:38:06.432481 [debug] [Thread-7 (]: On model.mercurios.stg_prohandel__articles: Close
[0m12:38:06.619038 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f3784bb2-502a-4138-ad09-b401897ffcae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1193d65d0>]}
[0m12:38:06.619534 [info ] [Thread-7 (]: 1 of 9 OK created sql view model staging_staging.stg_prohandel__articles ....... [[32mSUCCESS 1[0m in 7.53s]
[0m12:38:06.619876 [debug] [Thread-7 (]: Finished running node model.mercurios.stg_prohandel__articles
[0m12:38:09.917819 [debug] [Thread-9 (]: SQL status: SUCCESS 1 in 10.788 seconds
[0m12:38:09.919271 [debug] [Thread-9 (]: On model.mercurios.stg_prohandel__sales: Close
[0m12:38:10.026853 [debug] [Thread-9 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f3784bb2-502a-4138-ad09-b401897ffcae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11920abd0>]}
[0m12:38:10.027439 [info ] [Thread-9 (]: 3 of 9 OK created sql view model staging_staging.stg_prohandel__sales .......... [[32mSUCCESS 1[0m in 10.93s]
[0m12:38:10.027811 [debug] [Thread-9 (]: Finished running node model.mercurios.stg_prohandel__sales
[0m12:38:10.028383 [debug] [Thread-10 ]: Began running node model.mercurios.demand_forecast
[0m12:38:10.028737 [debug] [Thread-8 (]: Began running node model.mercurios.int_inventory_with_metrics
[0m12:38:10.029104 [info ] [Thread-10 ]: 4 of 9 START sql table model staging_marts_inventory.demand_forecast ........... [RUN]
[0m12:38:10.029459 [info ] [Thread-8 (]: 5 of 9 START sql view model staging_intermediate.int_inventory_with_metrics .... [RUN]
[0m12:38:10.029811 [debug] [Thread-10 ]: Acquiring new snowflake connection 'model.mercurios.demand_forecast'
[0m12:38:10.030051 [debug] [Thread-8 (]: Re-using an available connection from the pool (formerly model.mercurios.stg_prohandel__inventory, now model.mercurios.int_inventory_with_metrics)
[0m12:38:10.030291 [debug] [Thread-10 ]: Began compiling node model.mercurios.demand_forecast
[0m12:38:10.030633 [debug] [Thread-8 (]: Began compiling node model.mercurios.int_inventory_with_metrics
[0m12:38:10.034245 [debug] [Thread-10 ]: Writing injected SQL for node "model.mercurios.demand_forecast"
[0m12:38:10.036840 [debug] [Thread-8 (]: Writing injected SQL for node "model.mercurios.int_inventory_with_metrics"
[0m12:38:10.037835 [debug] [Thread-10 ]: Began executing node model.mercurios.demand_forecast
[0m12:38:10.043401 [debug] [Thread-8 (]: Began executing node model.mercurios.int_inventory_with_metrics
[0m12:38:10.052163 [debug] [Thread-10 ]: Writing runtime sql for node "model.mercurios.demand_forecast"
[0m12:38:10.054070 [debug] [Thread-8 (]: Writing runtime sql for node "model.mercurios.int_inventory_with_metrics"
[0m12:38:10.057005 [debug] [Thread-8 (]: Using snowflake connection "model.mercurios.int_inventory_with_metrics"
[0m12:38:10.062192 [debug] [Thread-10 ]: Using snowflake connection "model.mercurios.demand_forecast"
[0m12:38:10.062801 [debug] [Thread-8 (]: On model.mercurios.int_inventory_with_metrics: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "node_id": "model.mercurios.int_inventory_with_metrics"} */
create or replace   view MERCURIOS_DATA.staging_intermediate.int_inventory_with_metrics
  
   as (
    with inventory as (
    select * from MERCURIOS_DATA.staging_staging.stg_prohandel__inventory
),

articles as (
    select * from MERCURIOS_DATA.staging_staging.stg_prohandel__articles
),

sales_last_30_days as (
    select
        article_id,
        sum(quantity) as quantity_sold_30d,
        count(distinct sale_id) as num_orders_30d
    from MERCURIOS_DATA.staging_staging.stg_prohandel__sales
    where sale_date >= dateadd('day', -30, current_date())
    group by article_id
),

sales_last_90_days as (
    select
        article_id,
        sum(quantity) as quantity_sold_90d,
        count(distinct sale_id) as num_orders_90d
    from MERCURIOS_DATA.staging_staging.stg_prohandel__sales
    where sale_date >= dateadd('day', -90, current_date())
    group by article_id
),

inventory_with_metrics as (
    select
        -- Inventory fields
        i.inventory_id,
        i.article_id,
        i.warehouse_id,
        i.quantity,
        i.stock_level,
        i.needs_reorder,
        i.location,
        i.last_count_date,
        i.is_available,
        i.tenant_id,
        
        -- Article fields
        a.article_number,
        a.description,
        a.category,
        a.subcategory,
        a.brand,
        a.supplier,
        a.purchase_price,
        a.retail_price,
        a.min_stock_level,
        a.max_stock_level,
        a.reorder_point,
        a.lead_time_days,
        a.profit_margin,
        a.profit_margin_percent,
        a.price_tier,
        
        -- Sales metrics
        coalesce(s30.quantity_sold_30d, 0) as quantity_sold_30d,
        coalesce(s30.num_orders_30d, 0) as num_orders_30d,
        coalesce(s90.quantity_sold_90d, 0) as quantity_sold_90d,
        coalesce(s90.num_orders_90d, 0) as num_orders_90d,
        
        -- Calculate days of supply
        case
            when coalesce(s30.quantity_sold_30d, 0) > 0 then 
                (i.quantity / (s30.quantity_sold_30d / 30.0))
            else null
        end as days_of_supply_30d,
        
        case
            when coalesce(s90.quantity_sold_90d, 0) > 0 then 
                (i.quantity / (s90.quantity_sold_90d / 90.0))
            else null
        end as days_of_supply_90d,
        
        -- Calculate stock turnover rate (annualized)
        case
            when i.quantity > 0 and coalesce(s30.quantity_sold_30d, 0) > 0 then 
                (s30.quantity_sold_30d * (365.0 / 30.0)) / i.quantity
            else null
        end as turnover_rate_30d,
        
        case
            when i.quantity > 0 and coalesce(s90.quantity_sold_90d, 0) > 0 then 
                (s90.quantity_sold_90d * (365.0 / 90.0)) / i.quantity
            else null
        end as turnover_rate_90d,
        
        -- Calculate inventory value
        i.quantity * a.purchase_price as inventory_value,
        i.quantity * a.retail_price as potential_revenue,
        
        -- Calculate excess inventory flag
        case
            when coalesce(s90.quantity_sold_90d, 0) = 0 and i.quantity > 10 then true
            when coalesce(s90.quantity_sold_90d, 0) > 0 and 
                 (i.quantity / (s90.quantity_sold_90d / 90.0)) > 180 then true
            else false
        end as is_excess_inventory,
        
        -- Calculate slow-moving inventory flag
        case
            when coalesce(s90.quantity_sold_90d, 0) = 0 and i.quantity > 0 then true
            when coalesce(s90.quantity_sold_90d, 0) > 0 and 
                 (s90.quantity_sold_90d * (365.0 / 90.0)) / i.quantity < 1 then true
            else false
        end as is_slow_moving,
        
        -- Calculate stockout risk flag
        case
            when i.quantity = 0 then 'Stockout'
            when coalesce(s30.quantity_sold_30d, 0) > 0 and 
                 (i.quantity / (s30.quantity_sold_30d / 30.0)) < 7 then 'Critical'
            when coalesce(s30.quantity_sold_30d, 0) > 0 and 
                 (i.quantity / (s30.quantity_sold_30d / 30.0)) < 14 then 'Warning'
            else 'Normal'
        end as stockout_risk,
        
        -- Fivetran metadata
        i._fivetran_synced
    from inventory i
    left join articles a on i.article_id = a.article_id
    left join sales_last_30_days s30 on i.article_id = s30.article_id
    left join sales_last_90_days s90 on i.article_id = s90.article_id
)

select * from inventory_with_metrics
  );
[0m12:38:10.063564 [debug] [Thread-10 ]: On model.mercurios.demand_forecast: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "node_id": "model.mercurios.demand_forecast"} */
create or replace transient table MERCURIOS_DATA.staging_marts_inventory.demand_forecast
         as
        (select * from (
              

with sales_history as (
    select
        s.article_id,
        a.article_number,
        a.description,
        a.category,
        a.subcategory,
        a.brand,
        a.supplier,
        a.price_tier,
        s.sale_date,
        sum(s.quantity) as quantity_sold,
        count(distinct s.sale_id) as number_of_sales,
        sum(s.revenue) as revenue
    from MERCURIOS_DATA.staging_staging.stg_prohandel__sales s
    join MERCURIOS_DATA.staging_staging.stg_prohandel__articles a on s.article_id = a.article_id
    where s.sale_date >= dateadd('day', -365, current_date())
    group by 
        s.article_id,
        a.article_number,
        a.description,
        a.category,
        a.subcategory,
        a.brand,
        a.supplier,
        a.price_tier,
        s.sale_date
),

-- Calculate daily, weekly, and monthly aggregates
daily_sales as (
    select
        article_id,
        article_number,
        description,
        category,
        subcategory,
        brand,
        supplier,
        price_tier,
        sale_date,
        quantity_sold,
        number_of_sales,
        revenue,
        -- Extract date parts for seasonality analysis
        dayofweek(sale_date) as day_of_week,
        dayofmonth(sale_date) as day_of_month,
        month(sale_date) as month,
        quarter(sale_date) as quarter
    from sales_history
),

weekly_sales as (
    select
        article_id,
        article_number,
        description,
        category,
        subcategory,
        brand,
        supplier,
        price_tier,
        date_trunc('week', sale_date) as week_start_date,
        sum(quantity_sold) as weekly_quantity_sold,
        sum(number_of_sales) as weekly_number_of_sales,
        sum(revenue) as weekly_revenue,
        avg(quantity_sold) as avg_daily_quantity_sold,
        week(sale_date) as week_of_year
    from daily_sales
    group by 
        article_id,
        article_number,
        description,
        category,
        subcategory,
        brand,
        supplier,
        price_tier,
        week_start_date,
        week_of_year
),

monthly_sales as (
    select
        article_id,
        article_number,
        description,
        category,
        subcategory,
        brand,
        supplier,
        price_tier,
        date_trunc('month', sale_date) as month_start_date,
        sum(quantity_sold) as monthly_quantity_sold,
        sum(number_of_sales) as monthly_number_of_sales,
        sum(revenue) as monthly_revenue,
        avg(quantity_sold) as avg_daily_quantity_sold,
        month(sale_date) as month_of_year
    from daily_sales
    group by 
        article_id,
        article_number,
        description,
        category,
        subcategory,
        brand,
        supplier,
        price_tier,
        month_start_date,
        month_of_year
),

-- Calculate moving averages and trends
moving_averages as (
    select
        article_id,
        sale_date,
        quantity_sold,
        
        -- Calculate 7-day moving average
        avg(quantity_sold) over (
            partition by article_id 
            order by sale_date 
            rows between 6 preceding and current row
        ) as ma_7_day,
        
        -- Calculate 30-day moving average
        avg(quantity_sold) over (
            partition by article_id 
            order by sale_date 
            rows between 29 preceding and current row
        ) as ma_30_day,
        
        -- Calculate 90-day moving average
        avg(quantity_sold) over (
            partition by article_id 
            order by sale_date 
            rows between 89 preceding and current row
        ) as ma_90_day
    from daily_sales
),

-- Calculate seasonality factors
seasonality as (
    select
        article_id,
        day_of_week,
        avg(quantity_sold) as avg_qty_by_day_of_week,
        
        -- Calculate day of week seasonality factor
        avg(quantity_sold) / nullif(
            avg(avg(quantity_sold)) over (partition by article_id),
            0
        ) as day_of_week_factor
    from daily_sales
    group by article_id, day_of_week
),

monthly_seasonality as (
    select
        article_id,
        month_of_year,
        avg(monthly_quantity_sold) as avg_qty_by_month,
        
        -- Calculate month seasonality factor
        avg(monthly_quantity_sold) / nullif(
            avg(avg(monthly_quantity_sold)) over (partition by article_id),
            0
        ) as month_factor
    from monthly_sales
    group by article_id, month_of_year
),

-- Calculate recent sales statistics for forecasting
recent_stats as (
    select
        article_id,
        
        -- Last 30 days
        sum(case when sale_date >= dateadd('day', -30, current_date()) then quantity_sold else 0 end) as qty_last_30d,
        avg(case when sale_date >= dateadd('day', -30, current_date()) then quantity_sold else null end) as avg_daily_qty_last_30d,
        
        -- Last 90 days
        sum(case when sale_date >= dateadd('day', -90, current_date()) then quantity_sold else 0 end) as qty_last_90d,
        avg(case when sale_date >= dateadd('day', -90, current_date()) then quantity_sold else null end) as avg_daily_qty_last_90d,
        
        -- Last 365 days
        sum(quantity_sold) as qty_last_365d,
        avg(quantity_sold) as avg_daily_qty_last_365d,
        
        -- Calculate trend (comparing last 30 days to previous 30 days)
        sum(case when sale_date >= dateadd('day', -30, current_date()) then quantity_sold else 0 end) /
        nullif(sum(case when sale_date >= dateadd('day', -60, current_date()) and 
                        sale_date < dateadd('day', -30, current_date()) then quantity_sold else 0 end), 0) - 1 as trend_factor
    from daily_sales
    group by article_id
),

-- Generate forecast dates (simplified without dbt_utils for now)
forecast_dates as (
    select dateadd('day', seq4(), current_date()) as date_day
    from table(generator(rowcount => 90))
),

-- Create the final forecast
demand_forecast as (
    select
        a.article_id,
        a.article_number,
        a.description,
        a.category,
        a.subcategory,
        a.brand,
        a.supplier,
        a.price_tier,
        d.date_day as forecast_date,
        
        -- Extract date parts for applying seasonality
        dayofweek(d.date_day) as day_of_week,
        month(d.date_day) as month_of_year,
        
        -- Base forecast using recent average
        rs.avg_daily_qty_last_90d as base_forecast,
        
        -- Apply trend factor (capped to prevent extreme values)
        case
            when rs.trend_factor > 0.5 then 1.5
            when rs.trend_factor < -0.5 then 0.5
            else 1 + coalesce(rs.trend_factor, 0)
        end as applied_trend_factor,
        
        -- Apply day of week seasonality
        coalesce(s.day_of_week_factor, 1) as day_of_week_factor,
        
        -- Apply monthly seasonality
        coalesce(ms.month_factor, 1) as month_factor,
        
        -- Calculate final forecast
        round(
            rs.avg_daily_qty_last_90d * 
            case
                when rs.trend_factor > 0.5 then 1.5
                when rs.trend_factor < -0.5 then 0.5
                else 1 + coalesce(rs.trend_factor, 0)
            end *
            coalesce(s.day_of_week_factor, 1) *
            coalesce(ms.month_factor, 1),
            2
        ) as forecasted_daily_demand,
        
        -- Add cumulative forecast
        sum(
            round(
                rs.avg_daily_qty_last_90d * 
                case
                    when rs.trend_factor > 0.5 then 1.5
                    when rs.trend_factor < -0.5 then 0.5
                    else 1 + coalesce(rs.trend_factor, 0)
                end *
                coalesce(s.day_of_week_factor, 1) *
                coalesce(ms.month_factor, 1),
                2
            )
        ) over (
            partition by a.article_id 
            order by d.date_day 
            rows between unbounded preceding and current row
        ) as cumulative_forecasted_demand,
        
        -- Historical sales statistics
        rs.avg_daily_qty_last_30d,
        rs.avg_daily_qty_last_90d,
        rs.avg_daily_qty_last_365d,
        rs.qty_last_30d,
        rs.qty_last_90d,
        rs.qty_last_365d,
        
        -- Add confidence level based on data quality
        case
            when rs.qty_last_365d > 100 and rs.avg_daily_qty_last_30d > 0 then 'High'
            when rs.qty_last_90d > 30 and rs.avg_daily_qty_last_30d > 0 then 'Medium'
            when rs.qty_last_30d > 0 then 'Low'
            else 'Very Low'
        end as forecast_confidence,
        
        -- Generate forecast timestamp
        current_timestamp() as generated_at,
        
        -- Add tenant_id
        a.tenant_id
        
    from MERCURIOS_DATA.staging_staging.stg_prohandel__articles a
    cross join forecast_dates d
    left join recent_stats rs on a.article_id = rs.article_id
    left join seasonality s on a.article_id = s.article_id and dayofweek(d.date_day) = s.day_of_week
    left join monthly_seasonality ms on a.article_id = ms.article_id and month(d.date_day) = ms.month_of_year
    where rs.avg_daily_qty_last_90d > 0  -- Only forecast for items with recent sales
)

select * from demand_forecast
              ) order by (article_id, forecast_date)
        );
[0m12:38:10.064082 [debug] [Thread-8 (]: Opening a new connection, currently in state closed
[0m12:38:10.064408 [debug] [Thread-10 ]: Opening a new connection, currently in state init
[0m12:38:13.847835 [debug] [Thread-8 (]: SQL status: SUCCESS 1 in 3.784 seconds
[0m12:38:13.850032 [debug] [Thread-8 (]: On model.mercurios.int_inventory_with_metrics: Close
[0m12:38:13.984868 [debug] [Thread-8 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f3784bb2-502a-4138-ad09-b401897ffcae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1267d6cd0>]}
[0m12:38:13.985459 [info ] [Thread-8 (]: 5 of 9 OK created sql view model staging_intermediate.int_inventory_with_metrics  [[32mSUCCESS 1[0m in 3.95s]
[0m12:38:13.985819 [debug] [Thread-8 (]: Finished running node model.mercurios.int_inventory_with_metrics
[0m12:38:13.986174 [debug] [Thread-9 (]: Began running node model.mercurios.inventory_status
[0m12:38:13.986417 [info ] [Thread-9 (]: 6 of 9 START sql table model staging_marts_inventory.inventory_status .......... [RUN]
[0m12:38:13.986706 [debug] [Thread-9 (]: Re-using an available connection from the pool (formerly model.mercurios.stg_prohandel__sales, now model.mercurios.inventory_status)
[0m12:38:13.986928 [debug] [Thread-9 (]: Began compiling node model.mercurios.inventory_status
[0m12:38:13.989406 [debug] [Thread-9 (]: Writing injected SQL for node "model.mercurios.inventory_status"
[0m12:38:13.990145 [debug] [Thread-9 (]: Began executing node model.mercurios.inventory_status
[0m12:38:13.992550 [debug] [Thread-9 (]: Writing runtime sql for node "model.mercurios.inventory_status"
[0m12:38:13.994790 [debug] [Thread-9 (]: Using snowflake connection "model.mercurios.inventory_status"
[0m12:38:13.995214 [debug] [Thread-9 (]: On model.mercurios.inventory_status: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "node_id": "model.mercurios.inventory_status"} */
create or replace transient table MERCURIOS_DATA.staging_marts_inventory.inventory_status
         as
        (select * from (
              

with inventory_metrics as (
    select * from MERCURIOS_DATA.staging_intermediate.int_inventory_with_metrics
),

inventory_status as (
    select
        -- Primary keys and identifiers
        inventory_id,
        article_id,
        warehouse_id,
        article_number,
        
        -- Article details
        description,
        category,
        subcategory,
        brand,
        supplier,
        price_tier,
        
        -- Inventory metrics
        quantity,
        stock_level,
        needs_reorder,
        days_of_supply_30d,
        days_of_supply_90d,
        turnover_rate_30d,
        turnover_rate_90d,
        stockout_risk,
        
        -- Sales metrics
        quantity_sold_30d,
        quantity_sold_90d,
        num_orders_30d,
        num_orders_90d,
        
        -- Financial metrics
        purchase_price,
        retail_price,
        profit_margin,
        profit_margin_percent,
        inventory_value,
        potential_revenue,
        
        -- Flags
        is_excess_inventory,
        is_slow_moving,
        
        -- Calculated fields
        case
            when stockout_risk = 'Stockout' then 1
            when stockout_risk = 'Critical' then 2
            when stockout_risk = 'Warning' then 3
            else 4
        end as stockout_risk_priority,
        
        case
            when is_excess_inventory then inventory_value else 0
        end as excess_inventory_value,
        
        case
            when is_slow_moving then inventory_value else 0
        end as slow_moving_value,
        
        -- Reorder quantity recommendation
        case
            -- If no sales, recommend minimum stock
            when quantity_sold_90d = 0 then 
                greatest(5 - quantity, 0)
            -- If sales exist, calculate based on days of supply target
            when days_of_supply_90d is not null then
                greatest(
                    ceiling((quantity_sold_90d / 90.0) * 30) - quantity, -- 30 days supply
                    0
                )
            else 0
        end as recommended_reorder_quantity,
        
        -- ABC Analysis (based on sales volume and value)
        case
            when quantity_sold_90d > 0 and 
                 quantity_sold_90d * retail_price >= 
                 percentile_cont(0.8) within group (order by nullif(quantity_sold_90d * retail_price, 0)) 
                 over (partition by warehouse_id) then 'A'
            when quantity_sold_90d > 0 and 
                 quantity_sold_90d * retail_price >= 
                 percentile_cont(0.5) within group (order by nullif(quantity_sold_90d * retail_price, 0)) 
                 over (partition by warehouse_id) then 'B'
            when quantity_sold_90d > 0 then 'C'
            else 'D' -- No sales
        end as abc_class,
        
        -- Last update timestamp
        _fivetran_synced as last_updated
    from inventory_metrics
)

select * from inventory_status
              ) order by (warehouse_id, stockout_risk)
        );
[0m12:38:13.995583 [debug] [Thread-9 (]: Opening a new connection, currently in state closed
[0m12:38:18.175834 [debug] [Thread-10 ]: SQL status: SUCCESS 1 in 8.111 seconds
[0m12:38:18.176879 [debug] [Thread-10 ]: Using snowflake connection "model.mercurios.demand_forecast"
[0m12:38:18.177567 [debug] [Thread-10 ]: On model.mercurios.demand_forecast: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "node_id": "model.mercurios.demand_forecast"} */
alter  table MERCURIOS_DATA.staging_marts_inventory.demand_forecast cluster by (article_id, forecast_date);
[0m12:38:18.358525 [debug] [Thread-10 ]: SQL status: SUCCESS 1 in 0.180 seconds
[0m12:38:18.359984 [debug] [Thread-10 ]: On model.mercurios.demand_forecast: Close
[0m12:38:18.460613 [debug] [Thread-10 ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f3784bb2-502a-4138-ad09-b401897ffcae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1193133d0>]}
[0m12:38:18.461276 [info ] [Thread-10 ]: 4 of 9 OK created sql table model staging_marts_inventory.demand_forecast ...... [[32mSUCCESS 1[0m in 8.43s]
[0m12:38:18.461701 [debug] [Thread-10 ]: Finished running node model.mercurios.demand_forecast
[0m12:38:20.320803 [debug] [Thread-9 (]: Snowflake adapter: Snowflake query id: 01baef7a-0204-2b29-0003-4bde00066d3e
[0m12:38:20.321197 [debug] [Thread-9 (]: Snowflake adapter: Snowflake error: 002140 (42601): SQL compilation error:
Unknown function CEILING
[0m12:38:20.321663 [debug] [Thread-9 (]: On model.mercurios.inventory_status: Close
[0m12:38:20.430121 [debug] [Thread-9 (]: Database Error in model inventory_status (models/marts/inventory/inventory_status.sql)
  002140 (42601): SQL compilation error:
  Unknown function CEILING
  compiled code at target/run/mercurios/models/marts/inventory/inventory_status.sql
[0m12:38:20.430753 [debug] [Thread-9 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f3784bb2-502a-4138-ad09-b401897ffcae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x126440d90>]}
[0m12:38:20.431357 [error] [Thread-9 (]: 6 of 9 ERROR creating sql table model staging_marts_inventory.inventory_status . [[31mERROR[0m in 6.44s]
[0m12:38:20.431848 [debug] [Thread-9 (]: Finished running node model.mercurios.inventory_status
[0m12:38:20.432233 [debug] [Thread-13 ]: Marking all children of 'model.mercurios.inventory_status' to be skipped because of status 'error'.  Reason: Database Error in model inventory_status (models/marts/inventory/inventory_status.sql)
  002140 (42601): SQL compilation error:
  Unknown function CEILING
  compiled code at target/run/mercurios/models/marts/inventory/inventory_status.sql.
[0m12:38:20.433410 [debug] [Thread-8 (]: Began running node model.mercurios.reorder_recommendations
[0m12:38:20.433788 [debug] [Thread-7 (]: Began running node model.mercurios.stock_levels
[0m12:38:20.434117 [info ] [Thread-8 (]: 7 of 9 SKIP relation staging_marts_inventory.reorder_recommendations ........... [[33mSKIP[0m]
[0m12:38:20.434542 [info ] [Thread-7 (]: 8 of 9 SKIP relation staging_marts_inventory.stock_levels ...................... [[33mSKIP[0m]
[0m12:38:20.434875 [debug] [Thread-8 (]: Finished running node model.mercurios.reorder_recommendations
[0m12:38:20.435187 [debug] [Thread-7 (]: Finished running node model.mercurios.stock_levels
[0m12:38:20.435677 [debug] [Thread-9 (]: Began running node model.mercurios.tenant_inventory_dashboard
[0m12:38:20.436113 [info ] [Thread-9 (]: 9 of 9 SKIP relation staging_marts_inventory.tenant_inventory_dashboard ........ [[33mSKIP[0m]
[0m12:38:20.436499 [debug] [Thread-9 (]: Finished running node model.mercurios.tenant_inventory_dashboard
[0m12:38:20.437856 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:38:20.438192 [debug] [MainThread]: Connection 'model.mercurios.stg_prohandel__articles' was properly closed.
[0m12:38:20.438511 [debug] [MainThread]: Connection 'model.mercurios.int_inventory_with_metrics' was properly closed.
[0m12:38:20.438725 [debug] [MainThread]: Connection 'model.mercurios.inventory_status' was properly closed.
[0m12:38:20.438921 [debug] [MainThread]: Connection 'model.mercurios.demand_forecast' was properly closed.
[0m12:38:20.439243 [info ] [MainThread]: 
[0m12:38:20.439492 [info ] [MainThread]: Finished running 5 table models, 4 view models in 0 hours 0 minutes and 43.85 seconds (43.85s).
[0m12:38:20.440365 [debug] [MainThread]: Command end result
[0m12:38:20.461657 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/target/manifest.json
[0m12:38:20.463190 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/target/semantic_manifest.json
[0m12:38:20.467024 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/target/run_results.json
[0m12:38:20.467261 [info ] [MainThread]: 
[0m12:38:20.467475 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m12:38:20.467644 [info ] [MainThread]: 
[0m12:38:20.467853 [error] [MainThread]:   Database Error in model inventory_status (models/marts/inventory/inventory_status.sql)
  002140 (42601): SQL compilation error:
  Unknown function CEILING
  compiled code at target/run/mercurios/models/marts/inventory/inventory_status.sql
[0m12:38:20.468020 [info ] [MainThread]: 
[0m12:38:20.468195 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=1 SKIP=3 TOTAL=9
[0m12:38:20.469990 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 45.82938, "process_in_blocks": "0", "process_kernel_time": 1.301998, "process_mem_max_rss": "198082560", "process_out_blocks": "0", "process_user_time": 3.934843}
[0m12:38:20.470294 [debug] [MainThread]: Command `dbt run` failed at 12:38:20.470249 after 45.83 seconds
[0m12:38:20.470545 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c14a350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aade050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1036c5c50>]}
[0m12:38:20.470757 [debug] [MainThread]: Flushing usage events
[0m12:38:21.164318 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:38:54.441360 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107e30f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11374c450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11374c190>]}


============================== 12:38:54.445032 | 3ab8784c-1c6b-4841-b9ce-611fdb97d8be ==============================
[0m12:38:54.445032 [info ] [MainThread]: Running with dbt=1.9.2
[0m12:38:54.445400 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/logs', 'profiles_dir': '/Users/juliusrechenbach/API ProHandelTest/dbt_mercurios', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m12:38:55.150123 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '3ab8784c-1c6b-4841-b9ce-611fdb97d8be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11379a5d0>]}
[0m12:38:55.186137 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '3ab8784c-1c6b-4841-b9ce-611fdb97d8be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112471610>]}
[0m12:38:55.186933 [info ] [MainThread]: Registered adapter: snowflake=1.9.1
[0m12:38:55.271239 [debug] [MainThread]: checksum: 12b12750b70de726cfd89136b8e24afc3f3e77597a97bff40ab7e5f9b39d5e18, vars: {}, profile: , target: , version: 1.9.2
[0m12:38:55.356475 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m12:38:55.356929 [debug] [MainThread]: Partial parsing: updated file: mercurios://models/marts/inventory/inventory_status.sql
[0m12:38:55.558773 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.mercurios.marts.sales
[0m12:38:55.565708 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3ab8784c-1c6b-4841-b9ce-611fdb97d8be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1214219d0>]}
[0m12:38:55.612769 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/target/manifest.json
[0m12:38:55.615336 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/target/semantic_manifest.json
[0m12:38:55.630174 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3ab8784c-1c6b-4841-b9ce-611fdb97d8be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1135d9d50>]}
[0m12:38:55.630521 [info ] [MainThread]: Found 9 models, 17 data tests, 3 sources, 586 macros
[0m12:38:55.630715 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3ab8784c-1c6b-4841-b9ce-611fdb97d8be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1211a9a10>]}
[0m12:38:55.631860 [info ] [MainThread]: 
[0m12:38:55.632070 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:38:55.632223 [info ] [MainThread]: 
[0m12:38:55.632483 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m12:38:55.634866 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_MERCURIOS_DATA'
[0m12:38:55.641839 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_MERCURIOS_DATA'
[0m12:38:55.642337 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_MERCURIOS_DATA'
[0m12:38:55.670509 [debug] [ThreadPool]: Using snowflake connection "list_MERCURIOS_DATA"
[0m12:38:55.670830 [debug] [ThreadPool]: Using snowflake connection "list_MERCURIOS_DATA"
[0m12:38:55.671083 [debug] [ThreadPool]: Using snowflake connection "list_MERCURIOS_DATA"
[0m12:38:55.671247 [debug] [ThreadPool]: On list_MERCURIOS_DATA: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "list_MERCURIOS_DATA"} */
show terse schemas in database MERCURIOS_DATA
    limit 10000
[0m12:38:55.671436 [debug] [ThreadPool]: On list_MERCURIOS_DATA: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "list_MERCURIOS_DATA"} */
show terse schemas in database MERCURIOS_DATA
    limit 10000
[0m12:38:55.671605 [debug] [ThreadPool]: On list_MERCURIOS_DATA: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "list_MERCURIOS_DATA"} */
show terse schemas in database MERCURIOS_DATA
    limit 10000
[0m12:38:55.671789 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:38:55.671945 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:38:55.672095 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:38:59.494930 [debug] [ThreadPool]: SQL status: SUCCESS 31 in 3.823 seconds
[0m12:38:59.496320 [debug] [ThreadPool]: On list_MERCURIOS_DATA: Close
[0m12:39:02.986285 [debug] [ThreadPool]: SQL status: SUCCESS 31 in 7.314 seconds
[0m12:39:02.988420 [debug] [ThreadPool]: On list_MERCURIOS_DATA: Close
[0m12:39:07.162630 [debug] [ThreadPool]: SQL status: SUCCESS 31 in 11.491 seconds
[0m12:39:07.163909 [debug] [ThreadPool]: On list_MERCURIOS_DATA: Close
[0m12:39:07.292085 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_MERCURIOS_DATA, now list_MERCURIOS_DATA_staging_staging)
[0m12:39:07.292510 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_MERCURIOS_DATA, now list_MERCURIOS_DATA_staging_marts_inventory)
[0m12:39:07.292826 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_MERCURIOS_DATA, now list_MERCURIOS_DATA_staging_intermediate)
[0m12:39:07.299304 [debug] [ThreadPool]: Using snowflake connection "list_MERCURIOS_DATA_staging_staging"
[0m12:39:07.301746 [debug] [ThreadPool]: Using snowflake connection "list_MERCURIOS_DATA_staging_marts_inventory"
[0m12:39:07.303326 [debug] [ThreadPool]: Using snowflake connection "list_MERCURIOS_DATA_staging_intermediate"
[0m12:39:07.303616 [debug] [ThreadPool]: On list_MERCURIOS_DATA_staging_staging: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "list_MERCURIOS_DATA_staging_staging"} */
show objects in MERCURIOS_DATA.staging_staging limit 10000;
[0m12:39:07.303836 [debug] [ThreadPool]: On list_MERCURIOS_DATA_staging_marts_inventory: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "list_MERCURIOS_DATA_staging_marts_inventory"} */
show objects in MERCURIOS_DATA.staging_marts_inventory limit 10000;
[0m12:39:07.304025 [debug] [ThreadPool]: On list_MERCURIOS_DATA_staging_intermediate: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "list_MERCURIOS_DATA_staging_intermediate"} */
show objects in MERCURIOS_DATA.staging_intermediate limit 10000;
[0m12:39:07.304253 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:39:07.304409 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:39:07.304564 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:39:11.682377 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 4.378 seconds
[0m12:39:11.683748 [debug] [ThreadPool]: On list_MERCURIOS_DATA_staging_intermediate: Close
[0m12:39:15.333797 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 8.029 seconds
[0m12:39:15.334948 [debug] [ThreadPool]: On list_MERCURIOS_DATA_staging_staging: Close
[0m12:39:18.861301 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 11.557 seconds
[0m12:39:18.862547 [debug] [ThreadPool]: On list_MERCURIOS_DATA_staging_marts_inventory: Close
[0m12:39:18.989034 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3ab8784c-1c6b-4841-b9ce-611fdb97d8be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1211a9950>]}
[0m12:39:18.990134 [debug] [Thread-7 (]: Began running node model.mercurios.stg_prohandel__articles
[0m12:39:18.990411 [debug] [Thread-8 (]: Began running node model.mercurios.stg_prohandel__inventory
[0m12:39:18.990668 [info ] [Thread-7 (]: 1 of 9 START sql view model staging_staging.stg_prohandel__articles ............ [RUN]
[0m12:39:18.990957 [info ] [Thread-8 (]: 2 of 9 START sql view model staging_staging.stg_prohandel__inventory ........... [RUN]
[0m12:39:18.991168 [debug] [Thread-9 (]: Began running node model.mercurios.stg_prohandel__sales
[0m12:39:18.991426 [debug] [Thread-7 (]: Re-using an available connection from the pool (formerly list_MERCURIOS_DATA_staging_staging, now model.mercurios.stg_prohandel__articles)
[0m12:39:18.991685 [debug] [Thread-8 (]: Re-using an available connection from the pool (formerly list_MERCURIOS_DATA_staging_marts_inventory, now model.mercurios.stg_prohandel__inventory)
[0m12:39:18.991953 [info ] [Thread-9 (]: 3 of 9 START sql view model staging_staging.stg_prohandel__sales ............... [RUN]
[0m12:39:18.992157 [debug] [Thread-7 (]: Began compiling node model.mercurios.stg_prohandel__articles
[0m12:39:18.992329 [debug] [Thread-8 (]: Began compiling node model.mercurios.stg_prohandel__inventory
[0m12:39:18.992507 [debug] [Thread-9 (]: Re-using an available connection from the pool (formerly list_MERCURIOS_DATA_staging_intermediate, now model.mercurios.stg_prohandel__sales)
[0m12:39:18.997573 [debug] [Thread-7 (]: Writing injected SQL for node "model.mercurios.stg_prohandel__articles"
[0m12:39:18.999189 [debug] [Thread-8 (]: Writing injected SQL for node "model.mercurios.stg_prohandel__inventory"
[0m12:39:18.999445 [debug] [Thread-9 (]: Began compiling node model.mercurios.stg_prohandel__sales
[0m12:39:19.002559 [debug] [Thread-9 (]: Writing injected SQL for node "model.mercurios.stg_prohandel__sales"
[0m12:39:19.003185 [debug] [Thread-7 (]: Began executing node model.mercurios.stg_prohandel__articles
[0m12:39:19.003543 [debug] [Thread-8 (]: Began executing node model.mercurios.stg_prohandel__inventory
[0m12:39:19.023568 [debug] [Thread-8 (]: Writing runtime sql for node "model.mercurios.stg_prohandel__inventory"
[0m12:39:19.024526 [debug] [Thread-7 (]: Writing runtime sql for node "model.mercurios.stg_prohandel__articles"
[0m12:39:19.024918 [debug] [Thread-9 (]: Began executing node model.mercurios.stg_prohandel__sales
[0m12:39:19.027012 [debug] [Thread-9 (]: Writing runtime sql for node "model.mercurios.stg_prohandel__sales"
[0m12:39:19.027795 [debug] [Thread-8 (]: Using snowflake connection "model.mercurios.stg_prohandel__inventory"
[0m12:39:19.028267 [debug] [Thread-8 (]: On model.mercurios.stg_prohandel__inventory: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "node_id": "model.mercurios.stg_prohandel__inventory"} */
create or replace   view MERCURIOS_DATA.staging_staging.stg_prohandel__inventory
  
   as (
    with source as (
    select * from MERCURIOS_DATA.RAW.inventory
),

renamed as (
    select
        inventory_id,
        article_id,
        warehouse_id,
        quantity,
        
        -- Add stock level categorization
        case
            when quantity <= 0 then 'Out of Stock'
            when quantity <= 5 then 'Low Stock'
            when quantity <= 20 then 'Medium Stock'
            when quantity > 20 then 'High Stock'
            else 'Unknown'
        end as stock_level,
        
        -- Add reorder flag
        case
            when quantity <= 5 then true
            else false
        end as needs_reorder,
        
        location,
        last_count_date,
        is_available,
        tenant_id,
        
        -- Fivetran metadata
        _fivetran_synced,
        
        -- Add data quality flags
        case when quantity < 0 then true else false end as is_negative_quantity
    from source
)

select * from renamed
  );
[0m12:39:19.029356 [debug] [Thread-7 (]: Using snowflake connection "model.mercurios.stg_prohandel__articles"
[0m12:39:19.029625 [debug] [Thread-8 (]: Opening a new connection, currently in state closed
[0m12:39:19.030381 [debug] [Thread-9 (]: Using snowflake connection "model.mercurios.stg_prohandel__sales"
[0m12:39:19.030651 [debug] [Thread-7 (]: On model.mercurios.stg_prohandel__articles: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "node_id": "model.mercurios.stg_prohandel__articles"} */
create or replace   view MERCURIOS_DATA.staging_staging.stg_prohandel__articles
  
   as (
    with source as (
    select * from MERCURIOS_DATA.RAW.article
),

renamed as (
    select
        article_id,
        article_number,
        description,
        category,
        subcategory,
        brand,
        supplier,
        purchase_price,
        retail_price,
        min_stock_level,
        max_stock_level,
        reorder_point,
        lead_time_days,
        is_active,
        
        -- Calculate profit margin
        (retail_price - purchase_price) as profit_margin,
        case 
            when (purchase_price > 0) then ((retail_price - purchase_price) / purchase_price) * 100 
            else null 
        end as profit_margin_percent,
        
        -- Add price tier categorization
        case
            when retail_price < 10 then 'Budget'
            when retail_price >= 10 and retail_price < 50 then 'Standard'
            when retail_price >= 50 and retail_price < 100 then 'Premium'
            when retail_price >= 100 then 'Luxury'
            else 'Uncategorized'
        end as price_tier,
        
        created_at,
        updated_at,
        tenant_id,
        
        -- Fivetran metadata
        _fivetran_synced,
        
        -- Add data quality flags
        case when description is null or description = '' then true else false end as is_missing_description,
        case when purchase_price is null or purchase_price = 0 then true else false end as is_missing_purchase_price,
        case when retail_price is null or retail_price = 0 then true else false end as is_missing_retail_price
    from source
)

select * from renamed
  );
[0m12:39:19.031068 [debug] [Thread-9 (]: On model.mercurios.stg_prohandel__sales: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "node_id": "model.mercurios.stg_prohandel__sales"} */
create or replace   view MERCURIOS_DATA.staging_staging.stg_prohandel__sales
  
   as (
    with source as (
    select * from MERCURIOS_DATA.RAW.sale
),

renamed as (
    select
        sale_id,
        order_id,
        article_id,
        quantity,
        price,
        discount,
        
        -- Calculate net price and revenue
        (price - coalesce(discount, 0)) as net_price,
        (price - coalesce(discount, 0)) * quantity as revenue,
        
        -- Add sale type categorization
        case
            when discount is null or discount = 0 then 'Regular'
            when discount > 0 and discount < (price * 0.1) then 'Small Discount'
            when discount >= (price * 0.1) and discount < (price * 0.3) then 'Medium Discount'
            when discount >= (price * 0.3) then 'Large Discount'
            else 'Unknown'
        end as sale_type,
        
        sale_date,
        shop_id,
        tenant_id,
        
        -- Fivetran metadata
        _fivetran_synced,
        
        -- Add data quality flags
        case when quantity <= 0 then true else false end as is_invalid_quantity,
        case when price <= 0 then true else false end as is_invalid_price,
        case when discount > price then true else false end as is_discount_greater_than_price
    from source
)

select * from renamed
  );
[0m12:39:19.031343 [debug] [Thread-7 (]: Opening a new connection, currently in state closed
[0m12:39:19.031998 [debug] [Thread-9 (]: Opening a new connection, currently in state closed
[0m12:39:22.674435 [debug] [Thread-8 (]: SQL status: SUCCESS 1 in 3.645 seconds
[0m12:39:22.687112 [debug] [Thread-8 (]: On model.mercurios.stg_prohandel__inventory: Close
[0m12:39:22.840355 [debug] [Thread-8 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3ab8784c-1c6b-4841-b9ce-611fdb97d8be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12525d650>]}
[0m12:39:22.840905 [info ] [Thread-8 (]: 2 of 9 OK created sql view model staging_staging.stg_prohandel__inventory ...... [[32mSUCCESS 1[0m in 3.85s]
[0m12:39:22.841319 [debug] [Thread-8 (]: Finished running node model.mercurios.stg_prohandel__inventory
[0m12:39:26.611621 [debug] [Thread-7 (]: SQL status: SUCCESS 1 in 7.580 seconds
[0m12:39:26.613765 [debug] [Thread-7 (]: On model.mercurios.stg_prohandel__articles: Close
[0m12:39:26.715322 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3ab8784c-1c6b-4841-b9ce-611fdb97d8be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121328b50>]}
[0m12:39:26.715954 [info ] [Thread-7 (]: 1 of 9 OK created sql view model staging_staging.stg_prohandel__articles ....... [[32mSUCCESS 1[0m in 7.72s]
[0m12:39:26.716269 [debug] [Thread-7 (]: Finished running node model.mercurios.stg_prohandel__articles
[0m12:39:29.902544 [debug] [Thread-9 (]: SQL status: SUCCESS 1 in 10.870 seconds
[0m12:39:29.904715 [debug] [Thread-9 (]: On model.mercurios.stg_prohandel__sales: Close
[0m12:39:30.019306 [debug] [Thread-9 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3ab8784c-1c6b-4841-b9ce-611fdb97d8be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1252574d0>]}
[0m12:39:30.019853 [info ] [Thread-9 (]: 3 of 9 OK created sql view model staging_staging.stg_prohandel__sales .......... [[32mSUCCESS 1[0m in 11.03s]
[0m12:39:30.020246 [debug] [Thread-9 (]: Finished running node model.mercurios.stg_prohandel__sales
[0m12:39:30.020807 [debug] [Thread-10 ]: Began running node model.mercurios.demand_forecast
[0m12:39:30.021036 [debug] [Thread-8 (]: Began running node model.mercurios.int_inventory_with_metrics
[0m12:39:30.021333 [info ] [Thread-10 ]: 4 of 9 START sql table model staging_marts_inventory.demand_forecast ........... [RUN]
[0m12:39:30.021584 [info ] [Thread-8 (]: 5 of 9 START sql view model staging_intermediate.int_inventory_with_metrics .... [RUN]
[0m12:39:30.021884 [debug] [Thread-10 ]: Acquiring new snowflake connection 'model.mercurios.demand_forecast'
[0m12:39:30.022108 [debug] [Thread-8 (]: Re-using an available connection from the pool (formerly model.mercurios.stg_prohandel__inventory, now model.mercurios.int_inventory_with_metrics)
[0m12:39:30.022320 [debug] [Thread-10 ]: Began compiling node model.mercurios.demand_forecast
[0m12:39:30.022513 [debug] [Thread-8 (]: Began compiling node model.mercurios.int_inventory_with_metrics
[0m12:39:30.025594 [debug] [Thread-10 ]: Writing injected SQL for node "model.mercurios.demand_forecast"
[0m12:39:30.028213 [debug] [Thread-8 (]: Writing injected SQL for node "model.mercurios.int_inventory_with_metrics"
[0m12:39:30.028832 [debug] [Thread-10 ]: Began executing node model.mercurios.demand_forecast
[0m12:39:30.034508 [debug] [Thread-8 (]: Began executing node model.mercurios.int_inventory_with_metrics
[0m12:39:30.040992 [debug] [Thread-10 ]: Writing runtime sql for node "model.mercurios.demand_forecast"
[0m12:39:30.042883 [debug] [Thread-8 (]: Writing runtime sql for node "model.mercurios.int_inventory_with_metrics"
[0m12:39:30.048201 [debug] [Thread-10 ]: Using snowflake connection "model.mercurios.demand_forecast"
[0m12:39:30.050637 [debug] [Thread-8 (]: Using snowflake connection "model.mercurios.int_inventory_with_metrics"
[0m12:39:30.051210 [debug] [Thread-10 ]: On model.mercurios.demand_forecast: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "node_id": "model.mercurios.demand_forecast"} */
create or replace transient table MERCURIOS_DATA.staging_marts_inventory.demand_forecast
         as
        (select * from (
              

with sales_history as (
    select
        s.article_id,
        a.article_number,
        a.description,
        a.category,
        a.subcategory,
        a.brand,
        a.supplier,
        a.price_tier,
        s.sale_date,
        sum(s.quantity) as quantity_sold,
        count(distinct s.sale_id) as number_of_sales,
        sum(s.revenue) as revenue
    from MERCURIOS_DATA.staging_staging.stg_prohandel__sales s
    join MERCURIOS_DATA.staging_staging.stg_prohandel__articles a on s.article_id = a.article_id
    where s.sale_date >= dateadd('day', -365, current_date())
    group by 
        s.article_id,
        a.article_number,
        a.description,
        a.category,
        a.subcategory,
        a.brand,
        a.supplier,
        a.price_tier,
        s.sale_date
),

-- Calculate daily, weekly, and monthly aggregates
daily_sales as (
    select
        article_id,
        article_number,
        description,
        category,
        subcategory,
        brand,
        supplier,
        price_tier,
        sale_date,
        quantity_sold,
        number_of_sales,
        revenue,
        -- Extract date parts for seasonality analysis
        dayofweek(sale_date) as day_of_week,
        dayofmonth(sale_date) as day_of_month,
        month(sale_date) as month,
        quarter(sale_date) as quarter
    from sales_history
),

weekly_sales as (
    select
        article_id,
        article_number,
        description,
        category,
        subcategory,
        brand,
        supplier,
        price_tier,
        date_trunc('week', sale_date) as week_start_date,
        sum(quantity_sold) as weekly_quantity_sold,
        sum(number_of_sales) as weekly_number_of_sales,
        sum(revenue) as weekly_revenue,
        avg(quantity_sold) as avg_daily_quantity_sold,
        week(sale_date) as week_of_year
    from daily_sales
    group by 
        article_id,
        article_number,
        description,
        category,
        subcategory,
        brand,
        supplier,
        price_tier,
        week_start_date,
        week_of_year
),

monthly_sales as (
    select
        article_id,
        article_number,
        description,
        category,
        subcategory,
        brand,
        supplier,
        price_tier,
        date_trunc('month', sale_date) as month_start_date,
        sum(quantity_sold) as monthly_quantity_sold,
        sum(number_of_sales) as monthly_number_of_sales,
        sum(revenue) as monthly_revenue,
        avg(quantity_sold) as avg_daily_quantity_sold,
        month(sale_date) as month_of_year
    from daily_sales
    group by 
        article_id,
        article_number,
        description,
        category,
        subcategory,
        brand,
        supplier,
        price_tier,
        month_start_date,
        month_of_year
),

-- Calculate moving averages and trends
moving_averages as (
    select
        article_id,
        sale_date,
        quantity_sold,
        
        -- Calculate 7-day moving average
        avg(quantity_sold) over (
            partition by article_id 
            order by sale_date 
            rows between 6 preceding and current row
        ) as ma_7_day,
        
        -- Calculate 30-day moving average
        avg(quantity_sold) over (
            partition by article_id 
            order by sale_date 
            rows between 29 preceding and current row
        ) as ma_30_day,
        
        -- Calculate 90-day moving average
        avg(quantity_sold) over (
            partition by article_id 
            order by sale_date 
            rows between 89 preceding and current row
        ) as ma_90_day
    from daily_sales
),

-- Calculate seasonality factors
seasonality as (
    select
        article_id,
        day_of_week,
        avg(quantity_sold) as avg_qty_by_day_of_week,
        
        -- Calculate day of week seasonality factor
        avg(quantity_sold) / nullif(
            avg(avg(quantity_sold)) over (partition by article_id),
            0
        ) as day_of_week_factor
    from daily_sales
    group by article_id, day_of_week
),

monthly_seasonality as (
    select
        article_id,
        month_of_year,
        avg(monthly_quantity_sold) as avg_qty_by_month,
        
        -- Calculate month seasonality factor
        avg(monthly_quantity_sold) / nullif(
            avg(avg(monthly_quantity_sold)) over (partition by article_id),
            0
        ) as month_factor
    from monthly_sales
    group by article_id, month_of_year
),

-- Calculate recent sales statistics for forecasting
recent_stats as (
    select
        article_id,
        
        -- Last 30 days
        sum(case when sale_date >= dateadd('day', -30, current_date()) then quantity_sold else 0 end) as qty_last_30d,
        avg(case when sale_date >= dateadd('day', -30, current_date()) then quantity_sold else null end) as avg_daily_qty_last_30d,
        
        -- Last 90 days
        sum(case when sale_date >= dateadd('day', -90, current_date()) then quantity_sold else 0 end) as qty_last_90d,
        avg(case when sale_date >= dateadd('day', -90, current_date()) then quantity_sold else null end) as avg_daily_qty_last_90d,
        
        -- Last 365 days
        sum(quantity_sold) as qty_last_365d,
        avg(quantity_sold) as avg_daily_qty_last_365d,
        
        -- Calculate trend (comparing last 30 days to previous 30 days)
        sum(case when sale_date >= dateadd('day', -30, current_date()) then quantity_sold else 0 end) /
        nullif(sum(case when sale_date >= dateadd('day', -60, current_date()) and 
                        sale_date < dateadd('day', -30, current_date()) then quantity_sold else 0 end), 0) - 1 as trend_factor
    from daily_sales
    group by article_id
),

-- Generate forecast dates (simplified without dbt_utils for now)
forecast_dates as (
    select dateadd('day', seq4(), current_date()) as date_day
    from table(generator(rowcount => 90))
),

-- Create the final forecast
demand_forecast as (
    select
        a.article_id,
        a.article_number,
        a.description,
        a.category,
        a.subcategory,
        a.brand,
        a.supplier,
        a.price_tier,
        d.date_day as forecast_date,
        
        -- Extract date parts for applying seasonality
        dayofweek(d.date_day) as day_of_week,
        month(d.date_day) as month_of_year,
        
        -- Base forecast using recent average
        rs.avg_daily_qty_last_90d as base_forecast,
        
        -- Apply trend factor (capped to prevent extreme values)
        case
            when rs.trend_factor > 0.5 then 1.5
            when rs.trend_factor < -0.5 then 0.5
            else 1 + coalesce(rs.trend_factor, 0)
        end as applied_trend_factor,
        
        -- Apply day of week seasonality
        coalesce(s.day_of_week_factor, 1) as day_of_week_factor,
        
        -- Apply monthly seasonality
        coalesce(ms.month_factor, 1) as month_factor,
        
        -- Calculate final forecast
        round(
            rs.avg_daily_qty_last_90d * 
            case
                when rs.trend_factor > 0.5 then 1.5
                when rs.trend_factor < -0.5 then 0.5
                else 1 + coalesce(rs.trend_factor, 0)
            end *
            coalesce(s.day_of_week_factor, 1) *
            coalesce(ms.month_factor, 1),
            2
        ) as forecasted_daily_demand,
        
        -- Add cumulative forecast
        sum(
            round(
                rs.avg_daily_qty_last_90d * 
                case
                    when rs.trend_factor > 0.5 then 1.5
                    when rs.trend_factor < -0.5 then 0.5
                    else 1 + coalesce(rs.trend_factor, 0)
                end *
                coalesce(s.day_of_week_factor, 1) *
                coalesce(ms.month_factor, 1),
                2
            )
        ) over (
            partition by a.article_id 
            order by d.date_day 
            rows between unbounded preceding and current row
        ) as cumulative_forecasted_demand,
        
        -- Historical sales statistics
        rs.avg_daily_qty_last_30d,
        rs.avg_daily_qty_last_90d,
        rs.avg_daily_qty_last_365d,
        rs.qty_last_30d,
        rs.qty_last_90d,
        rs.qty_last_365d,
        
        -- Add confidence level based on data quality
        case
            when rs.qty_last_365d > 100 and rs.avg_daily_qty_last_30d > 0 then 'High'
            when rs.qty_last_90d > 30 and rs.avg_daily_qty_last_30d > 0 then 'Medium'
            when rs.qty_last_30d > 0 then 'Low'
            else 'Very Low'
        end as forecast_confidence,
        
        -- Generate forecast timestamp
        current_timestamp() as generated_at,
        
        -- Add tenant_id
        a.tenant_id
        
    from MERCURIOS_DATA.staging_staging.stg_prohandel__articles a
    cross join forecast_dates d
    left join recent_stats rs on a.article_id = rs.article_id
    left join seasonality s on a.article_id = s.article_id and dayofweek(d.date_day) = s.day_of_week
    left join monthly_seasonality ms on a.article_id = ms.article_id and month(d.date_day) = ms.month_of_year
    where rs.avg_daily_qty_last_90d > 0  -- Only forecast for items with recent sales
)

select * from demand_forecast
              ) order by (article_id, forecast_date)
        );
[0m12:39:30.051936 [debug] [Thread-8 (]: On model.mercurios.int_inventory_with_metrics: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "node_id": "model.mercurios.int_inventory_with_metrics"} */
create or replace   view MERCURIOS_DATA.staging_intermediate.int_inventory_with_metrics
  
   as (
    with inventory as (
    select * from MERCURIOS_DATA.staging_staging.stg_prohandel__inventory
),

articles as (
    select * from MERCURIOS_DATA.staging_staging.stg_prohandel__articles
),

sales_last_30_days as (
    select
        article_id,
        sum(quantity) as quantity_sold_30d,
        count(distinct sale_id) as num_orders_30d
    from MERCURIOS_DATA.staging_staging.stg_prohandel__sales
    where sale_date >= dateadd('day', -30, current_date())
    group by article_id
),

sales_last_90_days as (
    select
        article_id,
        sum(quantity) as quantity_sold_90d,
        count(distinct sale_id) as num_orders_90d
    from MERCURIOS_DATA.staging_staging.stg_prohandel__sales
    where sale_date >= dateadd('day', -90, current_date())
    group by article_id
),

inventory_with_metrics as (
    select
        -- Inventory fields
        i.inventory_id,
        i.article_id,
        i.warehouse_id,
        i.quantity,
        i.stock_level,
        i.needs_reorder,
        i.location,
        i.last_count_date,
        i.is_available,
        i.tenant_id,
        
        -- Article fields
        a.article_number,
        a.description,
        a.category,
        a.subcategory,
        a.brand,
        a.supplier,
        a.purchase_price,
        a.retail_price,
        a.min_stock_level,
        a.max_stock_level,
        a.reorder_point,
        a.lead_time_days,
        a.profit_margin,
        a.profit_margin_percent,
        a.price_tier,
        
        -- Sales metrics
        coalesce(s30.quantity_sold_30d, 0) as quantity_sold_30d,
        coalesce(s30.num_orders_30d, 0) as num_orders_30d,
        coalesce(s90.quantity_sold_90d, 0) as quantity_sold_90d,
        coalesce(s90.num_orders_90d, 0) as num_orders_90d,
        
        -- Calculate days of supply
        case
            when coalesce(s30.quantity_sold_30d, 0) > 0 then 
                (i.quantity / (s30.quantity_sold_30d / 30.0))
            else null
        end as days_of_supply_30d,
        
        case
            when coalesce(s90.quantity_sold_90d, 0) > 0 then 
                (i.quantity / (s90.quantity_sold_90d / 90.0))
            else null
        end as days_of_supply_90d,
        
        -- Calculate stock turnover rate (annualized)
        case
            when i.quantity > 0 and coalesce(s30.quantity_sold_30d, 0) > 0 then 
                (s30.quantity_sold_30d * (365.0 / 30.0)) / i.quantity
            else null
        end as turnover_rate_30d,
        
        case
            when i.quantity > 0 and coalesce(s90.quantity_sold_90d, 0) > 0 then 
                (s90.quantity_sold_90d * (365.0 / 90.0)) / i.quantity
            else null
        end as turnover_rate_90d,
        
        -- Calculate inventory value
        i.quantity * a.purchase_price as inventory_value,
        i.quantity * a.retail_price as potential_revenue,
        
        -- Calculate excess inventory flag
        case
            when coalesce(s90.quantity_sold_90d, 0) = 0 and i.quantity > 10 then true
            when coalesce(s90.quantity_sold_90d, 0) > 0 and 
                 (i.quantity / (s90.quantity_sold_90d / 90.0)) > 180 then true
            else false
        end as is_excess_inventory,
        
        -- Calculate slow-moving inventory flag
        case
            when coalesce(s90.quantity_sold_90d, 0) = 0 and i.quantity > 0 then true
            when coalesce(s90.quantity_sold_90d, 0) > 0 and 
                 (s90.quantity_sold_90d * (365.0 / 90.0)) / i.quantity < 1 then true
            else false
        end as is_slow_moving,
        
        -- Calculate stockout risk flag
        case
            when i.quantity = 0 then 'Stockout'
            when coalesce(s30.quantity_sold_30d, 0) > 0 and 
                 (i.quantity / (s30.quantity_sold_30d / 30.0)) < 7 then 'Critical'
            when coalesce(s30.quantity_sold_30d, 0) > 0 and 
                 (i.quantity / (s30.quantity_sold_30d / 30.0)) < 14 then 'Warning'
            else 'Normal'
        end as stockout_risk,
        
        -- Fivetran metadata
        i._fivetran_synced
    from inventory i
    left join articles a on i.article_id = a.article_id
    left join sales_last_30_days s30 on i.article_id = s30.article_id
    left join sales_last_90_days s90 on i.article_id = s90.article_id
)

select * from inventory_with_metrics
  );
[0m12:39:30.052425 [debug] [Thread-10 ]: Opening a new connection, currently in state init
[0m12:39:30.052754 [debug] [Thread-8 (]: Opening a new connection, currently in state closed
[0m12:39:33.800049 [debug] [Thread-8 (]: SQL status: SUCCESS 1 in 3.747 seconds
[0m12:39:33.801678 [debug] [Thread-8 (]: On model.mercurios.int_inventory_with_metrics: Close
[0m12:39:33.933088 [debug] [Thread-8 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3ab8784c-1c6b-4841-b9ce-611fdb97d8be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1252577d0>]}
[0m12:39:33.933621 [info ] [Thread-8 (]: 5 of 9 OK created sql view model staging_intermediate.int_inventory_with_metrics  [[32mSUCCESS 1[0m in 3.91s]
[0m12:39:33.933925 [debug] [Thread-8 (]: Finished running node model.mercurios.int_inventory_with_metrics
[0m12:39:33.934380 [debug] [Thread-9 (]: Began running node model.mercurios.inventory_status
[0m12:39:33.934819 [info ] [Thread-9 (]: 6 of 9 START sql table model staging_marts_inventory.inventory_status .......... [RUN]
[0m12:39:33.935094 [debug] [Thread-9 (]: Re-using an available connection from the pool (formerly model.mercurios.stg_prohandel__sales, now model.mercurios.inventory_status)
[0m12:39:33.935283 [debug] [Thread-9 (]: Began compiling node model.mercurios.inventory_status
[0m12:39:33.937838 [debug] [Thread-9 (]: Writing injected SQL for node "model.mercurios.inventory_status"
[0m12:39:33.938513 [debug] [Thread-9 (]: Began executing node model.mercurios.inventory_status
[0m12:39:33.940909 [debug] [Thread-9 (]: Writing runtime sql for node "model.mercurios.inventory_status"
[0m12:39:33.943618 [debug] [Thread-9 (]: Using snowflake connection "model.mercurios.inventory_status"
[0m12:39:33.947504 [debug] [Thread-9 (]: On model.mercurios.inventory_status: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "node_id": "model.mercurios.inventory_status"} */
create or replace transient table MERCURIOS_DATA.staging_marts_inventory.inventory_status
         as
        (select * from (
              

with inventory_metrics as (
    select * from MERCURIOS_DATA.staging_intermediate.int_inventory_with_metrics
),

inventory_status as (
    select
        -- Primary keys and identifiers
        inventory_id,
        article_id,
        warehouse_id,
        article_number,
        
        -- Article details
        description,
        category,
        subcategory,
        brand,
        supplier,
        price_tier,
        
        -- Inventory metrics
        quantity,
        stock_level,
        needs_reorder,
        days_of_supply_30d,
        days_of_supply_90d,
        turnover_rate_30d,
        turnover_rate_90d,
        stockout_risk,
        
        -- Sales metrics
        quantity_sold_30d,
        quantity_sold_90d,
        num_orders_30d,
        num_orders_90d,
        
        -- Financial metrics
        purchase_price,
        retail_price,
        profit_margin,
        profit_margin_percent,
        inventory_value,
        potential_revenue,
        
        -- Flags
        is_excess_inventory,
        is_slow_moving,
        
        -- Calculated fields
        case
            when stockout_risk = 'Stockout' then 1
            when stockout_risk = 'Critical' then 2
            when stockout_risk = 'Warning' then 3
            else 4
        end as stockout_risk_priority,
        
        case
            when is_excess_inventory then inventory_value else 0
        end as excess_inventory_value,
        
        case
            when is_slow_moving then inventory_value else 0
        end as slow_moving_value,
        
        -- Reorder quantity recommendation
        case
            -- If no sales, recommend minimum stock
            when quantity_sold_90d = 0 then 
                greatest(5 - quantity, 0)
            -- If sales exist, calculate based on days of supply target
            when days_of_supply_90d is not null then
                greatest(
                    ceil((quantity_sold_90d / 90.0) * 30) - quantity, -- 30 days supply
                    0
                )
            else 0
        end as recommended_reorder_quantity,
        
        -- ABC Analysis (based on sales volume and value)
        case
            when quantity_sold_90d > 0 and 
                 quantity_sold_90d * retail_price >= 
                 percentile_cont(0.8) within group (order by nullif(quantity_sold_90d * retail_price, 0)) 
                 over (partition by warehouse_id) then 'A'
            when quantity_sold_90d > 0 and 
                 quantity_sold_90d * retail_price >= 
                 percentile_cont(0.5) within group (order by nullif(quantity_sold_90d * retail_price, 0)) 
                 over (partition by warehouse_id) then 'B'
            when quantity_sold_90d > 0 then 'C'
            else 'D' -- No sales
        end as abc_class,
        
        -- Last update timestamp
        _fivetran_synced as last_updated,
        
        -- Add tenant_id
        tenant_id
    from inventory_metrics
)

select * from inventory_status
              ) order by (warehouse_id, stockout_risk)
        );
[0m12:39:33.950484 [debug] [Thread-9 (]: Opening a new connection, currently in state closed
[0m12:39:38.493174 [debug] [Thread-10 ]: SQL status: SUCCESS 1 in 8.440 seconds
[0m12:39:38.493902 [debug] [Thread-10 ]: Using snowflake connection "model.mercurios.demand_forecast"
[0m12:39:38.494197 [debug] [Thread-10 ]: On model.mercurios.demand_forecast: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "node_id": "model.mercurios.demand_forecast"} */
alter  table MERCURIOS_DATA.staging_marts_inventory.demand_forecast cluster by (article_id, forecast_date);
[0m12:39:38.753862 [debug] [Thread-10 ]: SQL status: SUCCESS 1 in 0.259 seconds
[0m12:39:38.755732 [debug] [Thread-10 ]: On model.mercurios.demand_forecast: Close
[0m12:39:38.853427 [debug] [Thread-10 ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3ab8784c-1c6b-4841-b9ce-611fdb97d8be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x125282b50>]}
[0m12:39:38.854096 [info ] [Thread-10 ]: 4 of 9 OK created sql table model staging_marts_inventory.demand_forecast ...... [[32mSUCCESS 1[0m in 8.83s]
[0m12:39:38.854531 [debug] [Thread-10 ]: Finished running node model.mercurios.demand_forecast
[0m12:39:41.358750 [debug] [Thread-9 (]: SQL status: SUCCESS 1 in 7.408 seconds
[0m12:39:41.359449 [debug] [Thread-9 (]: Using snowflake connection "model.mercurios.inventory_status"
[0m12:39:41.359719 [debug] [Thread-9 (]: On model.mercurios.inventory_status: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "node_id": "model.mercurios.inventory_status"} */
alter  table MERCURIOS_DATA.staging_marts_inventory.inventory_status cluster by (warehouse_id, stockout_risk);
[0m12:39:41.565916 [debug] [Thread-9 (]: SQL status: SUCCESS 1 in 0.206 seconds
[0m12:39:41.569836 [debug] [Thread-9 (]: On model.mercurios.inventory_status: Close
[0m12:39:41.687771 [debug] [Thread-9 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3ab8784c-1c6b-4841-b9ce-611fdb97d8be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x125257910>]}
[0m12:39:41.688545 [info ] [Thread-9 (]: 6 of 9 OK created sql table model staging_marts_inventory.inventory_status ..... [[32mSUCCESS 1[0m in 7.75s]
[0m12:39:41.689099 [debug] [Thread-9 (]: Finished running node model.mercurios.inventory_status
[0m12:39:41.689902 [debug] [Thread-8 (]: Began running node model.mercurios.reorder_recommendations
[0m12:39:41.690301 [debug] [Thread-7 (]: Began running node model.mercurios.stock_levels
[0m12:39:41.690842 [info ] [Thread-8 (]: 7 of 9 START sql table model staging_marts_inventory.reorder_recommendations ... [RUN]
[0m12:39:41.691376 [info ] [Thread-7 (]: 8 of 9 START sql table model staging_marts_inventory.stock_levels .............. [RUN]
[0m12:39:41.691830 [debug] [Thread-8 (]: Re-using an available connection from the pool (formerly model.mercurios.int_inventory_with_metrics, now model.mercurios.reorder_recommendations)
[0m12:39:41.692215 [debug] [Thread-7 (]: Re-using an available connection from the pool (formerly model.mercurios.stg_prohandel__articles, now model.mercurios.stock_levels)
[0m12:39:41.692618 [debug] [Thread-8 (]: Began compiling node model.mercurios.reorder_recommendations
[0m12:39:41.692934 [debug] [Thread-7 (]: Began compiling node model.mercurios.stock_levels
[0m12:39:41.697638 [debug] [Thread-8 (]: Writing injected SQL for node "model.mercurios.reorder_recommendations"
[0m12:39:41.700789 [debug] [Thread-7 (]: Writing injected SQL for node "model.mercurios.stock_levels"
[0m12:39:41.701696 [debug] [Thread-8 (]: Began executing node model.mercurios.reorder_recommendations
[0m12:39:41.702090 [debug] [Thread-7 (]: Began executing node model.mercurios.stock_levels
[0m12:39:41.704581 [debug] [Thread-8 (]: Writing runtime sql for node "model.mercurios.reorder_recommendations"
[0m12:39:41.706740 [debug] [Thread-7 (]: Writing runtime sql for node "model.mercurios.stock_levels"
[0m12:39:41.712418 [debug] [Thread-8 (]: Using snowflake connection "model.mercurios.reorder_recommendations"
[0m12:39:41.713073 [debug] [Thread-8 (]: On model.mercurios.reorder_recommendations: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "node_id": "model.mercurios.reorder_recommendations"} */
create or replace transient table MERCURIOS_DATA.staging_marts_inventory.reorder_recommendations
         as
        (select * from (
              

with inventory_status as (
    select * from MERCURIOS_DATA.staging_marts_inventory.inventory_status
),

-- Get historical sales velocity
sales_velocity as (
    select
        s.article_id,
        -- Calculate average daily sales for different time periods
        sum(s.quantity) / 30.0 as daily_sales_30d,
        sum(s.quantity) / 90.0 as daily_sales_90d,
        -- Calculate standard deviation of daily sales for safety stock
        stddev(daily_qty) as daily_sales_stddev
    from (
        select
            article_id,
            sale_date,
            sum(quantity) as daily_qty
        from MERCURIOS_DATA.staging_staging.stg_prohandel__sales
        where sale_date >= dateadd('day', -90, current_date())
        group by article_id, sale_date
    ) s
    group by s.article_id
),

-- Calculate reorder points and quantities
reorder_calc as (
    select
        i.inventory_id,
        i.article_id,
        i.warehouse_id,
        i.article_number,
        i.description,
        i.category,
        i.subcategory,
        i.brand,
        i.supplier,
        i.quantity as current_quantity,
        i.stock_level,
        i.stockout_risk,
        i.purchase_price,
        i.retail_price,
        i.inventory_value,
        i.abc_class,
        
        -- Sales metrics
        i.quantity_sold_30d,
        i.quantity_sold_90d,
        coalesce(sv.daily_sales_30d, 0) as daily_sales_30d,
        coalesce(sv.daily_sales_90d, 0) as daily_sales_90d,
        coalesce(sv.daily_sales_stddev, 0) as daily_sales_stddev,
        
        -- Lead time assumptions (in days) - could be replaced with actual supplier data
        case
            when i.abc_class = 'A' then 7  -- Priority items get faster shipping
            when i.abc_class = 'B' then 10
            when i.abc_class = 'C' then 14
            else 14
        end as lead_time_days,
        
        -- Service level factor (z-score) based on ABC classification
        case
            when i.abc_class = 'A' then 2.33  -- 99% service level
            when i.abc_class = 'B' then 1.65  -- 95% service level
            when i.abc_class = 'C' then 1.28  -- 90% service level
            else 1.28
        end as service_level_factor,
        
        -- Calculate reorder point components
        coalesce(sv.daily_sales_90d, 0) * 
            case
                when i.abc_class = 'A' then 7
                when i.abc_class = 'B' then 10
                when i.abc_class = 'C' then 14
                else 14
            end as lead_time_demand,
            
        coalesce(sv.daily_sales_stddev, 0) * 
            case
                when i.abc_class = 'A' then 2.33
                when i.abc_class = 'B' then 1.65
                when i.abc_class = 'C' then 1.28
                else 1.28
            end * sqrt(
                case
                    when i.abc_class = 'A' then 7
                    when i.abc_class = 'B' then 10
                    when i.abc_class = 'C' then 14
                    else 14
                end
            ) as safety_stock,
        
        -- Economic Order Quantity (EOQ) calculation
        -- Assuming ordering cost of $20 per order and holding cost of 25% of item value per year
        case
            when coalesce(sv.daily_sales_90d, 0) > 0 and i.purchase_price > 0 then
                sqrt(
                    (2 * 20 * coalesce(sv.daily_sales_90d, 0) * 365) / 
                    (0.25 * i.purchase_price)
                )
            else null
        end as economic_order_quantity
        
    from inventory_status i
    left join sales_velocity sv on i.article_id = sv.article_id
),

-- Generate final recommendations
reorder_recommendations as (
    select
        inventory_id,
        article_id,
        warehouse_id,
        article_number,
        description,
        category,
        subcategory,
        brand,
        supplier,
        current_quantity,
        stock_level,
        stockout_risk,
        purchase_price,
        retail_price,
        inventory_value,
        abc_class,
        
        -- Sales metrics
        quantity_sold_30d,
        quantity_sold_90d,
        daily_sales_30d,
        daily_sales_90d,
        
        -- Reorder calculations
        lead_time_days,
        round(lead_time_demand, 2) as lead_time_demand,
        round(safety_stock, 2) as safety_stock,
        
        -- Calculate reorder point
        round(lead_time_demand + safety_stock, 0) as reorder_point,
        
        -- Calculate if reorder is needed
        case
            when current_quantity <= (lead_time_demand + safety_stock) then true
            else false
        end as needs_reorder,
        
        -- Calculate reorder quantity
        case
            when current_quantity <= (lead_time_demand + safety_stock) then
                case
                    -- Use EOQ if available and reasonable
                    when economic_order_quantity is not null and 
                         economic_order_quantity >= (lead_time_demand + safety_stock - current_quantity) then
                        ceiling(greatest(economic_order_quantity, 1))
                    -- Otherwise use lead time demand plus safety stock minus current quantity
                    else
                        ceiling(greatest(lead_time_demand + safety_stock - current_quantity, 1))
                end
            else 0
        end as recommended_order_quantity,
        
        -- Calculate order cost
        case
            when current_quantity <= (lead_time_demand + safety_stock) then
                case
                    when economic_order_quantity is not null and 
                         economic_order_quantity >= (lead_time_demand + safety_stock - current_quantity) then
                        ceiling(greatest(economic_order_quantity, 1)) * purchase_price
                    else
                        ceiling(greatest(lead_time_demand + safety_stock - current_quantity, 1)) * purchase_price
                end
            else 0
        end as order_cost,
        
        -- Calculate days until stockout
        case
            when daily_sales_90d > 0 then
                round(current_quantity / daily_sales_90d, 0)
            else
                999  -- Arbitrary large number for items with no sales
        end as days_until_stockout,
        
        -- Calculate priority
        case
            when current_quantity <= 0 then 1  -- Already out of stock
            when current_quantity <= safety_stock then 2  -- Below safety stock
            when current_quantity <= (lead_time_demand + safety_stock) then 3  -- Below reorder point
            else 4  -- Above reorder point
        end as priority,
        
        -- Calculate priority label
        case
            when current_quantity <= 0 then 'Critical - Out of Stock'
            when current_quantity <= safety_stock then 'High - Below Safety Stock'
            when current_quantity <= (lead_time_demand + safety_stock) then 'Medium - Below Reorder Point'
            else 'Low - Stock Adequate'
        end as priority_label,
        
        -- Add timestamp
        current_timestamp() as generated_at
        
    from reorder_calc
)

select * from reorder_recommendations
order by priority, abc_class, order_cost desc
              ) order by (warehouse_id, priority)
        );
[0m12:39:41.717196 [debug] [Thread-7 (]: Using snowflake connection "model.mercurios.stock_levels"
[0m12:39:41.717570 [debug] [Thread-8 (]: Opening a new connection, currently in state closed
[0m12:39:41.718095 [debug] [Thread-7 (]: On model.mercurios.stock_levels: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "node_id": "model.mercurios.stock_levels"} */
create or replace transient table MERCURIOS_DATA.staging_marts_inventory.stock_levels
         as
        (

with inventory_status as (
    select * from MERCURIOS_DATA.staging_marts_inventory.inventory_status
),

-- Aggregate metrics by warehouse
warehouse_metrics as (
    select
        warehouse_id,
        count(distinct article_id) as total_articles,
        sum(quantity) as total_quantity,
        sum(inventory_value) as total_inventory_value,
        sum(potential_revenue) as total_potential_revenue,
        
        -- Stock level counts
        count(case when stock_level = 'Out of Stock' then 1 end) as out_of_stock_count,
        count(case when stock_level = 'Low Stock' then 1 end) as low_stock_count,
        count(case when stock_level = 'Medium Stock' then 1 end) as medium_stock_count,
        count(case when stock_level = 'High Stock' then 1 end) as high_stock_count,
        
        -- Risk level counts
        count(case when stockout_risk = 'Stockout' then 1 end) as stockout_count,
        count(case when stockout_risk = 'Critical' then 1 end) as critical_risk_count,
        count(case when stockout_risk = 'Warning' then 1 end) as warning_risk_count,
        count(case when stockout_risk = 'Normal' then 1 end) as normal_risk_count,
        
        -- Inventory health metrics
        sum(case when is_excess_inventory then inventory_value else 0 end) as excess_inventory_value,
        sum(case when is_slow_moving then inventory_value else 0 end) as slow_moving_value,
        sum(case when needs_reorder then 1 else 0 end) as reorder_needed_count,
        sum(recommended_reorder_quantity) as total_recommended_reorder_quantity,
        
        -- ABC analysis counts
        count(case when abc_class = 'A' then 1 end) as class_a_count,
        count(case when abc_class = 'B' then 1 end) as class_b_count,
        count(case when abc_class = 'C' then 1 end) as class_c_count,
        count(case when abc_class = 'D' then 1 end) as class_d_count,
        
        -- Calculate percentages
        (count(case when stock_level = 'Out of Stock' then 1 end) * 100.0 / 
            nullif(count(distinct article_id), 0)) as out_of_stock_percent,
        (count(case when stock_level = 'Low Stock' then 1 end) * 100.0 / 
            nullif(count(distinct article_id), 0)) as low_stock_percent,
        (sum(case when is_excess_inventory then inventory_value else 0 end) * 100.0 / 
            nullif(sum(inventory_value), 0)) as excess_inventory_percent,
        (sum(case when is_slow_moving then inventory_value else 0 end) * 100.0 / 
            nullif(sum(inventory_value), 0)) as slow_moving_percent
    from inventory_status
    group by warehouse_id
),

-- Aggregate metrics by category
category_metrics as (
    select
        warehouse_id,
        category,
        count(distinct article_id) as total_articles,
        sum(quantity) as total_quantity,
        sum(inventory_value) as total_inventory_value,
        sum(potential_revenue) as total_potential_revenue,
        
        -- Stock level counts
        count(case when stock_level = 'Out of Stock' then 1 end) as out_of_stock_count,
        count(case when stock_level = 'Low Stock' then 1 end) as low_stock_count,
        
        -- Risk level counts
        count(case when stockout_risk = 'Stockout' or stockout_risk = 'Critical' then 1 end) as high_risk_count,
        
        -- Inventory health metrics
        sum(case when is_excess_inventory then inventory_value else 0 end) as excess_inventory_value,
        sum(case when is_slow_moving then inventory_value else 0 end) as slow_moving_value,
        
        -- ABC analysis counts
        count(case when abc_class = 'A' then 1 end) as class_a_count,
        count(case when abc_class = 'B' then 1 end) as class_b_count,
        count(case when abc_class = 'C' then 1 end) as class_c_count,
        count(case when abc_class = 'D' then 1 end) as class_d_count
    from inventory_status
    group by warehouse_id, category
),

-- Combine all metrics
stock_levels as (
    select
        'warehouse' as level_type,
        warehouse_id,
        null as category,
        total_articles,
        total_quantity,
        total_inventory_value,
        total_potential_revenue,
        out_of_stock_count,
        low_stock_count,
        medium_stock_count,
        high_stock_count,
        stockout_count,
        critical_risk_count,
        warning_risk_count,
        normal_risk_count,
        excess_inventory_value,
        slow_moving_value,
        reorder_needed_count,
        total_recommended_reorder_quantity,
        class_a_count,
        class_b_count,
        class_c_count,
        class_d_count,
        out_of_stock_percent,
        low_stock_percent,
        excess_inventory_percent,
        slow_moving_percent,
        current_timestamp() as generated_at
    from warehouse_metrics
    
    union all
    
    select
        'category' as level_type,
        warehouse_id,
        category,
        total_articles,
        total_quantity,
        total_inventory_value,
        total_potential_revenue,
        out_of_stock_count,
        low_stock_count,
        null as medium_stock_count,
        null as high_stock_count,
        null as stockout_count,
        null as critical_risk_count,
        null as warning_risk_count,
        null as normal_risk_count,
        excess_inventory_value,
        slow_moving_value,
        null as reorder_needed_count,
        null as total_recommended_reorder_quantity,
        class_a_count,
        class_b_count,
        class_c_count,
        class_d_count,
        (out_of_stock_count * 100.0 / nullif(total_articles, 0)) as out_of_stock_percent,
        (low_stock_count * 100.0 / nullif(total_articles, 0)) as low_stock_percent,
        (excess_inventory_value * 100.0 / nullif(total_inventory_value, 0)) as excess_inventory_percent,
        (slow_moving_value * 100.0 / nullif(total_inventory_value, 0)) as slow_moving_percent,
        current_timestamp() as generated_at
    from category_metrics
)

select * from stock_levels
        );
[0m12:39:41.718718 [debug] [Thread-7 (]: Opening a new connection, currently in state closed
[0m12:39:44.738071 [debug] [Thread-7 (]: SQL status: SUCCESS 1 in 3.019 seconds
[0m12:39:44.739635 [debug] [Thread-7 (]: On model.mercurios.stock_levels: Close
[0m12:39:44.872079 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3ab8784c-1c6b-4841-b9ce-611fdb97d8be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1254c2b50>]}
[0m12:39:44.872852 [info ] [Thread-7 (]: 8 of 9 OK created sql table model staging_marts_inventory.stock_levels ......... [[32mSUCCESS 1[0m in 3.18s]
[0m12:39:44.873396 [debug] [Thread-7 (]: Finished running node model.mercurios.stock_levels
[0m12:39:48.551415 [debug] [Thread-8 (]: Snowflake adapter: Snowflake query id: 01baef7b-0204-2cd7-0003-4bde0007e292
[0m12:39:48.552050 [debug] [Thread-8 (]: Snowflake adapter: Snowflake error: 000904 (42000): SQL compilation error: error line 15 at position 12
invalid identifier 'S.QUANTITY'
[0m12:39:48.552681 [debug] [Thread-8 (]: On model.mercurios.reorder_recommendations: Close
[0m12:39:48.657344 [debug] [Thread-8 (]: Database Error in model reorder_recommendations (models/marts/inventory/reorder_recommendations.sql)
  000904 (42000): SQL compilation error: error line 15 at position 12
  invalid identifier 'S.QUANTITY'
  compiled code at target/run/mercurios/models/marts/inventory/reorder_recommendations.sql
[0m12:39:48.658148 [debug] [Thread-8 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3ab8784c-1c6b-4841-b9ce-611fdb97d8be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1254c2f90>]}
[0m12:39:48.659049 [error] [Thread-8 (]: 7 of 9 ERROR creating sql table model staging_marts_inventory.reorder_recommendations  [[31mERROR[0m in 6.97s]
[0m12:39:48.659745 [debug] [Thread-8 (]: Finished running node model.mercurios.reorder_recommendations
[0m12:39:48.660386 [debug] [Thread-13 ]: Marking all children of 'model.mercurios.reorder_recommendations' to be skipped because of status 'error'.  Reason: Database Error in model reorder_recommendations (models/marts/inventory/reorder_recommendations.sql)
  000904 (42000): SQL compilation error: error line 15 at position 12
  invalid identifier 'S.QUANTITY'
  compiled code at target/run/mercurios/models/marts/inventory/reorder_recommendations.sql.
[0m12:39:48.661910 [debug] [Thread-9 (]: Began running node model.mercurios.tenant_inventory_dashboard
[0m12:39:48.662566 [info ] [Thread-9 (]: 9 of 9 SKIP relation staging_marts_inventory.tenant_inventory_dashboard ........ [[33mSKIP[0m]
[0m12:39:48.663033 [debug] [Thread-9 (]: Finished running node model.mercurios.tenant_inventory_dashboard
[0m12:39:48.664316 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:39:48.664722 [debug] [MainThread]: Connection 'model.mercurios.stock_levels' was properly closed.
[0m12:39:48.665011 [debug] [MainThread]: Connection 'model.mercurios.reorder_recommendations' was properly closed.
[0m12:39:48.665324 [debug] [MainThread]: Connection 'model.mercurios.inventory_status' was properly closed.
[0m12:39:48.665726 [debug] [MainThread]: Connection 'model.mercurios.demand_forecast' was properly closed.
[0m12:39:48.666434 [info ] [MainThread]: 
[0m12:39:48.666810 [info ] [MainThread]: Finished running 5 table models, 4 view models in 0 hours 0 minutes and 53.03 seconds (53.03s).
[0m12:39:48.668131 [debug] [MainThread]: Command end result
[0m12:39:48.693843 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/target/manifest.json
[0m12:39:48.695513 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/target/semantic_manifest.json
[0m12:39:48.700141 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/target/run_results.json
[0m12:39:48.700447 [info ] [MainThread]: 
[0m12:39:48.700739 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m12:39:48.700995 [info ] [MainThread]: 
[0m12:39:48.701340 [error] [MainThread]:   Database Error in model reorder_recommendations (models/marts/inventory/reorder_recommendations.sql)
  000904 (42000): SQL compilation error: error line 15 at position 12
  invalid identifier 'S.QUANTITY'
  compiled code at target/run/mercurios/models/marts/inventory/reorder_recommendations.sql
[0m12:39:48.701552 [info ] [MainThread]: 
[0m12:39:48.701751 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=1 SKIP=1 TOTAL=9
[0m12:39:48.704299 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 54.312584, "process_in_blocks": "0", "process_kernel_time": 1.612275, "process_mem_max_rss": "198148096", "process_out_blocks": "0", "process_user_time": 3.187872}
[0m12:39:48.704665 [debug] [MainThread]: Command `dbt run` failed at 12:39:48.704617 after 54.31 seconds
[0m12:39:48.704934 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11272cd50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103185d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x124dbbc90>]}
[0m12:39:48.705164 [debug] [MainThread]: Flushing usage events
[0m12:39:49.400911 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:40:46.940553 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1139de250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113a48190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113a497d0>]}


============================== 12:40:46.943946 | 6dcbe175-e581-4f83-940f-79a70cc6d0b1 ==============================
[0m12:40:46.943946 [info ] [MainThread]: Running with dbt=1.9.2
[0m12:40:46.944294 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/juliusrechenbach/API ProHandelTest/dbt_mercurios', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m12:40:47.576438 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '6dcbe175-e581-4f83-940f-79a70cc6d0b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1308cf410>]}
[0m12:40:47.612230 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '6dcbe175-e581-4f83-940f-79a70cc6d0b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1129a9690>]}
[0m12:40:47.613086 [info ] [MainThread]: Registered adapter: snowflake=1.9.1
[0m12:40:47.700333 [debug] [MainThread]: checksum: 12b12750b70de726cfd89136b8e24afc3f3e77597a97bff40ab7e5f9b39d5e18, vars: {}, profile: , target: , version: 1.9.2
[0m12:40:47.783321 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m12:40:47.784049 [debug] [MainThread]: Partial parsing: updated file: mercurios://models/marts/inventory/reorder_recommendations.sql
[0m12:40:47.976002 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.mercurios.marts.sales
[0m12:40:47.983357 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6dcbe175-e581-4f83-940f-79a70cc6d0b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111410150>]}
[0m12:40:48.028948 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/target/manifest.json
[0m12:40:48.031532 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/target/semantic_manifest.json
[0m12:40:48.046666 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6dcbe175-e581-4f83-940f-79a70cc6d0b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x130ca9750>]}
[0m12:40:48.047102 [info ] [MainThread]: Found 9 models, 17 data tests, 3 sources, 586 macros
[0m12:40:48.047308 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6dcbe175-e581-4f83-940f-79a70cc6d0b1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x130ea0150>]}
[0m12:40:48.048704 [info ] [MainThread]: 
[0m12:40:48.048984 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:40:48.049170 [info ] [MainThread]: 
[0m12:40:48.049547 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m12:40:48.052000 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_MERCURIOS_DATA'
[0m12:40:48.052350 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_MERCURIOS_DATA'
[0m12:40:48.058052 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_MERCURIOS_DATA'
[0m12:40:48.088084 [debug] [ThreadPool]: Using snowflake connection "list_MERCURIOS_DATA"
[0m12:40:48.088420 [debug] [ThreadPool]: Using snowflake connection "list_MERCURIOS_DATA"
[0m12:40:48.088691 [debug] [ThreadPool]: Using snowflake connection "list_MERCURIOS_DATA"
[0m12:40:48.088855 [debug] [ThreadPool]: On list_MERCURIOS_DATA: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "list_MERCURIOS_DATA"} */
show terse schemas in database MERCURIOS_DATA
    limit 10000
[0m12:40:48.089035 [debug] [ThreadPool]: On list_MERCURIOS_DATA: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "list_MERCURIOS_DATA"} */
show terse schemas in database MERCURIOS_DATA
    limit 10000
[0m12:40:48.089207 [debug] [ThreadPool]: On list_MERCURIOS_DATA: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "list_MERCURIOS_DATA"} */
show terse schemas in database MERCURIOS_DATA
    limit 10000
[0m12:40:48.089367 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:40:48.089550 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:40:48.089696 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:42:29.751294 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "list_MERCURIOS_DATA"} */
show terse schemas in database MERCURIOS_DATA
    limit 10000
[0m12:42:29.752485 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "list_MERCURIOS_DATA"} */
show terse schemas in database MERCURIOS_DATA
    limit 10000
[0m12:42:29.752901 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "list_MERCURIOS_DATA"} */
show terse schemas in database MERCURIOS_DATA
    limit 10000
[0m12:42:29.753768 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
[0m12:42:29.754054 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
[0m12:42:29.754255 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
[0m12:42:29.755034 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro list_schemas
[0m12:42:29.755450 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro list_schemas
[0m12:42:29.755798 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro list_schemas
[0m12:42:29.756031 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
[0m12:42:29.756248 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
[0m12:42:29.756445 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
[0m12:42:29.756840 [debug] [ThreadPool]: On list_MERCURIOS_DATA: No close available on handle
[0m12:42:29.757090 [debug] [ThreadPool]: On list_MERCURIOS_DATA: No close available on handle
[0m12:42:29.757343 [debug] [ThreadPool]: On list_MERCURIOS_DATA: No close available on handle
[0m12:42:29.758844 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:42:29.759033 [debug] [MainThread]: Connection 'list_MERCURIOS_DATA' was properly closed.
[0m12:42:29.759181 [debug] [MainThread]: Connection 'list_MERCURIOS_DATA' was properly closed.
[0m12:42:29.759320 [debug] [MainThread]: Connection 'list_MERCURIOS_DATA' was properly closed.
[0m12:42:29.759566 [info ] [MainThread]: 
[0m12:42:29.759834 [info ] [MainThread]: Finished running  in 0 hours 1 minutes and 41.71 seconds (101.71s).
[0m12:42:29.760596 [error] [MainThread]: Encountered an error:
Runtime Error
  Database error while listing schemas in database "MERCURIOS_DATA"
  Database Error
    250001: Could not connect to Snowflake backend after 2 attempt(s).Aborting
[0m12:42:29.763844 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 102.86907, "process_in_blocks": "0", "process_kernel_time": 1.93572, "process_mem_max_rss": "195362816", "process_out_blocks": "0", "process_user_time": 2.280251}
[0m12:42:29.764258 [debug] [MainThread]: Command `dbt run` failed at 12:42:29.764190 after 102.87 seconds
[0m12:42:29.764778 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113a68350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1139e6fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113a983d0>]}
[0m12:42:29.765167 [debug] [MainThread]: Flushing usage events
[0m12:42:30.347202 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:42:36.586702 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ae50d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105b72110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105b72890>]}


============================== 12:42:36.590270 | 3c96b52b-bf19-45ad-84d2-4fdf436ca2a6 ==============================
[0m12:42:36.590270 [info ] [MainThread]: Running with dbt=1.9.2
[0m12:42:36.590639 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/juliusrechenbach/API ProHandelTest/dbt_mercurios', 'debug': 'False', 'warn_error': 'None', 'log_path': '/Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'invocation_command': 'dbt debug', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:42:36.601284 [info ] [MainThread]: dbt version: 1.9.2
[0m12:42:36.601590 [info ] [MainThread]: python version: 3.11.1
[0m12:42:36.601771 [info ] [MainThread]: python path: /Users/juliusrechenbach/API ProHandelTest/.venv/bin/python
[0m12:42:36.601927 [info ] [MainThread]: os info: macOS-15.3.1-arm64-arm-64bit
[0m12:42:37.168932 [info ] [MainThread]: Using profiles dir at /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios
[0m12:42:37.169258 [info ] [MainThread]: Using profiles.yml file at /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/profiles.yml
[0m12:42:37.169418 [info ] [MainThread]: Using dbt_project.yml file at /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/dbt_project.yml
[0m12:42:37.169998 [info ] [MainThread]: adapter type: snowflake
[0m12:42:37.170172 [info ] [MainThread]: adapter version: 1.9.1
[0m12:42:37.232024 [info ] [MainThread]: Configuration:
[0m12:42:37.232362 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m12:42:37.232521 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m12:42:37.232663 [info ] [MainThread]: Required dependencies:
[0m12:42:37.232844 [debug] [MainThread]: Executing "git --help"
[0m12:42:37.251387 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m12:42:37.252122 [debug] [MainThread]: STDERR: "b''"
[0m12:42:37.252350 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m12:42:37.252533 [info ] [MainThread]: Connection:
[0m12:42:37.252732 [info ] [MainThread]:   account: VRXDFZX-ZZ95717
[0m12:42:37.252874 [info ] [MainThread]:   user: JULIUSRECHENBACH
[0m12:42:37.253010 [info ] [MainThread]:   database: MERCURIOS_DATA
[0m12:42:37.253144 [info ] [MainThread]:   warehouse: MERCURIOS_DEV_WH
[0m12:42:37.253274 [info ] [MainThread]:   role: MERCURIOS_DEVELOPER
[0m12:42:37.253413 [info ] [MainThread]:   schema: staging
[0m12:42:37.253554 [info ] [MainThread]:   authenticator: None
[0m12:42:37.253694 [info ] [MainThread]:   oauth_client_id: None
[0m12:42:37.253831 [info ] [MainThread]:   query_tag: dbt_mercurios_dev
[0m12:42:37.253970 [info ] [MainThread]:   client_session_keep_alive: True
[0m12:42:37.254111 [info ] [MainThread]:   host: None
[0m12:42:37.254249 [info ] [MainThread]:   port: None
[0m12:42:37.254389 [info ] [MainThread]:   proxy_host: None
[0m12:42:37.254529 [info ] [MainThread]:   proxy_port: None
[0m12:42:37.254667 [info ] [MainThread]:   protocol: None
[0m12:42:37.254803 [info ] [MainThread]:   connect_retries: 1
[0m12:42:37.254941 [info ] [MainThread]:   connect_timeout: None
[0m12:42:37.255079 [info ] [MainThread]:   retry_on_database_errors: False
[0m12:42:37.255214 [info ] [MainThread]:   retry_all: False
[0m12:42:37.255348 [info ] [MainThread]:   insecure_mode: False
[0m12:42:37.255480 [info ] [MainThread]:   reuse_connections: None
[0m12:42:37.255876 [info ] [MainThread]: Registered adapter: snowflake=1.9.1
[0m12:42:37.335086 [debug] [MainThread]: Acquiring new snowflake connection 'debug'
[0m12:42:37.362169 [debug] [MainThread]: Using snowflake connection "debug"
[0m12:42:37.362443 [debug] [MainThread]: On debug: select 1 as id
[0m12:42:37.362619 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:42:43.974451 [debug] [MainThread]: Snowflake adapter: Error running SQL: select 1 as id
[0m12:42:43.974766 [debug] [MainThread]: Snowflake adapter: Rolling back transaction.
[0m12:42:43.975026 [debug] [MainThread]: On debug: No close available on handle
[0m12:42:43.975298 [info ] [MainThread]:   Connection test: [[31mERROR[0m]

[0m12:42:43.975599 [info ] [MainThread]: [31m1 check failed:[0m
[0m12:42:43.975841 [info ] [MainThread]: dbt was unable to connect to the specified database.
The database returned the following error:

  >Database Error
  250001 (08001): Failed to connect to DB: VRXDFZX-ZZ95717.snowflakecomputing.com:443. User is locked from Duo Security. Contact your local system administrator.

Check your database credentials and try again. For more information, visit:
https://docs.getdbt.com/docs/configure-your-profile


[0m12:42:43.978009 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 7.4403234, "process_in_blocks": "0", "process_kernel_time": 1.304519, "process_mem_max_rss": "182452224", "process_out_blocks": "0", "process_user_time": 2.208302}
[0m12:42:43.978430 [debug] [MainThread]: Command `dbt debug` failed at 12:42:43.978357 after 7.44 seconds
[0m12:42:43.978725 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m12:42:43.978970 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b30ae90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x100dd9fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x100dd9f10>]}
[0m12:42:43.979245 [debug] [MainThread]: Flushing usage events
[0m12:42:44.489076 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:44:47.158824 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1109e4290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110712110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110a4c890>]}


============================== 12:44:47.162060 | 01576715-56fa-4290-bb91-6a441f57ce12 ==============================
[0m12:44:47.162060 [info ] [MainThread]: Running with dbt=1.9.2
[0m12:44:47.162410 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/logs', 'profiles_dir': '/Users/juliusrechenbach/API ProHandelTest/dbt_mercurios', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt run --models marts.inventory.reorder_recommendations', 'send_anonymous_usage_stats': 'True'}
[0m12:44:47.814823 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '01576715-56fa-4290-bb91-6a441f57ce12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1340d1090>]}
[0m12:44:47.851241 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '01576715-56fa-4290-bb91-6a441f57ce12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111036a50>]}
[0m12:44:47.852033 [info ] [MainThread]: Registered adapter: snowflake=1.9.1
[0m12:44:47.935262 [debug] [MainThread]: checksum: 12b12750b70de726cfd89136b8e24afc3f3e77597a97bff40ab7e5f9b39d5e18, vars: {}, profile: , target: , version: 1.9.2
[0m12:44:47.985242 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m12:44:47.985607 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '01576715-56fa-4290-bb91-6a441f57ce12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a44b50>]}
[0m12:44:48.793197 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.mercurios.marts.sales
[0m12:44:48.799974 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '01576715-56fa-4290-bb91-6a441f57ce12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1348f7f10>]}
[0m12:44:48.846311 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/target/manifest.json
[0m12:44:48.848665 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/target/semantic_manifest.json
[0m12:44:48.861020 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '01576715-56fa-4290-bb91-6a441f57ce12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x13492f3d0>]}
[0m12:44:48.861355 [info ] [MainThread]: Found 9 models, 17 data tests, 3 sources, 586 macros
[0m12:44:48.861552 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '01576715-56fa-4290-bb91-6a441f57ce12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x13445b210>]}
[0m12:44:48.862451 [info ] [MainThread]: 
[0m12:44:48.862647 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:44:48.862798 [info ] [MainThread]: 
[0m12:44:48.863117 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m12:44:48.863679 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_MERCURIOS_DATA'
[0m12:44:48.896844 [debug] [ThreadPool]: Using snowflake connection "list_MERCURIOS_DATA"
[0m12:44:48.897113 [debug] [ThreadPool]: On list_MERCURIOS_DATA: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "list_MERCURIOS_DATA"} */
show terse schemas in database MERCURIOS_DATA
    limit 10000
[0m12:44:48.897264 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:44:49.405384 [debug] [ThreadPool]: Snowflake adapter: Got a retryable error when attempting to open a snowflake connection.
3 attempts remaining. Retrying in 30 seconds.
Error:
250001 (08001): Failed to connect to DB: VRXDFZX-ZZ95717.snowflakecomputing.com:443. User is locked from Duo Security. Contact your local system administrator.
[0m12:45:20.093793 [debug] [ThreadPool]: Snowflake adapter: Got a retryable error when attempting to open a snowflake connection.
2 attempts remaining. Retrying in 30 seconds.
Error:
250001 (08001): Failed to connect to DB: VRXDFZX-ZZ95717.snowflakecomputing.com:443. User is locked from Duo Security. Contact your local system administrator.
[0m12:45:50.625314 [debug] [ThreadPool]: Snowflake adapter: Got a retryable error when attempting to open a snowflake connection.
1 attempts remaining. Retrying in 30 seconds.
Error:
250001 (08001): Failed to connect to DB: VRXDFZX-ZZ95717.snowflakecomputing.com:443. User is locked from Duo Security. Contact your local system administrator.
[0m12:46:21.138316 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "list_MERCURIOS_DATA"} */
show terse schemas in database MERCURIOS_DATA
    limit 10000
[0m12:46:21.140586 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
[0m12:46:21.141516 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro list_schemas
[0m12:46:21.141945 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
[0m12:46:21.143864 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:46:21.144341 [debug] [MainThread]: Connection 'list_MERCURIOS_DATA' was left open.
[0m12:46:21.144909 [debug] [MainThread]: On list_MERCURIOS_DATA: No close available on handle
[0m12:46:21.145398 [info ] [MainThread]: 
[0m12:46:21.145922 [info ] [MainThread]: Finished running  in 0 hours 1 minutes and 32.28 seconds (92.28s).
[0m12:46:21.147201 [error] [MainThread]: Encountered an error:
Runtime Error
  Database error while listing schemas in database "MERCURIOS_DATA"
  Database Error
    250001 (08001): Failed to connect to DB: VRXDFZX-ZZ95717.snowflakecomputing.com:443. User is locked from Duo Security. Contact your local system administrator.
[0m12:46:21.150609 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 94.0351, "process_in_blocks": "0", "process_kernel_time": 1.235272, "process_mem_max_rss": "202211328", "process_out_blocks": "0", "process_user_time": 2.809876}
[0m12:46:21.151366 [debug] [MainThread]: Command `dbt run` failed at 12:46:21.151120 after 94.04 seconds
[0m12:46:21.152415 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110a4dad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x134901390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x13492c7d0>]}
[0m12:46:21.153161 [debug] [MainThread]: Flushing usage events
[0m12:46:21.733135 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:51:19.385862 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067e4810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106869590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10686ac10>]}


============================== 12:51:19.389614 | fdb7cdd3-eb93-4713-a438-96fa0d81ceaf ==============================
[0m12:51:19.389614 [info ] [MainThread]: Running with dbt=1.9.2
[0m12:51:19.390097 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/logs', 'fail_fast': 'False', 'profiles_dir': '/Users/juliusrechenbach/API ProHandelTest/dbt_mercurios', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'invocation_command': 'dbt debug', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m12:51:19.399736 [info ] [MainThread]: dbt version: 1.9.2
[0m12:51:19.400044 [info ] [MainThread]: python version: 3.11.1
[0m12:51:19.400237 [info ] [MainThread]: python path: /Users/juliusrechenbach/API ProHandelTest/.venv/bin/python
[0m12:51:19.400404 [info ] [MainThread]: os info: macOS-15.3.1-arm64-arm-64bit
[0m12:51:20.027782 [info ] [MainThread]: Using profiles dir at /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios
[0m12:51:20.028584 [info ] [MainThread]: Using profiles.yml file at /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/profiles.yml
[0m12:51:20.029117 [info ] [MainThread]: Using dbt_project.yml file at /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/dbt_project.yml
[0m12:51:20.029859 [info ] [MainThread]: adapter type: snowflake
[0m12:51:20.030074 [info ] [MainThread]: adapter version: 1.9.1
[0m12:51:20.091817 [info ] [MainThread]: Configuration:
[0m12:51:20.094450 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m12:51:20.094703 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m12:51:20.094882 [info ] [MainThread]: Required dependencies:
[0m12:51:20.095090 [debug] [MainThread]: Executing "git --help"
[0m12:51:20.115149 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m12:51:20.117996 [debug] [MainThread]: STDERR: "b''"
[0m12:51:20.118607 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m12:51:20.119009 [info ] [MainThread]: Connection:
[0m12:51:20.119331 [info ] [MainThread]:   account: VRXDFZX-ZZ95717
[0m12:51:20.119489 [info ] [MainThread]:   user: JULIUSRECHENBACH
[0m12:51:20.119649 [info ] [MainThread]:   database: MERCURIOS_DATA
[0m12:51:20.119794 [info ] [MainThread]:   warehouse: MERCURIOS_DEV_WH
[0m12:51:20.120111 [info ] [MainThread]:   role: MERCURIOS_DEVELOPER
[0m12:51:20.120467 [info ] [MainThread]:   schema: staging
[0m12:51:20.120611 [info ] [MainThread]:   authenticator: None
[0m12:51:20.120754 [info ] [MainThread]:   oauth_client_id: None
[0m12:51:20.120905 [info ] [MainThread]:   query_tag: dbt_mercurios_dev
[0m12:51:20.121046 [info ] [MainThread]:   client_session_keep_alive: True
[0m12:51:20.121190 [info ] [MainThread]:   host: None
[0m12:51:20.121332 [info ] [MainThread]:   port: None
[0m12:51:20.121475 [info ] [MainThread]:   proxy_host: None
[0m12:51:20.121622 [info ] [MainThread]:   proxy_port: None
[0m12:51:20.121764 [info ] [MainThread]:   protocol: None
[0m12:51:20.121919 [info ] [MainThread]:   connect_retries: 3
[0m12:51:20.122061 [info ] [MainThread]:   connect_timeout: 30
[0m12:51:20.122203 [info ] [MainThread]:   retry_on_database_errors: True
[0m12:51:20.122425 [info ] [MainThread]:   retry_all: False
[0m12:51:20.122659 [info ] [MainThread]:   insecure_mode: False
[0m12:51:20.122878 [info ] [MainThread]:   reuse_connections: True
[0m12:51:20.123388 [info ] [MainThread]: Registered adapter: snowflake=1.9.1
[0m12:51:20.210543 [debug] [MainThread]: Acquiring new snowflake connection 'debug'
[0m12:51:20.241777 [debug] [MainThread]: Using snowflake connection "debug"
[0m12:51:20.242053 [debug] [MainThread]: On debug: select 1 as id
[0m12:51:20.242224 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:51:20.824911 [debug] [MainThread]: Snowflake adapter: Got a retryable error when attempting to open a snowflake connection.
3 attempts remaining. Retrying in 30 seconds.
Error:
250001 (08001): Failed to connect to DB: VRXDFZX-ZZ95717.snowflakecomputing.com:443. User is locked from Duo Security. Contact your local system administrator.
[0m12:51:51.258079 [debug] [MainThread]: Snowflake adapter: Got a retryable error when attempting to open a snowflake connection.
2 attempts remaining. Retrying in 30 seconds.
Error:
250001 (08001): Failed to connect to DB: VRXDFZX-ZZ95717.snowflakecomputing.com:443. User is locked from Duo Security. Contact your local system administrator.
[0m12:52:21.696984 [debug] [MainThread]: Snowflake adapter: Got a retryable error when attempting to open a snowflake connection.
1 attempts remaining. Retrying in 30 seconds.
Error:
250001 (08001): Failed to connect to DB: VRXDFZX-ZZ95717.snowflakecomputing.com:443. User is locked from Duo Security. Contact your local system administrator.
[0m12:52:52.162028 [debug] [MainThread]: Snowflake adapter: Error running SQL: select 1 as id
[0m12:52:52.162906 [debug] [MainThread]: Snowflake adapter: Rolling back transaction.
[0m12:52:52.163658 [info ] [MainThread]:   Connection test: [[31mERROR[0m]

[0m12:52:52.164126 [info ] [MainThread]: [31m1 check failed:[0m
[0m12:52:52.164368 [info ] [MainThread]: dbt was unable to connect to the specified database.
The database returned the following error:

  >Database Error
  250001 (08001): Failed to connect to DB: VRXDFZX-ZZ95717.snowflakecomputing.com:443. User is locked from Duo Security. Contact your local system administrator.

Check your database credentials and try again. For more information, visit:
https://docs.getdbt.com/docs/configure-your-profile


[0m12:52:52.168075 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 92.82898, "process_in_blocks": "0", "process_kernel_time": 1.721195, "process_mem_max_rss": "178896896", "process_out_blocks": "0", "process_user_time": 2.215735}
[0m12:52:52.168528 [debug] [MainThread]: Command `dbt debug` failed at 12:52:52.168434 after 92.83 seconds
[0m12:52:52.168908 [debug] [MainThread]: Connection 'debug' was left open.
[0m12:52:52.169096 [debug] [MainThread]: On debug: No close available on handle
[0m12:52:52.169432 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106412450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106504810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10612c190>]}
[0m12:52:52.169823 [debug] [MainThread]: Flushing usage events
[0m12:52:52.733501 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:53:52.742222 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1153e49d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11546d910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11546e090>]}


============================== 12:53:52.745682 | 9cad34f1-707a-4e44-b834-ab3a10507380 ==============================
[0m12:53:52.745682 [info ] [MainThread]: Running with dbt=1.9.2
[0m12:53:52.746035 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/juliusrechenbach/API ProHandelTest/dbt_mercurios', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'invocation_command': 'dbt debug', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:53:52.757735 [info ] [MainThread]: dbt version: 1.9.2
[0m12:53:52.758033 [info ] [MainThread]: python version: 3.11.1
[0m12:53:52.758218 [info ] [MainThread]: python path: /Users/juliusrechenbach/API ProHandelTest/.venv/bin/python
[0m12:53:52.758372 [info ] [MainThread]: os info: macOS-15.3.1-arm64-arm-64bit
[0m12:53:53.429821 [info ] [MainThread]: Using profiles dir at /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios
[0m12:53:53.430164 [info ] [MainThread]: Using profiles.yml file at /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/profiles.yml
[0m12:53:53.430327 [info ] [MainThread]: Using dbt_project.yml file at /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/dbt_project.yml
[0m12:53:53.430764 [info ] [MainThread]: adapter type: snowflake
[0m12:53:53.430984 [info ] [MainThread]: adapter version: 1.9.1
[0m12:53:53.497714 [info ] [MainThread]: Configuration:
[0m12:53:53.498181 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m12:53:53.498371 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m12:53:53.498529 [info ] [MainThread]: Required dependencies:
[0m12:53:53.498746 [debug] [MainThread]: Executing "git --help"
[0m12:53:53.519054 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m12:53:53.519748 [debug] [MainThread]: STDERR: "b''"
[0m12:53:53.519970 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m12:53:53.520165 [info ] [MainThread]: Connection:
[0m12:53:53.520439 [info ] [MainThread]:   account: VRXDFZX-ZZ95717
[0m12:53:53.520620 [info ] [MainThread]:   user: JULIUSRECHENBACH
[0m12:53:53.520782 [info ] [MainThread]:   database: MERCURIOS_DATA
[0m12:53:53.520925 [info ] [MainThread]:   warehouse: MERCURIOS_DEV_WH
[0m12:53:53.521075 [info ] [MainThread]:   role: MERCURIOS_DEVELOPER
[0m12:53:53.521215 [info ] [MainThread]:   schema: staging
[0m12:53:53.521354 [info ] [MainThread]:   authenticator: None
[0m12:53:53.521496 [info ] [MainThread]:   oauth_client_id: None
[0m12:53:53.521632 [info ] [MainThread]:   query_tag: dbt_mercurios_dev
[0m12:53:53.521772 [info ] [MainThread]:   client_session_keep_alive: True
[0m12:53:53.521920 [info ] [MainThread]:   host: None
[0m12:53:53.522056 [info ] [MainThread]:   port: None
[0m12:53:53.522195 [info ] [MainThread]:   proxy_host: None
[0m12:53:53.522336 [info ] [MainThread]:   proxy_port: None
[0m12:53:53.522474 [info ] [MainThread]:   protocol: None
[0m12:53:53.522610 [info ] [MainThread]:   connect_retries: 3
[0m12:53:53.522746 [info ] [MainThread]:   connect_timeout: 30
[0m12:53:53.522878 [info ] [MainThread]:   retry_on_database_errors: True
[0m12:53:53.523014 [info ] [MainThread]:   retry_all: False
[0m12:53:53.523149 [info ] [MainThread]:   insecure_mode: False
[0m12:53:53.523283 [info ] [MainThread]:   reuse_connections: True
[0m12:53:53.523632 [info ] [MainThread]: Registered adapter: snowflake=1.9.1
[0m12:53:53.600432 [debug] [MainThread]: Acquiring new snowflake connection 'debug'
[0m12:53:53.628751 [debug] [MainThread]: Using snowflake connection "debug"
[0m12:53:53.629077 [debug] [MainThread]: On debug: select 1 as id
[0m12:53:53.629321 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:53:54.073130 [debug] [MainThread]: Snowflake adapter: Got a retryable error when attempting to open a snowflake connection.
3 attempts remaining. Retrying in 30 seconds.
Error:
250001 (08001): Failed to connect to DB: VRXDFZX-ZZ95717.snowflakecomputing.com:443. User is locked from Duo Security. Contact your local system administrator.
[0m12:54:24.508751 [debug] [MainThread]: Snowflake adapter: Got a retryable error when attempting to open a snowflake connection.
2 attempts remaining. Retrying in 30 seconds.
Error:
250001 (08001): Failed to connect to DB: VRXDFZX-ZZ95717.snowflakecomputing.com:443. User is locked from Duo Security. Contact your local system administrator.
[0m12:54:54.918022 [debug] [MainThread]: Snowflake adapter: Got a retryable error when attempting to open a snowflake connection.
1 attempts remaining. Retrying in 30 seconds.
Error:
250001 (08001): Failed to connect to DB: VRXDFZX-ZZ95717.snowflakecomputing.com:443. User is locked from Duo Security. Contact your local system administrator.
[0m12:55:25.622872 [debug] [MainThread]: Snowflake adapter: Error running SQL: select 1 as id
[0m12:55:25.623473 [debug] [MainThread]: Snowflake adapter: Rolling back transaction.
[0m12:55:25.624004 [info ] [MainThread]:   Connection test: [[31mERROR[0m]

[0m12:55:25.624233 [info ] [MainThread]: [31m1 check failed:[0m
[0m12:55:25.624397 [info ] [MainThread]: dbt was unable to connect to the specified database.
The database returned the following error:

  >Database Error
  250001 (08001): Failed to connect to DB: VRXDFZX-ZZ95717.snowflakecomputing.com:443. User is locked from Duo Security. Contact your local system administrator.

Check your database credentials and try again. For more information, visit:
https://docs.getdbt.com/docs/configure-your-profile


[0m12:55:25.628839 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 92.943054, "process_in_blocks": "0", "process_kernel_time": 0.928638, "process_mem_max_rss": "177979392", "process_out_blocks": "0", "process_user_time": 2.752429}
[0m12:55:25.629302 [debug] [MainThread]: Command `dbt debug` failed at 12:55:25.629216 after 92.94 seconds
[0m12:55:25.629683 [debug] [MainThread]: Connection 'debug' was left open.
[0m12:55:25.629875 [debug] [MainThread]: On debug: No close available on handle
[0m12:55:25.630221 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1153dd490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1153dd6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1154517d0>]}
[0m12:55:25.630715 [debug] [MainThread]: Flushing usage events
[0m12:55:26.270298 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:01:31.808176 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c51cfd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c565d10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c566490>]}


============================== 13:01:31.815244 | e3b2507a-c522-4e8a-8397-e46f2eb79d71 ==============================
[0m13:01:31.815244 [info ] [MainThread]: Running with dbt=1.9.2
[0m13:01:31.815774 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/logs', 'fail_fast': 'False', 'profiles_dir': '/Users/juliusrechenbach/API ProHandelTest/dbt_mercurios', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt debug', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m13:01:31.827606 [info ] [MainThread]: dbt version: 1.9.2
[0m13:01:31.828324 [info ] [MainThread]: python version: 3.11.1
[0m13:01:31.828640 [info ] [MainThread]: python path: /Users/juliusrechenbach/API ProHandelTest/.venv/bin/python
[0m13:01:31.828823 [info ] [MainThread]: os info: macOS-15.3.1-arm64-arm-64bit
[0m13:01:32.849656 [info ] [MainThread]: Using profiles dir at /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios
[0m13:01:32.850046 [info ] [MainThread]: Using profiles.yml file at /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/profiles.yml
[0m13:01:32.850215 [info ] [MainThread]: Using dbt_project.yml file at /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/dbt_project.yml
[0m13:01:32.850692 [info ] [MainThread]: adapter type: snowflake
[0m13:01:32.850855 [info ] [MainThread]: adapter version: 1.9.1
[0m13:01:32.908597 [info ] [MainThread]: Configuration:
[0m13:01:32.908917 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m13:01:32.909073 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m13:01:32.909217 [info ] [MainThread]: Required dependencies:
[0m13:01:32.909410 [debug] [MainThread]: Executing "git --help"
[0m13:01:32.920764 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m13:01:32.921480 [debug] [MainThread]: STDERR: "b''"
[0m13:01:32.921707 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m13:01:32.921908 [info ] [MainThread]: Connection:
[0m13:01:32.922113 [info ] [MainThread]:   account: VRXDFZX-ZZ95717
[0m13:01:32.922260 [info ] [MainThread]:   user: JULIUSRECHENBACH
[0m13:01:32.922403 [info ] [MainThread]:   database: MERCURIOS_DATA
[0m13:01:32.922543 [info ] [MainThread]:   warehouse: MERCURIOS_DEV_WH
[0m13:01:32.922686 [info ] [MainThread]:   role: MERCURIOS_DEVELOPER
[0m13:01:32.922822 [info ] [MainThread]:   schema: staging
[0m13:01:32.922958 [info ] [MainThread]:   authenticator: externalbrowser
[0m13:01:32.923347 [info ] [MainThread]:   oauth_client_id: None
[0m13:01:32.923577 [info ] [MainThread]:   query_tag: dbt_mercurios_dev
[0m13:01:32.923741 [info ] [MainThread]:   client_session_keep_alive: True
[0m13:01:32.923899 [info ] [MainThread]:   host: None
[0m13:01:32.924039 [info ] [MainThread]:   port: None
[0m13:01:32.924184 [info ] [MainThread]:   proxy_host: None
[0m13:01:32.924329 [info ] [MainThread]:   proxy_port: None
[0m13:01:32.924466 [info ] [MainThread]:   protocol: None
[0m13:01:32.924603 [info ] [MainThread]:   connect_retries: 3
[0m13:01:32.924733 [info ] [MainThread]:   connect_timeout: 30
[0m13:01:32.924865 [info ] [MainThread]:   retry_on_database_errors: True
[0m13:01:32.924997 [info ] [MainThread]:   retry_all: False
[0m13:01:32.925126 [info ] [MainThread]:   insecure_mode: False
[0m13:01:32.925262 [info ] [MainThread]:   reuse_connections: True
[0m13:01:32.925963 [info ] [MainThread]: Registered adapter: snowflake=1.9.1
[0m13:01:33.004158 [debug] [MainThread]: Acquiring new snowflake connection 'debug'
[0m13:01:33.038621 [debug] [MainThread]: Using snowflake connection "debug"
[0m13:01:33.038923 [debug] [MainThread]: On debug: select 1 as id
[0m13:01:33.039094 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:01:33.358977 [debug] [MainThread]: Snowflake adapter: Got a retryable error when attempting to open a snowflake connection.
3 attempts remaining. Retrying in 30 seconds.
Error:
390190 (08001): Failed to connect to DB: VRXDFZX-ZZ95717.snowflakecomputing.com:443, There was an error related to the SAML Identity Provider account parameter. Contact Snowflake support.
[0m13:02:03.571830 [debug] [MainThread]: Snowflake adapter: Got a retryable error when attempting to open a snowflake connection.
2 attempts remaining. Retrying in 30 seconds.
Error:
390190 (08001): Failed to connect to DB: VRXDFZX-ZZ95717.snowflakecomputing.com:443, There was an error related to the SAML Identity Provider account parameter. Contact Snowflake support.
[0m13:02:33.813600 [debug] [MainThread]: Snowflake adapter: Got a retryable error when attempting to open a snowflake connection.
1 attempts remaining. Retrying in 30 seconds.
Error:
390190 (08001): Failed to connect to DB: VRXDFZX-ZZ95717.snowflakecomputing.com:443, There was an error related to the SAML Identity Provider account parameter. Contact Snowflake support.
[0m13:03:04.540665 [debug] [MainThread]: Snowflake adapter: Error running SQL: select 1 as id
[0m13:03:04.541797 [debug] [MainThread]: Snowflake adapter: Rolling back transaction.
[0m13:03:04.542728 [info ] [MainThread]:   Connection test: [[31mERROR[0m]

[0m13:03:04.543213 [info ] [MainThread]: [31m1 check failed:[0m
[0m13:03:04.543461 [info ] [MainThread]: dbt was unable to connect to the specified database.
The database returned the following error:

  >Database Error
  390190 (08001): Failed to connect to DB: VRXDFZX-ZZ95717.snowflakecomputing.com:443, There was an error related to the SAML Identity Provider account parameter. Contact Snowflake support.

Check your database credentials and try again. For more information, visit:
https://docs.getdbt.com/docs/configure-your-profile


[0m13:03:04.588104 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 92.83834, "process_in_blocks": "0", "process_kernel_time": 1.261479, "process_mem_max_rss": "178339840", "process_out_blocks": "0", "process_user_time": 2.576172}
[0m13:03:04.588683 [debug] [MainThread]: Command `dbt debug` failed at 13:03:04.588574 after 92.84 seconds
[0m13:03:04.589143 [debug] [MainThread]: Connection 'debug' was left open.
[0m13:03:04.589389 [debug] [MainThread]: On debug: No close available on handle
[0m13:03:04.589817 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c565450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f80add0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12e8c14d0>]}
[0m13:03:04.590272 [debug] [MainThread]: Flushing usage events
[0m13:03:05.159879 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:04:45.469259 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1117e5ed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11184c390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11184d7d0>]}


============================== 13:04:45.472750 | 222ae912-bd46-46f5-8adc-2ed8906ecb6e ==============================
[0m13:04:45.472750 [info ] [MainThread]: Running with dbt=1.9.2
[0m13:04:45.473197 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/logs', 'profiles_dir': '/Users/juliusrechenbach/API ProHandelTest/dbt_mercurios', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt debug', 'send_anonymous_usage_stats': 'True'}
[0m13:04:45.483004 [info ] [MainThread]: dbt version: 1.9.2
[0m13:04:45.483328 [info ] [MainThread]: python version: 3.11.1
[0m13:04:45.483527 [info ] [MainThread]: python path: /Users/juliusrechenbach/API ProHandelTest/.venv/bin/python
[0m13:04:45.483690 [info ] [MainThread]: os info: macOS-15.3.1-arm64-arm-64bit
[0m13:04:46.252101 [info ] [MainThread]: Using profiles dir at /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios
[0m13:04:46.252503 [info ] [MainThread]: Using profiles.yml file at /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/profiles.yml
[0m13:04:46.252668 [info ] [MainThread]: Using dbt_project.yml file at /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/dbt_project.yml
[0m13:04:46.254996 [info ] [MainThread]: adapter type: duckdb
[0m13:04:46.255358 [info ] [MainThread]: adapter version: 1.9.2
[0m13:04:46.314790 [info ] [MainThread]: Configuration:
[0m13:04:46.315122 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m13:04:46.315283 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m13:04:46.315433 [info ] [MainThread]: Required dependencies:
[0m13:04:46.315628 [debug] [MainThread]: Executing "git --help"
[0m13:04:46.331125 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m13:04:46.331663 [debug] [MainThread]: STDERR: "b''"
[0m13:04:46.331860 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m13:04:46.332048 [info ] [MainThread]: Connection:
[0m13:04:46.332266 [info ] [MainThread]:   database: dbt_mercurios_dev
[0m13:04:46.332410 [info ] [MainThread]:   schema: main
[0m13:04:46.332550 [info ] [MainThread]:   path: ./dbt_mercurios_dev.duckdb
[0m13:04:46.332691 [info ] [MainThread]:   config_options: None
[0m13:04:46.332825 [info ] [MainThread]:   extensions: None
[0m13:04:46.333015 [info ] [MainThread]:   settings: {}
[0m13:04:46.333150 [info ] [MainThread]:   external_root: .
[0m13:04:46.333324 [info ] [MainThread]:   use_credential_provider: None
[0m13:04:46.333460 [info ] [MainThread]:   attach: None
[0m13:04:46.333595 [info ] [MainThread]:   filesystems: None
[0m13:04:46.333734 [info ] [MainThread]:   remote: None
[0m13:04:46.333870 [info ] [MainThread]:   plugins: None
[0m13:04:46.334014 [info ] [MainThread]:   disable_transactions: False
[0m13:04:46.334363 [info ] [MainThread]: Registered adapter: duckdb=1.9.2
[0m13:04:46.389320 [debug] [MainThread]: Acquiring new duckdb connection 'debug'
[0m13:04:46.414437 [debug] [MainThread]: Using duckdb connection "debug"
[0m13:04:46.414696 [debug] [MainThread]: On debug: select 1 as id
[0m13:04:46.414859 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:04:46.428497 [debug] [MainThread]: SQL status: OK in 0.014 seconds
[0m13:04:46.429068 [debug] [MainThread]: On debug: Close
[0m13:04:46.429302 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m13:04:46.429476 [info ] [MainThread]: [32mAll checks passed![0m
[0m13:04:46.430860 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 1.0089302, "process_in_blocks": "0", "process_kernel_time": 0.348478, "process_mem_max_rss": "134987776", "process_out_blocks": "0", "process_user_time": 0.869841}
[0m13:04:46.431099 [debug] [MainThread]: Command `dbt debug` succeeded at 13:04:46.431052 after 1.01 seconds
[0m13:04:46.431278 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m13:04:46.431486 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111a11ed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112054990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111ab1e90>]}
[0m13:04:46.431725 [debug] [MainThread]: Flushing usage events
[0m13:04:47.002324 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:04:47.951265 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c1e5c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c24c550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c24c690>]}


============================== 13:04:47.953780 | 543c351c-04bf-4044-afc3-3b775566b087 ==============================
[0m13:04:47.953780 [info ] [MainThread]: Running with dbt=1.9.2
[0m13:04:47.954111 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/juliusrechenbach/API ProHandelTest/dbt_mercurios', 'debug': 'False', 'warn_error': 'None', 'log_path': '/Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt deps', 'send_anonymous_usage_stats': 'True'}
[0m13:04:48.033967 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '543c351c-04bf-4044-afc3-3b775566b087', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c40a0d0>]}
[0m13:04:48.059402 [debug] [MainThread]: Set downloads directory='/var/folders/41/fgfhmfrx04584bv_ztsg5_2m0000gn/T/dbt-downloads-1mhf_16c'
[0m13:04:48.059714 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m13:04:48.255247 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m13:04:48.255817 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m13:04:48.377041 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m13:04:48.380769 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m13:04:48.786603 [info ] [MainThread]: Installed from version 1.1.1
[0m13:04:48.786908 [info ] [MainThread]: Updated version available: 1.3.0
[0m13:04:48.787305 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '543c351c-04bf-4044-afc3-3b775566b087', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c297ad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c4f6fd0>]}
[0m13:04:48.787609 [info ] [MainThread]: 
[0m13:04:48.787809 [info ] [MainThread]: Updates available for packages: ['dbt-labs/dbt_utils']                 
Update your versions in packages.yml, then run dbt deps
[0m13:04:48.789087 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.880677, "process_in_blocks": "0", "process_kernel_time": 0.205511, "process_mem_max_rss": "114376704", "process_out_blocks": "0", "process_user_time": 0.746469}
[0m13:04:48.789346 [debug] [MainThread]: Command `dbt deps` succeeded at 13:04:48.789295 after 0.88 seconds
[0m13:04:48.789568 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10445a050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104459610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104459f50>]}
[0m13:04:48.789774 [debug] [MainThread]: Flushing usage events
[0m13:04:49.386556 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:04:51.002117 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cde4750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ce6a490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ce6ac10>]}


============================== 13:04:51.004758 | 18a54f75-fa5a-4c56-ae98-ecd8ced77160 ==============================
[0m13:04:51.004758 [info ] [MainThread]: Running with dbt=1.9.2
[0m13:04:51.005182 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/logs', 'debug': 'False', 'profiles_dir': '/Users/juliusrechenbach/API ProHandelTest/dbt_mercurios', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt run --models staging', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m13:04:51.160780 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '18a54f75-fa5a-4c56-ae98-ecd8ced77160', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cdf7250>]}
[0m13:04:51.200022 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '18a54f75-fa5a-4c56-ae98-ecd8ced77160', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104bae590>]}
[0m13:04:51.202593 [info ] [MainThread]: Registered adapter: duckdb=1.9.2
[0m13:04:51.266495 [debug] [MainThread]: checksum: 12b12750b70de726cfd89136b8e24afc3f3e77597a97bff40ab7e5f9b39d5e18, vars: {}, profile: , target: , version: 1.9.2
[0m13:04:51.323575 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m13:04:51.324399 [info ] [MainThread]: Unable to do partial parsing because a project dependency has been added
[0m13:04:51.324863 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '18a54f75-fa5a-4c56-ae98-ecd8ced77160', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c6f7cd0>]}
[0m13:04:52.160365 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.mercurios.marts.sales
[0m13:04:52.167757 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '18a54f75-fa5a-4c56-ae98-ecd8ced77160', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d3ca990>]}
[0m13:04:52.215247 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/target/manifest.json
[0m13:04:52.216594 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/target/semantic_manifest.json
[0m13:04:52.227830 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '18a54f75-fa5a-4c56-ae98-ecd8ced77160', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d8d3590>]}
[0m13:04:52.228223 [info ] [MainThread]: Found 9 models, 17 data tests, 3 sources, 540 macros
[0m13:04:52.228430 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '18a54f75-fa5a-4c56-ae98-ecd8ced77160', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d9b42d0>]}
[0m13:04:52.229393 [info ] [MainThread]: 
[0m13:04:52.229588 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m13:04:52.229751 [info ] [MainThread]: 
[0m13:04:52.230005 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m13:04:52.232515 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_dbt_mercurios_dev'
[0m13:04:52.262051 [debug] [ThreadPool]: Using duckdb connection "list_dbt_mercurios_dev"
[0m13:04:52.262357 [debug] [ThreadPool]: On list_dbt_mercurios_dev: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "list_dbt_mercurios_dev"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"dbt_mercurios_dev"'
    
  
  
[0m13:04:52.262536 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:04:52.271732 [debug] [ThreadPool]: SQL status: OK in 0.009 seconds
[0m13:04:52.272562 [debug] [ThreadPool]: On list_dbt_mercurios_dev: Close
[0m13:04:52.273073 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dbt_mercurios_dev, now create_dbt_mercurios_dev_main_staging)
[0m13:04:52.273645 [debug] [ThreadPool]: Creating schema "database: "dbt_mercurios_dev"
schema: "main_staging"
"
[0m13:04:52.277257 [debug] [ThreadPool]: Using duckdb connection "create_dbt_mercurios_dev_main_staging"
[0m13:04:52.277462 [debug] [ThreadPool]: On create_dbt_mercurios_dev_main_staging: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "create_dbt_mercurios_dev_main_staging"} */

    
        select type from duckdb_databases()
        where lower(database_name)='dbt_mercurios_dev'
        and type='sqlite'
    
  
[0m13:04:52.277618 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:04:52.278079 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m13:04:52.278710 [debug] [ThreadPool]: Using duckdb connection "create_dbt_mercurios_dev_main_staging"
[0m13:04:52.278892 [debug] [ThreadPool]: On create_dbt_mercurios_dev_main_staging: BEGIN
[0m13:04:52.279109 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m13:04:52.279249 [debug] [ThreadPool]: Using duckdb connection "create_dbt_mercurios_dev_main_staging"
[0m13:04:52.279395 [debug] [ThreadPool]: On create_dbt_mercurios_dev_main_staging: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "create_dbt_mercurios_dev_main_staging"} */

    
    
        create schema if not exists "dbt_mercurios_dev"."main_staging"
    
[0m13:04:52.279778 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m13:04:52.280355 [debug] [ThreadPool]: On create_dbt_mercurios_dev_main_staging: COMMIT
[0m13:04:52.280558 [debug] [ThreadPool]: Using duckdb connection "create_dbt_mercurios_dev_main_staging"
[0m13:04:52.280729 [debug] [ThreadPool]: On create_dbt_mercurios_dev_main_staging: COMMIT
[0m13:04:52.281232 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m13:04:52.281401 [debug] [ThreadPool]: On create_dbt_mercurios_dev_main_staging: Close
[0m13:04:52.282236 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_dbt_mercurios_dev_main_staging, now list_dbt_mercurios_dev_main_staging)
[0m13:04:52.282633 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_dbt_mercurios_dev_main_intermediate'
[0m13:04:52.286005 [debug] [ThreadPool]: Using duckdb connection "list_dbt_mercurios_dev_main_staging"
[0m13:04:52.286255 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_dbt_mercurios_dev_main_marts_inventory'
[0m13:04:52.326727 [debug] [ThreadPool]: Using duckdb connection "list_dbt_mercurios_dev_main_intermediate"
[0m13:04:52.327030 [debug] [ThreadPool]: On list_dbt_mercurios_dev_main_staging: BEGIN
[0m13:04:52.328442 [debug] [ThreadPool]: Using duckdb connection "list_dbt_mercurios_dev_main_marts_inventory"
[0m13:04:52.328690 [debug] [ThreadPool]: On list_dbt_mercurios_dev_main_intermediate: BEGIN
[0m13:04:52.328850 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:04:52.329002 [debug] [ThreadPool]: On list_dbt_mercurios_dev_main_marts_inventory: BEGIN
[0m13:04:52.329242 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:04:52.329726 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:04:52.329929 [debug] [ThreadPool]: SQL status: OK in 0.001 seconds
[0m13:04:52.330270 [debug] [ThreadPool]: SQL status: OK in 0.001 seconds
[0m13:04:52.330481 [debug] [ThreadPool]: Using duckdb connection "list_dbt_mercurios_dev_main_staging"
[0m13:04:52.330657 [debug] [ThreadPool]: SQL status: OK in 0.001 seconds
[0m13:04:52.330838 [debug] [ThreadPool]: Using duckdb connection "list_dbt_mercurios_dev_main_intermediate"
[0m13:04:52.331019 [debug] [ThreadPool]: On list_dbt_mercurios_dev_main_staging: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "list_dbt_mercurios_dev_main_staging"} */
select
      'dbt_mercurios_dev' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_staging'
    and lower(table_catalog) = 'dbt_mercurios_dev'
  
[0m13:04:52.331194 [debug] [ThreadPool]: Using duckdb connection "list_dbt_mercurios_dev_main_marts_inventory"
[0m13:04:52.331421 [debug] [ThreadPool]: On list_dbt_mercurios_dev_main_intermediate: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "list_dbt_mercurios_dev_main_intermediate"} */
select
      'dbt_mercurios_dev' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_intermediate'
    and lower(table_catalog) = 'dbt_mercurios_dev'
  
[0m13:04:52.331745 [debug] [ThreadPool]: On list_dbt_mercurios_dev_main_marts_inventory: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "list_dbt_mercurios_dev_main_marts_inventory"} */
select
      'dbt_mercurios_dev' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_marts_inventory'
    and lower(table_catalog) = 'dbt_mercurios_dev'
  
[0m13:04:52.342158 [debug] [ThreadPool]: SQL status: OK in 0.010 seconds
[0m13:04:52.342938 [debug] [ThreadPool]: On list_dbt_mercurios_dev_main_marts_inventory: ROLLBACK
[0m13:04:52.343244 [debug] [ThreadPool]: SQL status: OK in 0.011 seconds
[0m13:04:52.343469 [debug] [ThreadPool]: SQL status: OK in 0.012 seconds
[0m13:04:52.344268 [debug] [ThreadPool]: On list_dbt_mercurios_dev_main_intermediate: ROLLBACK
[0m13:04:52.344682 [debug] [ThreadPool]: Failed to rollback 'list_dbt_mercurios_dev_main_intermediate'
[0m13:04:52.344856 [debug] [ThreadPool]: On list_dbt_mercurios_dev_main_intermediate: Close
[0m13:04:52.345138 [debug] [ThreadPool]: Failed to rollback 'list_dbt_mercurios_dev_main_marts_inventory'
[0m13:04:52.345750 [debug] [ThreadPool]: On list_dbt_mercurios_dev_main_staging: ROLLBACK
[0m13:04:52.346083 [debug] [ThreadPool]: On list_dbt_mercurios_dev_main_marts_inventory: Close
[0m13:04:52.346369 [debug] [ThreadPool]: Failed to rollback 'list_dbt_mercurios_dev_main_staging'
[0m13:04:52.346577 [debug] [ThreadPool]: On list_dbt_mercurios_dev_main_staging: Close
[0m13:04:52.347059 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '18a54f75-fa5a-4c56-ae98-ecd8ced77160', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d888e10>]}
[0m13:04:52.347354 [debug] [MainThread]: Using duckdb connection "master"
[0m13:04:52.347509 [debug] [MainThread]: On master: BEGIN
[0m13:04:52.347652 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:04:52.347951 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m13:04:52.348095 [debug] [MainThread]: On master: COMMIT
[0m13:04:52.348236 [debug] [MainThread]: Using duckdb connection "master"
[0m13:04:52.348379 [debug] [MainThread]: On master: COMMIT
[0m13:04:52.348601 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m13:04:52.348782 [debug] [MainThread]: On master: Close
[0m13:04:52.349547 [debug] [Thread-1 (]: Began running node model.mercurios.stg_prohandel__articles
[0m13:04:52.349981 [info ] [Thread-1 (]: 1 of 3 START sql view model main_staging.stg_prohandel__articles ............... [RUN]
[0m13:04:52.350234 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_dbt_mercurios_dev_main_staging, now model.mercurios.stg_prohandel__articles)
[0m13:04:52.350427 [debug] [Thread-1 (]: Began compiling node model.mercurios.stg_prohandel__articles
[0m13:04:52.354510 [debug] [Thread-1 (]: Writing injected SQL for node "model.mercurios.stg_prohandel__articles"
[0m13:04:52.354772 [debug] [Thread-2 (]: Began running node model.mercurios.stg_prohandel__inventory
[0m13:04:52.355025 [debug] [Thread-3 (]: Began running node model.mercurios.stg_prohandel__sales
[0m13:04:52.355276 [info ] [Thread-2 (]: 2 of 3 START sql view model main_staging.stg_prohandel__inventory .............. [RUN]
[0m13:04:52.355680 [info ] [Thread-3 (]: 3 of 3 START sql view model main_staging.stg_prohandel__sales .................. [RUN]
[0m13:04:52.356047 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_dbt_mercurios_dev_main_intermediate, now model.mercurios.stg_prohandel__inventory)
[0m13:04:52.356251 [debug] [Thread-1 (]: Began executing node model.mercurios.stg_prohandel__articles
[0m13:04:52.356509 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_dbt_mercurios_dev_main_marts_inventory, now model.mercurios.stg_prohandel__sales)
[0m13:04:52.356715 [debug] [Thread-2 (]: Began compiling node model.mercurios.stg_prohandel__inventory
[0m13:04:52.372361 [debug] [Thread-1 (]: Writing runtime sql for node "model.mercurios.stg_prohandel__articles"
[0m13:04:52.372595 [debug] [Thread-3 (]: Began compiling node model.mercurios.stg_prohandel__sales
[0m13:04:52.374426 [debug] [Thread-2 (]: Writing injected SQL for node "model.mercurios.stg_prohandel__inventory"
[0m13:04:52.376216 [debug] [Thread-3 (]: Writing injected SQL for node "model.mercurios.stg_prohandel__sales"
[0m13:04:52.376699 [debug] [Thread-1 (]: Using duckdb connection "model.mercurios.stg_prohandel__articles"
[0m13:04:52.376934 [debug] [Thread-1 (]: On model.mercurios.stg_prohandel__articles: BEGIN
[0m13:04:52.377136 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:04:52.377435 [debug] [Thread-2 (]: Began executing node model.mercurios.stg_prohandel__inventory
[0m13:04:52.379358 [debug] [Thread-2 (]: Writing runtime sql for node "model.mercurios.stg_prohandel__inventory"
[0m13:04:52.379547 [debug] [Thread-1 (]: SQL status: OK in 0.002 seconds
[0m13:04:52.379735 [debug] [Thread-3 (]: Began executing node model.mercurios.stg_prohandel__sales
[0m13:04:52.380007 [debug] [Thread-1 (]: Using duckdb connection "model.mercurios.stg_prohandel__articles"
[0m13:04:52.381846 [debug] [Thread-3 (]: Writing runtime sql for node "model.mercurios.stg_prohandel__sales"
[0m13:04:52.382123 [debug] [Thread-1 (]: On model.mercurios.stg_prohandel__articles: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "node_id": "model.mercurios.stg_prohandel__articles"} */

  
  create view "dbt_mercurios_dev"."main_staging"."stg_prohandel__articles__dbt_tmp" as (
    with source as (
    select * from "MERCURIOS_DATA"."RAW"."article"
),

renamed as (
    select
        article_id,
        article_number,
        description,
        category,
        subcategory,
        brand,
        supplier,
        purchase_price,
        retail_price,
        min_stock_level,
        max_stock_level,
        reorder_point,
        lead_time_days,
        is_active,
        
        -- Calculate profit margin
        (retail_price - purchase_price) as profit_margin,
        case 
            when (purchase_price > 0) then ((retail_price - purchase_price) / purchase_price) * 100 
            else null 
        end as profit_margin_percent,
        
        -- Add price tier categorization
        case
            when retail_price < 10 then 'Budget'
            when retail_price >= 10 and retail_price < 50 then 'Standard'
            when retail_price >= 50 and retail_price < 100 then 'Premium'
            when retail_price >= 100 then 'Luxury'
            else 'Uncategorized'
        end as price_tier,
        
        created_at,
        updated_at,
        tenant_id,
        
        -- Fivetran metadata
        _fivetran_synced,
        
        -- Add data quality flags
        case when description is null or description = '' then true else false end as is_missing_description,
        case when purchase_price is null or purchase_price = 0 then true else false end as is_missing_purchase_price,
        case when retail_price is null or retail_price = 0 then true else false end as is_missing_retail_price
    from source
)

select * from renamed
  );

[0m13:04:52.382387 [debug] [Thread-2 (]: Using duckdb connection "model.mercurios.stg_prohandel__inventory"
[0m13:04:52.382783 [debug] [Thread-2 (]: On model.mercurios.stg_prohandel__inventory: BEGIN
[0m13:04:52.383030 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m13:04:52.383236 [debug] [Thread-3 (]: Using duckdb connection "model.mercurios.stg_prohandel__sales"
[0m13:04:52.383502 [debug] [Thread-3 (]: On model.mercurios.stg_prohandel__sales: BEGIN
[0m13:04:52.383842 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "node_id": "model.mercurios.stg_prohandel__articles"} */

  
  create view "dbt_mercurios_dev"."main_staging"."stg_prohandel__articles__dbt_tmp" as (
    with source as (
    select * from "MERCURIOS_DATA"."RAW"."article"
),

renamed as (
    select
        article_id,
        article_number,
        description,
        category,
        subcategory,
        brand,
        supplier,
        purchase_price,
        retail_price,
        min_stock_level,
        max_stock_level,
        reorder_point,
        lead_time_days,
        is_active,
        
        -- Calculate profit margin
        (retail_price - purchase_price) as profit_margin,
        case 
            when (purchase_price > 0) then ((retail_price - purchase_price) / purchase_price) * 100 
            else null 
        end as profit_margin_percent,
        
        -- Add price tier categorization
        case
            when retail_price < 10 then 'Budget'
            when retail_price >= 10 and retail_price < 50 then 'Standard'
            when retail_price >= 50 and retail_price < 100 then 'Premium'
            when retail_price >= 100 then 'Luxury'
            else 'Uncategorized'
        end as price_tier,
        
        created_at,
        updated_at,
        tenant_id,
        
        -- Fivetran metadata
        _fivetran_synced,
        
        -- Add data quality flags
        case when description is null or description = '' then true else false end as is_missing_description,
        case when purchase_price is null or purchase_price = 0 then true else false end as is_missing_purchase_price,
        case when retail_price is null or retail_price = 0 then true else false end as is_missing_retail_price
    from source
)

select * from renamed
  );

[0m13:04:52.384151 [debug] [Thread-2 (]: SQL status: OK in 0.001 seconds
[0m13:04:52.384346 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m13:04:52.384531 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m13:04:52.384712 [debug] [Thread-2 (]: Using duckdb connection "model.mercurios.stg_prohandel__inventory"
[0m13:04:52.385040 [debug] [Thread-1 (]: On model.mercurios.stg_prohandel__articles: ROLLBACK
[0m13:04:52.385223 [debug] [Thread-3 (]: SQL status: OK in 0.001 seconds
[0m13:04:52.385426 [debug] [Thread-2 (]: On model.mercurios.stg_prohandel__inventory: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "node_id": "model.mercurios.stg_prohandel__inventory"} */

  
  create view "dbt_mercurios_dev"."main_staging"."stg_prohandel__inventory__dbt_tmp" as (
    with source as (
    select * from "MERCURIOS_DATA"."RAW"."inventory"
),

renamed as (
    select
        inventory_id,
        article_id,
        warehouse_id,
        quantity,
        
        -- Add stock level categorization
        case
            when quantity <= 0 then 'Out of Stock'
            when quantity <= 5 then 'Low Stock'
            when quantity <= 20 then 'Medium Stock'
            when quantity > 20 then 'High Stock'
            else 'Unknown'
        end as stock_level,
        
        -- Add reorder flag
        case
            when quantity <= 5 then true
            else false
        end as needs_reorder,
        
        location,
        last_count_date,
        is_available,
        tenant_id,
        
        -- Fivetran metadata
        _fivetran_synced,
        
        -- Add data quality flags
        case when quantity < 0 then true else false end as is_negative_quantity
    from source
)

select * from renamed
  );

[0m13:04:52.386165 [debug] [Thread-3 (]: Using duckdb connection "model.mercurios.stg_prohandel__sales"
[0m13:04:52.386511 [debug] [Thread-3 (]: On model.mercurios.stg_prohandel__sales: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "node_id": "model.mercurios.stg_prohandel__sales"} */

  
  create view "dbt_mercurios_dev"."main_staging"."stg_prohandel__sales__dbt_tmp" as (
    with source as (
    select * from "MERCURIOS_DATA"."RAW"."sale"
),

renamed as (
    select
        sale_id,
        order_id,
        article_id,
        quantity,
        price,
        discount,
        
        -- Calculate net price and revenue
        (price - coalesce(discount, 0)) as net_price,
        (price - coalesce(discount, 0)) * quantity as revenue,
        
        -- Add sale type categorization
        case
            when discount is null or discount = 0 then 'Regular'
            when discount > 0 and discount < (price * 0.1) then 'Small Discount'
            when discount >= (price * 0.1) and discount < (price * 0.3) then 'Medium Discount'
            when discount >= (price * 0.3) then 'Large Discount'
            else 'Unknown'
        end as sale_type,
        
        sale_date,
        shop_id,
        tenant_id,
        
        -- Fivetran metadata
        _fivetran_synced,
        
        -- Add data quality flags
        case when quantity <= 0 then true else false end as is_invalid_quantity,
        case when price <= 0 then true else false end as is_invalid_price,
        case when discount > price then true else false end as is_discount_greater_than_price
    from source
)

select * from renamed
  );

[0m13:04:52.386924 [debug] [Thread-2 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "node_id": "model.mercurios.stg_prohandel__inventory"} */

  
  create view "dbt_mercurios_dev"."main_staging"."stg_prohandel__inventory__dbt_tmp" as (
    with source as (
    select * from "MERCURIOS_DATA"."RAW"."inventory"
),

renamed as (
    select
        inventory_id,
        article_id,
        warehouse_id,
        quantity,
        
        -- Add stock level categorization
        case
            when quantity <= 0 then 'Out of Stock'
            when quantity <= 5 then 'Low Stock'
            when quantity <= 20 then 'Medium Stock'
            when quantity > 20 then 'High Stock'
            else 'Unknown'
        end as stock_level,
        
        -- Add reorder flag
        case
            when quantity <= 5 then true
            else false
        end as needs_reorder,
        
        location,
        last_count_date,
        is_available,
        tenant_id,
        
        -- Fivetran metadata
        _fivetran_synced,
        
        -- Add data quality flags
        case when quantity < 0 then true else false end as is_negative_quantity
    from source
)

select * from renamed
  );

[0m13:04:52.387558 [debug] [Thread-2 (]: DuckDB adapter: Rolling back transaction.
[0m13:04:52.387927 [debug] [Thread-3 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "node_id": "model.mercurios.stg_prohandel__sales"} */

  
  create view "dbt_mercurios_dev"."main_staging"."stg_prohandel__sales__dbt_tmp" as (
    with source as (
    select * from "MERCURIOS_DATA"."RAW"."sale"
),

renamed as (
    select
        sale_id,
        order_id,
        article_id,
        quantity,
        price,
        discount,
        
        -- Calculate net price and revenue
        (price - coalesce(discount, 0)) as net_price,
        (price - coalesce(discount, 0)) * quantity as revenue,
        
        -- Add sale type categorization
        case
            when discount is null or discount = 0 then 'Regular'
            when discount > 0 and discount < (price * 0.1) then 'Small Discount'
            when discount >= (price * 0.1) and discount < (price * 0.3) then 'Medium Discount'
            when discount >= (price * 0.3) then 'Large Discount'
            else 'Unknown'
        end as sale_type,
        
        sale_date,
        shop_id,
        tenant_id,
        
        -- Fivetran metadata
        _fivetran_synced,
        
        -- Add data quality flags
        case when quantity <= 0 then true else false end as is_invalid_quantity,
        case when price <= 0 then true else false end as is_invalid_price,
        case when discount > price then true else false end as is_discount_greater_than_price
    from source
)

select * from renamed
  );

[0m13:04:52.388265 [debug] [Thread-2 (]: On model.mercurios.stg_prohandel__inventory: ROLLBACK
[0m13:04:52.388510 [debug] [Thread-3 (]: DuckDB adapter: Rolling back transaction.
[0m13:04:52.389396 [debug] [Thread-3 (]: On model.mercurios.stg_prohandel__sales: ROLLBACK
[0m13:04:52.394800 [debug] [Thread-3 (]: Failed to rollback 'model.mercurios.stg_prohandel__sales'
[0m13:04:52.395603 [debug] [Thread-1 (]: Failed to rollback 'model.mercurios.stg_prohandel__articles'
[0m13:04:52.396345 [debug] [Thread-2 (]: Failed to rollback 'model.mercurios.stg_prohandel__inventory'
[0m13:04:52.396573 [debug] [Thread-3 (]: On model.mercurios.stg_prohandel__sales: Close
[0m13:04:52.396794 [debug] [Thread-1 (]: On model.mercurios.stg_prohandel__articles: Close
[0m13:04:52.396982 [debug] [Thread-2 (]: On model.mercurios.stg_prohandel__inventory: Close
[0m13:04:52.399491 [debug] [Thread-3 (]: Runtime Error in model stg_prohandel__sales (models/staging/stg_prohandel__sales.sql)
  Binder Error: Catalog "MERCURIOS_DATA" does not exist!
[0m13:04:52.400999 [debug] [Thread-1 (]: Runtime Error in model stg_prohandel__articles (models/staging/stg_prohandel__articles.sql)
  Binder Error: Catalog "MERCURIOS_DATA" does not exist!
[0m13:04:52.401758 [debug] [Thread-2 (]: Runtime Error in model stg_prohandel__inventory (models/staging/stg_prohandel__inventory.sql)
  Binder Error: Catalog "MERCURIOS_DATA" does not exist!
[0m13:04:52.402158 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '18a54f75-fa5a-4c56-ae98-ecd8ced77160', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d6fd190>]}
[0m13:04:52.402327 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '18a54f75-fa5a-4c56-ae98-ecd8ced77160', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d6fc950>]}
[0m13:04:52.402493 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '18a54f75-fa5a-4c56-ae98-ecd8ced77160', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d70d610>]}
[0m13:04:52.402848 [error] [Thread-3 (]: 3 of 3 ERROR creating sql view model main_staging.stg_prohandel__sales ......... [[31mERROR[0m in 0.04s]
[0m13:04:52.403177 [error] [Thread-1 (]: 1 of 3 ERROR creating sql view model main_staging.stg_prohandel__articles ...... [[31mERROR[0m in 0.05s]
[0m13:04:52.403788 [debug] [Thread-3 (]: Finished running node model.mercurios.stg_prohandel__sales
[0m13:04:52.403511 [error] [Thread-2 (]: 2 of 3 ERROR creating sql view model main_staging.stg_prohandel__inventory ..... [[31mERROR[0m in 0.05s]
[0m13:04:52.404101 [debug] [Thread-1 (]: Finished running node model.mercurios.stg_prohandel__articles
[0m13:04:52.404349 [debug] [Thread-7 (]: Marking all children of 'model.mercurios.stg_prohandel__sales' to be skipped because of status 'error'.  Reason: Runtime Error in model stg_prohandel__sales (models/staging/stg_prohandel__sales.sql)
  Binder Error: Catalog "MERCURIOS_DATA" does not exist!.
[0m13:04:52.404604 [debug] [Thread-2 (]: Finished running node model.mercurios.stg_prohandel__inventory
[0m13:04:52.405174 [debug] [Thread-7 (]: Marking all children of 'model.mercurios.stg_prohandel__articles' to be skipped because of status 'error'.  Reason: Runtime Error in model stg_prohandel__articles (models/staging/stg_prohandel__articles.sql)
  Binder Error: Catalog "MERCURIOS_DATA" does not exist!.
[0m13:04:52.405458 [debug] [Thread-7 (]: Marking all children of 'model.mercurios.stg_prohandel__inventory' to be skipped because of status 'error'.  Reason: Runtime Error in model stg_prohandel__inventory (models/staging/stg_prohandel__inventory.sql)
  Binder Error: Catalog "MERCURIOS_DATA" does not exist!.
[0m13:04:52.406091 [debug] [MainThread]: Using duckdb connection "master"
[0m13:04:52.406257 [debug] [MainThread]: On master: BEGIN
[0m13:04:52.406398 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m13:04:52.406753 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m13:04:52.406922 [debug] [MainThread]: On master: COMMIT
[0m13:04:52.407078 [debug] [MainThread]: Using duckdb connection "master"
[0m13:04:52.407221 [debug] [MainThread]: On master: COMMIT
[0m13:04:52.407438 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m13:04:52.407587 [debug] [MainThread]: On master: Close
[0m13:04:52.407783 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:04:52.407924 [debug] [MainThread]: Connection 'model.mercurios.stg_prohandel__articles' was properly closed.
[0m13:04:52.408057 [debug] [MainThread]: Connection 'model.mercurios.stg_prohandel__inventory' was properly closed.
[0m13:04:52.408188 [debug] [MainThread]: Connection 'model.mercurios.stg_prohandel__sales' was properly closed.
[0m13:04:52.408372 [info ] [MainThread]: 
[0m13:04:52.408541 [info ] [MainThread]: Finished running 3 view models in 0 hours 0 minutes and 0.18 seconds (0.18s).
[0m13:04:52.409125 [debug] [MainThread]: Command end result
[0m13:04:52.427107 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/target/manifest.json
[0m13:04:52.428112 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/target/semantic_manifest.json
[0m13:04:52.431294 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/target/run_results.json
[0m13:04:52.431486 [info ] [MainThread]: 
[0m13:04:52.431693 [info ] [MainThread]: [31mCompleted with 3 errors, 0 partial successes, and 0 warnings:[0m
[0m13:04:52.431862 [info ] [MainThread]: 
[0m13:04:52.432062 [error] [MainThread]:   Runtime Error in model stg_prohandel__sales (models/staging/stg_prohandel__sales.sql)
  Binder Error: Catalog "MERCURIOS_DATA" does not exist!
[0m13:04:52.432215 [info ] [MainThread]: 
[0m13:04:52.432387 [error] [MainThread]:   Runtime Error in model stg_prohandel__articles (models/staging/stg_prohandel__articles.sql)
  Binder Error: Catalog "MERCURIOS_DATA" does not exist!
[0m13:04:52.432532 [info ] [MainThread]: 
[0m13:04:52.432698 [error] [MainThread]:   Runtime Error in model stg_prohandel__inventory (models/staging/stg_prohandel__inventory.sql)
  Binder Error: Catalog "MERCURIOS_DATA" does not exist!
[0m13:04:52.432840 [info ] [MainThread]: 
[0m13:04:52.432998 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=3 SKIP=0 TOTAL=3
[0m13:04:52.433960 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.4735932, "process_in_blocks": "0", "process_kernel_time": 0.254722, "process_mem_max_rss": "150945792", "process_out_blocks": "0", "process_user_time": 1.934222}
[0m13:04:52.434175 [debug] [MainThread]: Command `dbt run` failed at 13:04:52.434137 after 1.47 seconds
[0m13:04:52.434381 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1049121d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d9e8950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d658a50>]}
[0m13:04:52.434578 [debug] [MainThread]: Flushing usage events
[0m13:04:52.949729 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:04:54.056929 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1140e51d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11416e850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11416efd0>]}


============================== 13:04:54.059363 | 931d70a6-9ca7-4502-aece-49a537ae2f4f ==============================
[0m13:04:54.059363 [info ] [MainThread]: Running with dbt=1.9.2
[0m13:04:54.059892 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/juliusrechenbach/API ProHandelTest/dbt_mercurios', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run --models intermediate', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m13:04:54.191508 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '931d70a6-9ca7-4502-aece-49a537ae2f4f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114102610>]}
[0m13:04:54.229517 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '931d70a6-9ca7-4502-aece-49a537ae2f4f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105062d10>]}
[0m13:04:54.231655 [info ] [MainThread]: Registered adapter: duckdb=1.9.2
[0m13:04:54.289457 [debug] [MainThread]: checksum: 12b12750b70de726cfd89136b8e24afc3f3e77597a97bff40ab7e5f9b39d5e18, vars: {}, profile: , target: , version: 1.9.2
[0m13:04:54.353065 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m13:04:54.353384 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m13:04:54.357625 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.mercurios.marts.sales
[0m13:04:54.378470 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '931d70a6-9ca7-4502-aece-49a537ae2f4f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1143836d0>]}
[0m13:04:54.425309 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/target/manifest.json
[0m13:04:54.426437 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/target/semantic_manifest.json
[0m13:04:54.434550 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '931d70a6-9ca7-4502-aece-49a537ae2f4f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1148952d0>]}
[0m13:04:54.434898 [info ] [MainThread]: Found 9 models, 17 data tests, 3 sources, 540 macros
[0m13:04:54.435085 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '931d70a6-9ca7-4502-aece-49a537ae2f4f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1147b3710>]}
[0m13:04:54.435930 [info ] [MainThread]: 
[0m13:04:54.436123 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m13:04:54.436264 [info ] [MainThread]: 
[0m13:04:54.436527 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m13:04:54.437064 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_dbt_mercurios_dev'
[0m13:04:54.492378 [debug] [ThreadPool]: Using duckdb connection "list_dbt_mercurios_dev"
[0m13:04:54.492647 [debug] [ThreadPool]: On list_dbt_mercurios_dev: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "list_dbt_mercurios_dev"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"dbt_mercurios_dev"'
    
  
  
[0m13:04:54.492813 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:04:54.500165 [debug] [ThreadPool]: SQL status: OK in 0.007 seconds
[0m13:04:54.500982 [debug] [ThreadPool]: On list_dbt_mercurios_dev: Close
[0m13:04:54.501352 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dbt_mercurios_dev, now create_dbt_mercurios_dev_main_intermediate)
[0m13:04:54.501593 [debug] [ThreadPool]: Creating schema "database: "dbt_mercurios_dev"
schema: "main_intermediate"
"
[0m13:04:54.505341 [debug] [ThreadPool]: Using duckdb connection "create_dbt_mercurios_dev_main_intermediate"
[0m13:04:54.505590 [debug] [ThreadPool]: On create_dbt_mercurios_dev_main_intermediate: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "create_dbt_mercurios_dev_main_intermediate"} */

    
        select type from duckdb_databases()
        where lower(database_name)='dbt_mercurios_dev'
        and type='sqlite'
    
  
[0m13:04:54.505781 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:04:54.506364 [debug] [ThreadPool]: SQL status: OK in 0.001 seconds
[0m13:04:54.507021 [debug] [ThreadPool]: Using duckdb connection "create_dbt_mercurios_dev_main_intermediate"
[0m13:04:54.507229 [debug] [ThreadPool]: On create_dbt_mercurios_dev_main_intermediate: BEGIN
[0m13:04:54.507454 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m13:04:54.507597 [debug] [ThreadPool]: Using duckdb connection "create_dbt_mercurios_dev_main_intermediate"
[0m13:04:54.507739 [debug] [ThreadPool]: On create_dbt_mercurios_dev_main_intermediate: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "create_dbt_mercurios_dev_main_intermediate"} */

    
    
        create schema if not exists "dbt_mercurios_dev"."main_intermediate"
    
[0m13:04:54.507972 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m13:04:54.508360 [debug] [ThreadPool]: On create_dbt_mercurios_dev_main_intermediate: COMMIT
[0m13:04:54.508509 [debug] [ThreadPool]: Using duckdb connection "create_dbt_mercurios_dev_main_intermediate"
[0m13:04:54.508644 [debug] [ThreadPool]: On create_dbt_mercurios_dev_main_intermediate: COMMIT
[0m13:04:54.509477 [debug] [ThreadPool]: SQL status: OK in 0.001 seconds
[0m13:04:54.509656 [debug] [ThreadPool]: On create_dbt_mercurios_dev_main_intermediate: Close
[0m13:04:54.512350 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_dbt_mercurios_dev_main_intermediate, now list_dbt_mercurios_dev_main_marts_inventory)
[0m13:04:54.512626 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_dbt_mercurios_dev_main_staging'
[0m13:04:54.515387 [debug] [ThreadPool]: Using duckdb connection "list_dbt_mercurios_dev_main_marts_inventory"
[0m13:04:54.515640 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_dbt_mercurios_dev_main_intermediate'
[0m13:04:54.516833 [debug] [ThreadPool]: Using duckdb connection "list_dbt_mercurios_dev_main_staging"
[0m13:04:54.517090 [debug] [ThreadPool]: On list_dbt_mercurios_dev_main_marts_inventory: BEGIN
[0m13:04:54.518293 [debug] [ThreadPool]: Using duckdb connection "list_dbt_mercurios_dev_main_intermediate"
[0m13:04:54.518451 [debug] [ThreadPool]: On list_dbt_mercurios_dev_main_staging: BEGIN
[0m13:04:54.518591 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:04:54.518735 [debug] [ThreadPool]: On list_dbt_mercurios_dev_main_intermediate: BEGIN
[0m13:04:54.518866 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:04:54.519160 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:04:54.519400 [debug] [ThreadPool]: SQL status: OK in 0.001 seconds
[0m13:04:54.519637 [debug] [ThreadPool]: SQL status: OK in 0.001 seconds
[0m13:04:54.519775 [debug] [ThreadPool]: SQL status: OK in 0.001 seconds
[0m13:04:54.519958 [debug] [ThreadPool]: Using duckdb connection "list_dbt_mercurios_dev_main_marts_inventory"
[0m13:04:54.520110 [debug] [ThreadPool]: Using duckdb connection "list_dbt_mercurios_dev_main_staging"
[0m13:04:54.520253 [debug] [ThreadPool]: Using duckdb connection "list_dbt_mercurios_dev_main_intermediate"
[0m13:04:54.520410 [debug] [ThreadPool]: On list_dbt_mercurios_dev_main_marts_inventory: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "list_dbt_mercurios_dev_main_marts_inventory"} */
select
      'dbt_mercurios_dev' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_marts_inventory'
    and lower(table_catalog) = 'dbt_mercurios_dev'
  
[0m13:04:54.520584 [debug] [ThreadPool]: On list_dbt_mercurios_dev_main_staging: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "list_dbt_mercurios_dev_main_staging"} */
select
      'dbt_mercurios_dev' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_staging'
    and lower(table_catalog) = 'dbt_mercurios_dev'
  
[0m13:04:54.520754 [debug] [ThreadPool]: On list_dbt_mercurios_dev_main_intermediate: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "list_dbt_mercurios_dev_main_intermediate"} */
select
      'dbt_mercurios_dev' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_intermediate'
    and lower(table_catalog) = 'dbt_mercurios_dev'
  
[0m13:04:54.531004 [debug] [ThreadPool]: SQL status: OK in 0.010 seconds
[0m13:04:54.531294 [debug] [ThreadPool]: SQL status: OK in 0.010 seconds
[0m13:04:54.532125 [debug] [ThreadPool]: On list_dbt_mercurios_dev_main_marts_inventory: ROLLBACK
[0m13:04:54.532392 [debug] [ThreadPool]: SQL status: OK in 0.011 seconds
[0m13:04:54.533024 [debug] [ThreadPool]: On list_dbt_mercurios_dev_main_staging: ROLLBACK
[0m13:04:54.533815 [debug] [ThreadPool]: On list_dbt_mercurios_dev_main_intermediate: ROLLBACK
[0m13:04:54.534373 [debug] [ThreadPool]: Failed to rollback 'list_dbt_mercurios_dev_main_staging'
[0m13:04:54.534668 [debug] [ThreadPool]: Failed to rollback 'list_dbt_mercurios_dev_main_intermediate'
[0m13:04:54.534906 [debug] [ThreadPool]: Failed to rollback 'list_dbt_mercurios_dev_main_marts_inventory'
[0m13:04:54.535076 [debug] [ThreadPool]: On list_dbt_mercurios_dev_main_staging: Close
[0m13:04:54.535235 [debug] [ThreadPool]: On list_dbt_mercurios_dev_main_intermediate: Close
[0m13:04:54.535409 [debug] [ThreadPool]: On list_dbt_mercurios_dev_main_marts_inventory: Close
[0m13:04:54.536042 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '931d70a6-9ca7-4502-aece-49a537ae2f4f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114788590>]}
[0m13:04:54.536307 [debug] [MainThread]: Using duckdb connection "master"
[0m13:04:54.536452 [debug] [MainThread]: On master: BEGIN
[0m13:04:54.536584 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:04:54.536874 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m13:04:54.537080 [debug] [MainThread]: On master: COMMIT
[0m13:04:54.537281 [debug] [MainThread]: Using duckdb connection "master"
[0m13:04:54.537467 [debug] [MainThread]: On master: COMMIT
[0m13:04:54.537721 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m13:04:54.537880 [debug] [MainThread]: On master: Close
[0m13:04:54.538658 [debug] [Thread-1 (]: Began running node model.mercurios.int_inventory_with_metrics
[0m13:04:54.538968 [info ] [Thread-1 (]: 1 of 1 START sql view model main_intermediate.int_inventory_with_metrics ....... [RUN]
[0m13:04:54.539227 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_dbt_mercurios_dev_main_marts_inventory, now model.mercurios.int_inventory_with_metrics)
[0m13:04:54.539410 [debug] [Thread-1 (]: Began compiling node model.mercurios.int_inventory_with_metrics
[0m13:04:54.544061 [debug] [Thread-1 (]: Writing injected SQL for node "model.mercurios.int_inventory_with_metrics"
[0m13:04:54.544489 [debug] [Thread-1 (]: Began executing node model.mercurios.int_inventory_with_metrics
[0m13:04:54.559698 [debug] [Thread-1 (]: Writing runtime sql for node "model.mercurios.int_inventory_with_metrics"
[0m13:04:54.560765 [debug] [Thread-1 (]: Using duckdb connection "model.mercurios.int_inventory_with_metrics"
[0m13:04:54.561041 [debug] [Thread-1 (]: On model.mercurios.int_inventory_with_metrics: BEGIN
[0m13:04:54.561238 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:04:54.561692 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m13:04:54.561890 [debug] [Thread-1 (]: Using duckdb connection "model.mercurios.int_inventory_with_metrics"
[0m13:04:54.562200 [debug] [Thread-1 (]: On model.mercurios.int_inventory_with_metrics: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "node_id": "model.mercurios.int_inventory_with_metrics"} */

  
  create view "dbt_mercurios_dev"."main_intermediate"."int_inventory_with_metrics__dbt_tmp" as (
    with inventory as (
    select * from "dbt_mercurios_dev"."main_staging"."stg_prohandel__inventory"
),

articles as (
    select * from "dbt_mercurios_dev"."main_staging"."stg_prohandel__articles"
),

sales_last_30_days as (
    select
        article_id,
        sum(quantity) as quantity_sold_30d,
        count(distinct sale_id) as num_orders_30d
    from "dbt_mercurios_dev"."main_staging"."stg_prohandel__sales"
    where sale_date >= dateadd('day', -30, current_date())
    group by article_id
),

sales_last_90_days as (
    select
        article_id,
        sum(quantity) as quantity_sold_90d,
        count(distinct sale_id) as num_orders_90d
    from "dbt_mercurios_dev"."main_staging"."stg_prohandel__sales"
    where sale_date >= dateadd('day', -90, current_date())
    group by article_id
),

inventory_with_metrics as (
    select
        -- Inventory fields
        i.inventory_id,
        i.article_id,
        i.warehouse_id,
        i.quantity,
        i.stock_level,
        i.needs_reorder,
        i.location,
        i.last_count_date,
        i.is_available,
        i.tenant_id,
        
        -- Article fields
        a.article_number,
        a.description,
        a.category,
        a.subcategory,
        a.brand,
        a.supplier,
        a.purchase_price,
        a.retail_price,
        a.min_stock_level,
        a.max_stock_level,
        a.reorder_point,
        a.lead_time_days,
        a.profit_margin,
        a.profit_margin_percent,
        a.price_tier,
        
        -- Sales metrics
        coalesce(s30.quantity_sold_30d, 0) as quantity_sold_30d,
        coalesce(s30.num_orders_30d, 0) as num_orders_30d,
        coalesce(s90.quantity_sold_90d, 0) as quantity_sold_90d,
        coalesce(s90.num_orders_90d, 0) as num_orders_90d,
        
        -- Calculate days of supply
        case
            when coalesce(s30.quantity_sold_30d, 0) > 0 then 
                (i.quantity / (s30.quantity_sold_30d / 30.0))
            else null
        end as days_of_supply_30d,
        
        case
            when coalesce(s90.quantity_sold_90d, 0) > 0 then 
                (i.quantity / (s90.quantity_sold_90d / 90.0))
            else null
        end as days_of_supply_90d,
        
        -- Calculate stock turnover rate (annualized)
        case
            when i.quantity > 0 and coalesce(s30.quantity_sold_30d, 0) > 0 then 
                (s30.quantity_sold_30d * (365.0 / 30.0)) / i.quantity
            else null
        end as turnover_rate_30d,
        
        case
            when i.quantity > 0 and coalesce(s90.quantity_sold_90d, 0) > 0 then 
                (s90.quantity_sold_90d * (365.0 / 90.0)) / i.quantity
            else null
        end as turnover_rate_90d,
        
        -- Calculate inventory value
        i.quantity * a.purchase_price as inventory_value,
        i.quantity * a.retail_price as potential_revenue,
        
        -- Calculate excess inventory flag
        case
            when coalesce(s90.quantity_sold_90d, 0) = 0 and i.quantity > 10 then true
            when coalesce(s90.quantity_sold_90d, 0) > 0 and 
                 (i.quantity / (s90.quantity_sold_90d / 90.0)) > 180 then true
            else false
        end as is_excess_inventory,
        
        -- Calculate slow-moving inventory flag
        case
            when coalesce(s90.quantity_sold_90d, 0) = 0 and i.quantity > 0 then true
            when coalesce(s90.quantity_sold_90d, 0) > 0 and 
                 (s90.quantity_sold_90d * (365.0 / 90.0)) / i.quantity < 1 then true
            else false
        end as is_slow_moving,
        
        -- Calculate stockout risk flag
        case
            when i.quantity = 0 then 'Stockout'
            when coalesce(s30.quantity_sold_30d, 0) > 0 and 
                 (i.quantity / (s30.quantity_sold_30d / 30.0)) < 7 then 'Critical'
            when coalesce(s30.quantity_sold_30d, 0) > 0 and 
                 (i.quantity / (s30.quantity_sold_30d / 30.0)) < 14 then 'Warning'
            else 'Normal'
        end as stockout_risk,
        
        -- Fivetran metadata
        i._fivetran_synced
    from inventory i
    left join articles a on i.article_id = a.article_id
    left join sales_last_30_days s30 on i.article_id = s30.article_id
    left join sales_last_90_days s90 on i.article_id = s90.article_id
)

select * from inventory_with_metrics
  );

[0m13:04:54.565210 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "node_id": "model.mercurios.int_inventory_with_metrics"} */

  
  create view "dbt_mercurios_dev"."main_intermediate"."int_inventory_with_metrics__dbt_tmp" as (
    with inventory as (
    select * from "dbt_mercurios_dev"."main_staging"."stg_prohandel__inventory"
),

articles as (
    select * from "dbt_mercurios_dev"."main_staging"."stg_prohandel__articles"
),

sales_last_30_days as (
    select
        article_id,
        sum(quantity) as quantity_sold_30d,
        count(distinct sale_id) as num_orders_30d
    from "dbt_mercurios_dev"."main_staging"."stg_prohandel__sales"
    where sale_date >= dateadd('day', -30, current_date())
    group by article_id
),

sales_last_90_days as (
    select
        article_id,
        sum(quantity) as quantity_sold_90d,
        count(distinct sale_id) as num_orders_90d
    from "dbt_mercurios_dev"."main_staging"."stg_prohandel__sales"
    where sale_date >= dateadd('day', -90, current_date())
    group by article_id
),

inventory_with_metrics as (
    select
        -- Inventory fields
        i.inventory_id,
        i.article_id,
        i.warehouse_id,
        i.quantity,
        i.stock_level,
        i.needs_reorder,
        i.location,
        i.last_count_date,
        i.is_available,
        i.tenant_id,
        
        -- Article fields
        a.article_number,
        a.description,
        a.category,
        a.subcategory,
        a.brand,
        a.supplier,
        a.purchase_price,
        a.retail_price,
        a.min_stock_level,
        a.max_stock_level,
        a.reorder_point,
        a.lead_time_days,
        a.profit_margin,
        a.profit_margin_percent,
        a.price_tier,
        
        -- Sales metrics
        coalesce(s30.quantity_sold_30d, 0) as quantity_sold_30d,
        coalesce(s30.num_orders_30d, 0) as num_orders_30d,
        coalesce(s90.quantity_sold_90d, 0) as quantity_sold_90d,
        coalesce(s90.num_orders_90d, 0) as num_orders_90d,
        
        -- Calculate days of supply
        case
            when coalesce(s30.quantity_sold_30d, 0) > 0 then 
                (i.quantity / (s30.quantity_sold_30d / 30.0))
            else null
        end as days_of_supply_30d,
        
        case
            when coalesce(s90.quantity_sold_90d, 0) > 0 then 
                (i.quantity / (s90.quantity_sold_90d / 90.0))
            else null
        end as days_of_supply_90d,
        
        -- Calculate stock turnover rate (annualized)
        case
            when i.quantity > 0 and coalesce(s30.quantity_sold_30d, 0) > 0 then 
                (s30.quantity_sold_30d * (365.0 / 30.0)) / i.quantity
            else null
        end as turnover_rate_30d,
        
        case
            when i.quantity > 0 and coalesce(s90.quantity_sold_90d, 0) > 0 then 
                (s90.quantity_sold_90d * (365.0 / 90.0)) / i.quantity
            else null
        end as turnover_rate_90d,
        
        -- Calculate inventory value
        i.quantity * a.purchase_price as inventory_value,
        i.quantity * a.retail_price as potential_revenue,
        
        -- Calculate excess inventory flag
        case
            when coalesce(s90.quantity_sold_90d, 0) = 0 and i.quantity > 10 then true
            when coalesce(s90.quantity_sold_90d, 0) > 0 and 
                 (i.quantity / (s90.quantity_sold_90d / 90.0)) > 180 then true
            else false
        end as is_excess_inventory,
        
        -- Calculate slow-moving inventory flag
        case
            when coalesce(s90.quantity_sold_90d, 0) = 0 and i.quantity > 0 then true
            when coalesce(s90.quantity_sold_90d, 0) > 0 and 
                 (s90.quantity_sold_90d * (365.0 / 90.0)) / i.quantity < 1 then true
            else false
        end as is_slow_moving,
        
        -- Calculate stockout risk flag
        case
            when i.quantity = 0 then 'Stockout'
            when coalesce(s30.quantity_sold_30d, 0) > 0 and 
                 (i.quantity / (s30.quantity_sold_30d / 30.0)) < 7 then 'Critical'
            when coalesce(s30.quantity_sold_30d, 0) > 0 and 
                 (i.quantity / (s30.quantity_sold_30d / 30.0)) < 14 then 'Warning'
            else 'Normal'
        end as stockout_risk,
        
        -- Fivetran metadata
        i._fivetran_synced
    from inventory i
    left join articles a on i.article_id = a.article_id
    left join sales_last_30_days s30 on i.article_id = s30.article_id
    left join sales_last_90_days s90 on i.article_id = s90.article_id
)

select * from inventory_with_metrics
  );

[0m13:04:54.565579 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m13:04:54.565851 [debug] [Thread-1 (]: On model.mercurios.int_inventory_with_metrics: ROLLBACK
[0m13:04:54.567782 [debug] [Thread-1 (]: Failed to rollback 'model.mercurios.int_inventory_with_metrics'
[0m13:04:54.567972 [debug] [Thread-1 (]: On model.mercurios.int_inventory_with_metrics: Close
[0m13:04:54.569262 [debug] [Thread-1 (]: Runtime Error in model int_inventory_with_metrics (models/intermediate/int_inventory_with_metrics.sql)
  Catalog Error: Table with name stg_prohandel__inventory does not exist!
  Did you mean "pg_catalog.pg_constraint"?
  
  LINE 6:     select * from "dbt_mercurios_dev"."main_staging"."stg_prohandel__inventory...
                            ^
[0m13:04:54.570082 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '931d70a6-9ca7-4502-aece-49a537ae2f4f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112f70610>]}
[0m13:04:54.570426 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model main_intermediate.int_inventory_with_metrics  [[31mERROR[0m in 0.03s]
[0m13:04:54.570711 [debug] [Thread-1 (]: Finished running node model.mercurios.int_inventory_with_metrics
[0m13:04:54.570950 [debug] [Thread-7 (]: Marking all children of 'model.mercurios.int_inventory_with_metrics' to be skipped because of status 'error'.  Reason: Runtime Error in model int_inventory_with_metrics (models/intermediate/int_inventory_with_metrics.sql)
  Catalog Error: Table with name stg_prohandel__inventory does not exist!
  Did you mean "pg_catalog.pg_constraint"?
  
  LINE 6:     select * from "dbt_mercurios_dev"."main_staging"."stg_prohandel__inventory...
                            ^.
[0m13:04:54.571936 [debug] [MainThread]: Using duckdb connection "master"
[0m13:04:54.572206 [debug] [MainThread]: On master: BEGIN
[0m13:04:54.572348 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m13:04:54.572664 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m13:04:54.572831 [debug] [MainThread]: On master: COMMIT
[0m13:04:54.572977 [debug] [MainThread]: Using duckdb connection "master"
[0m13:04:54.573114 [debug] [MainThread]: On master: COMMIT
[0m13:04:54.573308 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m13:04:54.573453 [debug] [MainThread]: On master: Close
[0m13:04:54.573640 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:04:54.573774 [debug] [MainThread]: Connection 'model.mercurios.int_inventory_with_metrics' was properly closed.
[0m13:04:54.573906 [debug] [MainThread]: Connection 'list_dbt_mercurios_dev_main_staging' was properly closed.
[0m13:04:54.574031 [debug] [MainThread]: Connection 'list_dbt_mercurios_dev_main_intermediate' was properly closed.
[0m13:04:54.574192 [info ] [MainThread]: 
[0m13:04:54.574358 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 0.14 seconds (0.14s).
[0m13:04:54.574684 [debug] [MainThread]: Command end result
[0m13:04:54.591343 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/target/manifest.json
[0m13:04:54.592546 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/target/semantic_manifest.json
[0m13:04:54.595322 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/target/run_results.json
[0m13:04:54.595502 [info ] [MainThread]: 
[0m13:04:54.595697 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m13:04:54.595853 [info ] [MainThread]: 
[0m13:04:54.596038 [error] [MainThread]:   Runtime Error in model int_inventory_with_metrics (models/intermediate/int_inventory_with_metrics.sql)
  Catalog Error: Table with name stg_prohandel__inventory does not exist!
  Did you mean "pg_catalog.pg_constraint"?
  
  LINE 6:     select * from "dbt_mercurios_dev"."main_staging"."stg_prohandel__inventory...
                            ^
[0m13:04:54.596190 [info ] [MainThread]: 
[0m13:04:54.596340 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m13:04:54.597114 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 0.5829441, "process_in_blocks": "0", "process_kernel_time": 0.228927, "process_mem_max_rss": "149848064", "process_out_blocks": "0", "process_user_time": 1.127639}
[0m13:04:54.597306 [debug] [MainThread]: Command `dbt run` failed at 13:04:54.597272 after 0.58 seconds
[0m13:04:54.597499 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e861d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114f02fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114f00150>]}
[0m13:04:54.597676 [debug] [MainThread]: Flushing usage events
[0m13:04:55.122799 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:04:56.198458 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1140e4fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11416a990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11416b110>]}


============================== 13:04:56.201040 | ac2fd2ff-d7c5-4156-97c4-1d40d82a69cc ==============================
[0m13:04:56.201040 [info ] [MainThread]: Running with dbt=1.9.2
[0m13:04:56.201405 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/Users/juliusrechenbach/API ProHandelTest/dbt_mercurios', 'log_path': '/Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt run --models marts', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m13:04:56.334130 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ac2fd2ff-d7c5-4156-97c4-1d40d82a69cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1141af3d0>]}
[0m13:04:56.370246 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ac2fd2ff-d7c5-4156-97c4-1d40d82a69cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10487e7d0>]}
[0m13:04:56.372552 [info ] [MainThread]: Registered adapter: duckdb=1.9.2
[0m13:04:56.429730 [debug] [MainThread]: checksum: 12b12750b70de726cfd89136b8e24afc3f3e77597a97bff40ab7e5f9b39d5e18, vars: {}, profile: , target: , version: 1.9.2
[0m13:04:56.498707 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m13:04:56.499002 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m13:04:56.502889 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.mercurios.marts.sales
[0m13:04:56.524845 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ac2fd2ff-d7c5-4156-97c4-1d40d82a69cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1143f2c10>]}
[0m13:04:56.572202 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/target/manifest.json
[0m13:04:56.573671 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/target/semantic_manifest.json
[0m13:04:56.582005 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ac2fd2ff-d7c5-4156-97c4-1d40d82a69cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114148c50>]}
[0m13:04:56.582545 [info ] [MainThread]: Found 9 models, 17 data tests, 3 sources, 540 macros
[0m13:04:56.582785 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ac2fd2ff-d7c5-4156-97c4-1d40d82a69cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114560f90>]}
[0m13:04:56.583890 [info ] [MainThread]: 
[0m13:04:56.584177 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m13:04:56.584338 [info ] [MainThread]: 
[0m13:04:56.584742 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m13:04:56.587400 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_dbt_mercurios_dev'
[0m13:04:56.649741 [debug] [ThreadPool]: Using duckdb connection "list_dbt_mercurios_dev"
[0m13:04:56.650006 [debug] [ThreadPool]: On list_dbt_mercurios_dev: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "list_dbt_mercurios_dev"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"dbt_mercurios_dev"'
    
  
  
[0m13:04:56.650167 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:04:56.657351 [debug] [ThreadPool]: SQL status: OK in 0.007 seconds
[0m13:04:56.658260 [debug] [ThreadPool]: On list_dbt_mercurios_dev: Close
[0m13:04:56.658696 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dbt_mercurios_dev, now create_dbt_mercurios_dev_main_marts_inventory)
[0m13:04:56.658945 [debug] [ThreadPool]: Creating schema "database: "dbt_mercurios_dev"
schema: "main_marts_inventory"
"
[0m13:04:56.662585 [debug] [ThreadPool]: Using duckdb connection "create_dbt_mercurios_dev_main_marts_inventory"
[0m13:04:56.662838 [debug] [ThreadPool]: On create_dbt_mercurios_dev_main_marts_inventory: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "create_dbt_mercurios_dev_main_marts_inventory"} */

    
        select type from duckdb_databases()
        where lower(database_name)='dbt_mercurios_dev'
        and type='sqlite'
    
  
[0m13:04:56.662992 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:04:56.663601 [debug] [ThreadPool]: SQL status: OK in 0.001 seconds
[0m13:04:56.664228 [debug] [ThreadPool]: Using duckdb connection "create_dbt_mercurios_dev_main_marts_inventory"
[0m13:04:56.664382 [debug] [ThreadPool]: On create_dbt_mercurios_dev_main_marts_inventory: BEGIN
[0m13:04:56.664650 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m13:04:56.664784 [debug] [ThreadPool]: Using duckdb connection "create_dbt_mercurios_dev_main_marts_inventory"
[0m13:04:56.664919 [debug] [ThreadPool]: On create_dbt_mercurios_dev_main_marts_inventory: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "create_dbt_mercurios_dev_main_marts_inventory"} */

    
    
        create schema if not exists "dbt_mercurios_dev"."main_marts_inventory"
    
[0m13:04:56.665149 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m13:04:56.665513 [debug] [ThreadPool]: On create_dbt_mercurios_dev_main_marts_inventory: COMMIT
[0m13:04:56.665682 [debug] [ThreadPool]: Using duckdb connection "create_dbt_mercurios_dev_main_marts_inventory"
[0m13:04:56.665824 [debug] [ThreadPool]: On create_dbt_mercurios_dev_main_marts_inventory: COMMIT
[0m13:04:56.666335 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m13:04:56.666564 [debug] [ThreadPool]: On create_dbt_mercurios_dev_main_marts_inventory: Close
[0m13:04:56.667384 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_dbt_mercurios_dev_main_marts_inventory, now list_dbt_mercurios_dev_main_staging)
[0m13:04:56.670343 [debug] [ThreadPool]: Using duckdb connection "list_dbt_mercurios_dev_main_staging"
[0m13:04:56.670687 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_dbt_mercurios_dev_main_intermediate'
[0m13:04:56.671013 [debug] [ThreadPool]: On list_dbt_mercurios_dev_main_staging: BEGIN
[0m13:04:56.671274 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_dbt_mercurios_dev_main_marts_inventory'
[0m13:04:56.672439 [debug] [ThreadPool]: Using duckdb connection "list_dbt_mercurios_dev_main_intermediate"
[0m13:04:56.672626 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:04:56.673704 [debug] [ThreadPool]: Using duckdb connection "list_dbt_mercurios_dev_main_marts_inventory"
[0m13:04:56.673867 [debug] [ThreadPool]: On list_dbt_mercurios_dev_main_intermediate: BEGIN
[0m13:04:56.674130 [debug] [ThreadPool]: On list_dbt_mercurios_dev_main_marts_inventory: BEGIN
[0m13:04:56.674324 [debug] [ThreadPool]: SQL status: OK in 0.002 seconds
[0m13:04:56.674547 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:04:56.674684 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:04:56.674819 [debug] [ThreadPool]: Using duckdb connection "list_dbt_mercurios_dev_main_staging"
[0m13:04:56.675132 [debug] [ThreadPool]: SQL status: OK in 0.001 seconds
[0m13:04:56.675328 [debug] [ThreadPool]: SQL status: OK in 0.001 seconds
[0m13:04:56.675546 [debug] [ThreadPool]: On list_dbt_mercurios_dev_main_staging: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "list_dbt_mercurios_dev_main_staging"} */
select
      'dbt_mercurios_dev' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_staging'
    and lower(table_catalog) = 'dbt_mercurios_dev'
  
[0m13:04:56.675700 [debug] [ThreadPool]: Using duckdb connection "list_dbt_mercurios_dev_main_intermediate"
[0m13:04:56.675838 [debug] [ThreadPool]: Using duckdb connection "list_dbt_mercurios_dev_main_marts_inventory"
[0m13:04:56.676097 [debug] [ThreadPool]: On list_dbt_mercurios_dev_main_intermediate: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "list_dbt_mercurios_dev_main_intermediate"} */
select
      'dbt_mercurios_dev' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_intermediate'
    and lower(table_catalog) = 'dbt_mercurios_dev'
  
[0m13:04:56.676290 [debug] [ThreadPool]: On list_dbt_mercurios_dev_main_marts_inventory: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "list_dbt_mercurios_dev_main_marts_inventory"} */
select
      'dbt_mercurios_dev' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_marts_inventory'
    and lower(table_catalog) = 'dbt_mercurios_dev'
  
[0m13:04:56.686129 [debug] [ThreadPool]: SQL status: OK in 0.010 seconds
[0m13:04:56.686923 [debug] [ThreadPool]: On list_dbt_mercurios_dev_main_intermediate: ROLLBACK
[0m13:04:56.687124 [debug] [ThreadPool]: SQL status: OK in 0.011 seconds
[0m13:04:56.687332 [debug] [ThreadPool]: SQL status: OK in 0.011 seconds
[0m13:04:56.688037 [debug] [ThreadPool]: On list_dbt_mercurios_dev_main_marts_inventory: ROLLBACK
[0m13:04:56.688701 [debug] [ThreadPool]: On list_dbt_mercurios_dev_main_staging: ROLLBACK
[0m13:04:56.689029 [debug] [ThreadPool]: Failed to rollback 'list_dbt_mercurios_dev_main_intermediate'
[0m13:04:56.689294 [debug] [ThreadPool]: Failed to rollback 'list_dbt_mercurios_dev_main_marts_inventory'
[0m13:04:56.689522 [debug] [ThreadPool]: Failed to rollback 'list_dbt_mercurios_dev_main_staging'
[0m13:04:56.689683 [debug] [ThreadPool]: On list_dbt_mercurios_dev_main_intermediate: Close
[0m13:04:56.689831 [debug] [ThreadPool]: On list_dbt_mercurios_dev_main_marts_inventory: Close
[0m13:04:56.689974 [debug] [ThreadPool]: On list_dbt_mercurios_dev_main_staging: Close
[0m13:04:56.690657 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ac2fd2ff-d7c5-4156-97c4-1d40d82a69cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114831710>]}
[0m13:04:56.690917 [debug] [MainThread]: Using duckdb connection "master"
[0m13:04:56.691059 [debug] [MainThread]: On master: BEGIN
[0m13:04:56.691193 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:04:56.691491 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m13:04:56.691632 [debug] [MainThread]: On master: COMMIT
[0m13:04:56.691766 [debug] [MainThread]: Using duckdb connection "master"
[0m13:04:56.691895 [debug] [MainThread]: On master: COMMIT
[0m13:04:56.692111 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m13:04:56.692298 [debug] [MainThread]: On master: Close
[0m13:04:56.693583 [debug] [Thread-1 (]: Began running node model.mercurios.demand_forecast
[0m13:04:56.693927 [debug] [Thread-2 (]: Began running node model.mercurios.inventory_status
[0m13:04:56.694190 [info ] [Thread-1 (]: 1 of 5 START sql table model main_marts_inventory.demand_forecast .............. [RUN]
[0m13:04:56.694584 [info ] [Thread-2 (]: 2 of 5 START sql table model main_marts_inventory.inventory_status ............. [RUN]
[0m13:04:56.694909 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_dbt_mercurios_dev_main_staging, now model.mercurios.demand_forecast)
[0m13:04:56.695176 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_dbt_mercurios_dev_main_intermediate, now model.mercurios.inventory_status)
[0m13:04:56.695431 [debug] [Thread-1 (]: Began compiling node model.mercurios.demand_forecast
[0m13:04:56.695609 [debug] [Thread-2 (]: Began compiling node model.mercurios.inventory_status
[0m13:04:56.700804 [debug] [Thread-1 (]: Writing injected SQL for node "model.mercurios.demand_forecast"
[0m13:04:56.702691 [debug] [Thread-2 (]: Writing injected SQL for node "model.mercurios.inventory_status"
[0m13:04:56.703335 [debug] [Thread-1 (]: Began executing node model.mercurios.demand_forecast
[0m13:04:56.703585 [debug] [Thread-2 (]: Began executing node model.mercurios.inventory_status
[0m13:04:56.720140 [debug] [Thread-1 (]: Writing runtime sql for node "model.mercurios.demand_forecast"
[0m13:04:56.723099 [debug] [Thread-2 (]: Writing runtime sql for node "model.mercurios.inventory_status"
[0m13:04:56.723789 [debug] [Thread-2 (]: Using duckdb connection "model.mercurios.inventory_status"
[0m13:04:56.724036 [debug] [Thread-2 (]: On model.mercurios.inventory_status: BEGIN
[0m13:04:56.724286 [debug] [Thread-1 (]: Using duckdb connection "model.mercurios.demand_forecast"
[0m13:04:56.724518 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m13:04:56.724759 [debug] [Thread-1 (]: On model.mercurios.demand_forecast: BEGIN
[0m13:04:56.725078 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:04:56.725327 [debug] [Thread-2 (]: SQL status: OK in 0.001 seconds
[0m13:04:56.725562 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m13:04:56.725735 [debug] [Thread-2 (]: Using duckdb connection "model.mercurios.inventory_status"
[0m13:04:56.725914 [debug] [Thread-1 (]: Using duckdb connection "model.mercurios.demand_forecast"
[0m13:04:56.726239 [debug] [Thread-2 (]: On model.mercurios.inventory_status: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "node_id": "model.mercurios.inventory_status"} */

  
    
    

    create  table
      "dbt_mercurios_dev"."main_marts_inventory"."inventory_status__dbt_tmp"
  
    as (
      

with inventory_metrics as (
    select * from "dbt_mercurios_dev"."main_intermediate"."int_inventory_with_metrics"
),

inventory_status as (
    select
        -- Primary keys and identifiers
        inventory_id,
        article_id,
        warehouse_id,
        article_number,
        
        -- Article details
        description,
        category,
        subcategory,
        brand,
        supplier,
        price_tier,
        
        -- Inventory metrics
        quantity,
        stock_level,
        needs_reorder,
        days_of_supply_30d,
        days_of_supply_90d,
        turnover_rate_30d,
        turnover_rate_90d,
        stockout_risk,
        
        -- Sales metrics
        quantity_sold_30d,
        quantity_sold_90d,
        num_orders_30d,
        num_orders_90d,
        
        -- Financial metrics
        purchase_price,
        retail_price,
        profit_margin,
        profit_margin_percent,
        inventory_value,
        potential_revenue,
        
        -- Flags
        is_excess_inventory,
        is_slow_moving,
        
        -- Calculated fields
        case
            when stockout_risk = 'Stockout' then 1
            when stockout_risk = 'Critical' then 2
            when stockout_risk = 'Warning' then 3
            else 4
        end as stockout_risk_priority,
        
        case
            when is_excess_inventory then inventory_value else 0
        end as excess_inventory_value,
        
        case
            when is_slow_moving then inventory_value else 0
        end as slow_moving_value,
        
        -- Reorder quantity recommendation
        case
            -- If no sales, recommend minimum stock
            when quantity_sold_90d = 0 then 
                greatest(5 - quantity, 0)
            -- If sales exist, calculate based on days of supply target
            when days_of_supply_90d is not null then
                greatest(
                    ceil((quantity_sold_90d / 90.0) * 30) - quantity, -- 30 days supply
                    0
                )
            else 0
        end as recommended_reorder_quantity,
        
        -- ABC Analysis (based on sales volume and value)
        case
            when quantity_sold_90d > 0 and 
                 quantity_sold_90d * retail_price >= 
                 percentile_cont(0.8) within group (order by nullif(quantity_sold_90d * retail_price, 0)) 
                 over (partition by warehouse_id) then 'A'
            when quantity_sold_90d > 0 and 
                 quantity_sold_90d * retail_price >= 
                 percentile_cont(0.5) within group (order by nullif(quantity_sold_90d * retail_price, 0)) 
                 over (partition by warehouse_id) then 'B'
            when quantity_sold_90d > 0 then 'C'
            else 'D' -- No sales
        end as abc_class,
        
        -- Last update timestamp
        _fivetran_synced as last_updated,
        
        -- Add tenant_id
        tenant_id
    from inventory_metrics
)

select * from inventory_status
    );
  
  
[0m13:04:56.726881 [debug] [Thread-1 (]: On model.mercurios.demand_forecast: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "node_id": "model.mercurios.demand_forecast"} */

  
    
    

    create  table
      "dbt_mercurios_dev"."main_marts_inventory"."demand_forecast__dbt_tmp"
  
    as (
      

with sales_history as (
    select
        s.article_id,
        a.article_number,
        a.description,
        a.category,
        a.subcategory,
        a.brand,
        a.supplier,
        a.price_tier,
        s.sale_date,
        sum(s.quantity) as quantity_sold,
        count(distinct s.sale_id) as number_of_sales,
        sum(s.revenue) as revenue
    from "dbt_mercurios_dev"."main_staging"."stg_prohandel__sales" s
    join "dbt_mercurios_dev"."main_staging"."stg_prohandel__articles" a on s.article_id = a.article_id
    where s.sale_date >= dateadd('day', -365, current_date())
    group by 
        s.article_id,
        a.article_number,
        a.description,
        a.category,
        a.subcategory,
        a.brand,
        a.supplier,
        a.price_tier,
        s.sale_date
),

-- Calculate daily, weekly, and monthly aggregates
daily_sales as (
    select
        article_id,
        article_number,
        description,
        category,
        subcategory,
        brand,
        supplier,
        price_tier,
        sale_date,
        quantity_sold,
        number_of_sales,
        revenue,
        -- Extract date parts for seasonality analysis
        dayofweek(sale_date) as day_of_week,
        dayofmonth(sale_date) as day_of_month,
        month(sale_date) as month,
        quarter(sale_date) as quarter
    from sales_history
),

weekly_sales as (
    select
        article_id,
        article_number,
        description,
        category,
        subcategory,
        brand,
        supplier,
        price_tier,
        date_trunc('week', sale_date) as week_start_date,
        sum(quantity_sold) as weekly_quantity_sold,
        sum(number_of_sales) as weekly_number_of_sales,
        sum(revenue) as weekly_revenue,
        avg(quantity_sold) as avg_daily_quantity_sold,
        week(sale_date) as week_of_year
    from daily_sales
    group by 
        article_id,
        article_number,
        description,
        category,
        subcategory,
        brand,
        supplier,
        price_tier,
        week_start_date,
        week_of_year
),

monthly_sales as (
    select
        article_id,
        article_number,
        description,
        category,
        subcategory,
        brand,
        supplier,
        price_tier,
        date_trunc('month', sale_date) as month_start_date,
        sum(quantity_sold) as monthly_quantity_sold,
        sum(number_of_sales) as monthly_number_of_sales,
        sum(revenue) as monthly_revenue,
        avg(quantity_sold) as avg_daily_quantity_sold,
        month(sale_date) as month_of_year
    from daily_sales
    group by 
        article_id,
        article_number,
        description,
        category,
        subcategory,
        brand,
        supplier,
        price_tier,
        month_start_date,
        month_of_year
),

-- Calculate moving averages and trends
moving_averages as (
    select
        article_id,
        sale_date,
        quantity_sold,
        
        -- Calculate 7-day moving average
        avg(quantity_sold) over (
            partition by article_id 
            order by sale_date 
            rows between 6 preceding and current row
        ) as ma_7_day,
        
        -- Calculate 30-day moving average
        avg(quantity_sold) over (
            partition by article_id 
            order by sale_date 
            rows between 29 preceding and current row
        ) as ma_30_day,
        
        -- Calculate 90-day moving average
        avg(quantity_sold) over (
            partition by article_id 
            order by sale_date 
            rows between 89 preceding and current row
        ) as ma_90_day
    from daily_sales
),

-- Calculate seasonality factors
seasonality as (
    select
        article_id,
        day_of_week,
        avg(quantity_sold) as avg_qty_by_day_of_week,
        
        -- Calculate day of week seasonality factor
        avg(quantity_sold) / nullif(
            avg(avg(quantity_sold)) over (partition by article_id),
            0
        ) as day_of_week_factor
    from daily_sales
    group by article_id, day_of_week
),

monthly_seasonality as (
    select
        article_id,
        month_of_year,
        avg(monthly_quantity_sold) as avg_qty_by_month,
        
        -- Calculate month seasonality factor
        avg(monthly_quantity_sold) / nullif(
            avg(avg(monthly_quantity_sold)) over (partition by article_id),
            0
        ) as month_factor
    from monthly_sales
    group by article_id, month_of_year
),

-- Calculate recent sales statistics for forecasting
recent_stats as (
    select
        article_id,
        
        -- Last 30 days
        sum(case when sale_date >= dateadd('day', -30, current_date()) then quantity_sold else 0 end) as qty_last_30d,
        avg(case when sale_date >= dateadd('day', -30, current_date()) then quantity_sold else null end) as avg_daily_qty_last_30d,
        
        -- Last 90 days
        sum(case when sale_date >= dateadd('day', -90, current_date()) then quantity_sold else 0 end) as qty_last_90d,
        avg(case when sale_date >= dateadd('day', -90, current_date()) then quantity_sold else null end) as avg_daily_qty_last_90d,
        
        -- Last 365 days
        sum(quantity_sold) as qty_last_365d,
        avg(quantity_sold) as avg_daily_qty_last_365d,
        
        -- Calculate trend (comparing last 30 days to previous 30 days)
        sum(case when sale_date >= dateadd('day', -30, current_date()) then quantity_sold else 0 end) /
        nullif(sum(case when sale_date >= dateadd('day', -60, current_date()) and 
                        sale_date < dateadd('day', -30, current_date()) then quantity_sold else 0 end), 0) - 1 as trend_factor
    from daily_sales
    group by article_id
),

-- Generate forecast dates (simplified without dbt_utils for now)
forecast_dates as (
    select dateadd('day', seq4(), current_date()) as date_day
    from table(generator(rowcount => 90))
),

-- Create the final forecast
demand_forecast as (
    select
        a.article_id,
        a.article_number,
        a.description,
        a.category,
        a.subcategory,
        a.brand,
        a.supplier,
        a.price_tier,
        d.date_day as forecast_date,
        
        -- Extract date parts for applying seasonality
        dayofweek(d.date_day) as day_of_week,
        month(d.date_day) as month_of_year,
        
        -- Base forecast using recent average
        rs.avg_daily_qty_last_90d as base_forecast,
        
        -- Apply trend factor (capped to prevent extreme values)
        case
            when rs.trend_factor > 0.5 then 1.5
            when rs.trend_factor < -0.5 then 0.5
            else 1 + coalesce(rs.trend_factor, 0)
        end as applied_trend_factor,
        
        -- Apply day of week seasonality
        coalesce(s.day_of_week_factor, 1) as day_of_week_factor,
        
        -- Apply monthly seasonality
        coalesce(ms.month_factor, 1) as month_factor,
        
        -- Calculate final forecast
        round(
            rs.avg_daily_qty_last_90d * 
            case
                when rs.trend_factor > 0.5 then 1.5
                when rs.trend_factor < -0.5 then 0.5
                else 1 + coalesce(rs.trend_factor, 0)
            end *
            coalesce(s.day_of_week_factor, 1) *
            coalesce(ms.month_factor, 1),
            2
        ) as forecasted_daily_demand,
        
        -- Add cumulative forecast
        sum(
            round(
                rs.avg_daily_qty_last_90d * 
                case
                    when rs.trend_factor > 0.5 then 1.5
                    when rs.trend_factor < -0.5 then 0.5
                    else 1 + coalesce(rs.trend_factor, 0)
                end *
                coalesce(s.day_of_week_factor, 1) *
                coalesce(ms.month_factor, 1),
                2
            )
        ) over (
            partition by a.article_id 
            order by d.date_day 
            rows between unbounded preceding and current row
        ) as cumulative_forecasted_demand,
        
        -- Historical sales statistics
        rs.avg_daily_qty_last_30d,
        rs.avg_daily_qty_last_90d,
        rs.avg_daily_qty_last_365d,
        rs.qty_last_30d,
        rs.qty_last_90d,
        rs.qty_last_365d,
        
        -- Add confidence level based on data quality
        case
            when rs.qty_last_365d > 100 and rs.avg_daily_qty_last_30d > 0 then 'High'
            when rs.qty_last_90d > 30 and rs.avg_daily_qty_last_30d > 0 then 'Medium'
            when rs.qty_last_30d > 0 then 'Low'
            else 'Very Low'
        end as forecast_confidence,
        
        -- Generate forecast timestamp
        current_timestamp() as generated_at,
        
        -- Add tenant_id
        a.tenant_id
        
    from "dbt_mercurios_dev"."main_staging"."stg_prohandel__articles" a
    cross join forecast_dates d
    left join recent_stats rs on a.article_id = rs.article_id
    left join seasonality s on a.article_id = s.article_id and dayofweek(d.date_day) = s.day_of_week
    left join monthly_seasonality ms on a.article_id = ms.article_id and month(d.date_day) = ms.month_of_year
    where rs.avg_daily_qty_last_90d > 0  -- Only forecast for items with recent sales
)

select * from demand_forecast
    );
  
  
[0m13:04:56.728318 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "node_id": "model.mercurios.demand_forecast"} */

  
    
    

    create  table
      "dbt_mercurios_dev"."main_marts_inventory"."demand_forecast__dbt_tmp"
  
    as (
      

with sales_history as (
    select
        s.article_id,
        a.article_number,
        a.description,
        a.category,
        a.subcategory,
        a.brand,
        a.supplier,
        a.price_tier,
        s.sale_date,
        sum(s.quantity) as quantity_sold,
        count(distinct s.sale_id) as number_of_sales,
        sum(s.revenue) as revenue
    from "dbt_mercurios_dev"."main_staging"."stg_prohandel__sales" s
    join "dbt_mercurios_dev"."main_staging"."stg_prohandel__articles" a on s.article_id = a.article_id
    where s.sale_date >= dateadd('day', -365, current_date())
    group by 
        s.article_id,
        a.article_number,
        a.description,
        a.category,
        a.subcategory,
        a.brand,
        a.supplier,
        a.price_tier,
        s.sale_date
),

-- Calculate daily, weekly, and monthly aggregates
daily_sales as (
    select
        article_id,
        article_number,
        description,
        category,
        subcategory,
        brand,
        supplier,
        price_tier,
        sale_date,
        quantity_sold,
        number_of_sales,
        revenue,
        -- Extract date parts for seasonality analysis
        dayofweek(sale_date) as day_of_week,
        dayofmonth(sale_date) as day_of_month,
        month(sale_date) as month,
        quarter(sale_date) as quarter
    from sales_history
),

weekly_sales as (
    select
        article_id,
        article_number,
        description,
        category,
        subcategory,
        brand,
        supplier,
        price_tier,
        date_trunc('week', sale_date) as week_start_date,
        sum(quantity_sold) as weekly_quantity_sold,
        sum(number_of_sales) as weekly_number_of_sales,
        sum(revenue) as weekly_revenue,
        avg(quantity_sold) as avg_daily_quantity_sold,
        week(sale_date) as week_of_year
    from daily_sales
    group by 
        article_id,
        article_number,
        description,
        category,
        subcategory,
        brand,
        supplier,
        price_tier,
        week_start_date,
        week_of_year
),

monthly_sales as (
    select
        article_id,
        article_number,
        description,
        category,
        subcategory,
        brand,
        supplier,
        price_tier,
        date_trunc('month', sale_date) as month_start_date,
        sum(quantity_sold) as monthly_quantity_sold,
        sum(number_of_sales) as monthly_number_of_sales,
        sum(revenue) as monthly_revenue,
        avg(quantity_sold) as avg_daily_quantity_sold,
        month(sale_date) as month_of_year
    from daily_sales
    group by 
        article_id,
        article_number,
        description,
        category,
        subcategory,
        brand,
        supplier,
        price_tier,
        month_start_date,
        month_of_year
),

-- Calculate moving averages and trends
moving_averages as (
    select
        article_id,
        sale_date,
        quantity_sold,
        
        -- Calculate 7-day moving average
        avg(quantity_sold) over (
            partition by article_id 
            order by sale_date 
            rows between 6 preceding and current row
        ) as ma_7_day,
        
        -- Calculate 30-day moving average
        avg(quantity_sold) over (
            partition by article_id 
            order by sale_date 
            rows between 29 preceding and current row
        ) as ma_30_day,
        
        -- Calculate 90-day moving average
        avg(quantity_sold) over (
            partition by article_id 
            order by sale_date 
            rows between 89 preceding and current row
        ) as ma_90_day
    from daily_sales
),

-- Calculate seasonality factors
seasonality as (
    select
        article_id,
        day_of_week,
        avg(quantity_sold) as avg_qty_by_day_of_week,
        
        -- Calculate day of week seasonality factor
        avg(quantity_sold) / nullif(
            avg(avg(quantity_sold)) over (partition by article_id),
            0
        ) as day_of_week_factor
    from daily_sales
    group by article_id, day_of_week
),

monthly_seasonality as (
    select
        article_id,
        month_of_year,
        avg(monthly_quantity_sold) as avg_qty_by_month,
        
        -- Calculate month seasonality factor
        avg(monthly_quantity_sold) / nullif(
            avg(avg(monthly_quantity_sold)) over (partition by article_id),
            0
        ) as month_factor
    from monthly_sales
    group by article_id, month_of_year
),

-- Calculate recent sales statistics for forecasting
recent_stats as (
    select
        article_id,
        
        -- Last 30 days
        sum(case when sale_date >= dateadd('day', -30, current_date()) then quantity_sold else 0 end) as qty_last_30d,
        avg(case when sale_date >= dateadd('day', -30, current_date()) then quantity_sold else null end) as avg_daily_qty_last_30d,
        
        -- Last 90 days
        sum(case when sale_date >= dateadd('day', -90, current_date()) then quantity_sold else 0 end) as qty_last_90d,
        avg(case when sale_date >= dateadd('day', -90, current_date()) then quantity_sold else null end) as avg_daily_qty_last_90d,
        
        -- Last 365 days
        sum(quantity_sold) as qty_last_365d,
        avg(quantity_sold) as avg_daily_qty_last_365d,
        
        -- Calculate trend (comparing last 30 days to previous 30 days)
        sum(case when sale_date >= dateadd('day', -30, current_date()) then quantity_sold else 0 end) /
        nullif(sum(case when sale_date >= dateadd('day', -60, current_date()) and 
                        sale_date < dateadd('day', -30, current_date()) then quantity_sold else 0 end), 0) - 1 as trend_factor
    from daily_sales
    group by article_id
),

-- Generate forecast dates (simplified without dbt_utils for now)
forecast_dates as (
    select dateadd('day', seq4(), current_date()) as date_day
    from table(generator(rowcount => 90))
),

-- Create the final forecast
demand_forecast as (
    select
        a.article_id,
        a.article_number,
        a.description,
        a.category,
        a.subcategory,
        a.brand,
        a.supplier,
        a.price_tier,
        d.date_day as forecast_date,
        
        -- Extract date parts for applying seasonality
        dayofweek(d.date_day) as day_of_week,
        month(d.date_day) as month_of_year,
        
        -- Base forecast using recent average
        rs.avg_daily_qty_last_90d as base_forecast,
        
        -- Apply trend factor (capped to prevent extreme values)
        case
            when rs.trend_factor > 0.5 then 1.5
            when rs.trend_factor < -0.5 then 0.5
            else 1 + coalesce(rs.trend_factor, 0)
        end as applied_trend_factor,
        
        -- Apply day of week seasonality
        coalesce(s.day_of_week_factor, 1) as day_of_week_factor,
        
        -- Apply monthly seasonality
        coalesce(ms.month_factor, 1) as month_factor,
        
        -- Calculate final forecast
        round(
            rs.avg_daily_qty_last_90d * 
            case
                when rs.trend_factor > 0.5 then 1.5
                when rs.trend_factor < -0.5 then 0.5
                else 1 + coalesce(rs.trend_factor, 0)
            end *
            coalesce(s.day_of_week_factor, 1) *
            coalesce(ms.month_factor, 1),
            2
        ) as forecasted_daily_demand,
        
        -- Add cumulative forecast
        sum(
            round(
                rs.avg_daily_qty_last_90d * 
                case
                    when rs.trend_factor > 0.5 then 1.5
                    when rs.trend_factor < -0.5 then 0.5
                    else 1 + coalesce(rs.trend_factor, 0)
                end *
                coalesce(s.day_of_week_factor, 1) *
                coalesce(ms.month_factor, 1),
                2
            )
        ) over (
            partition by a.article_id 
            order by d.date_day 
            rows between unbounded preceding and current row
        ) as cumulative_forecasted_demand,
        
        -- Historical sales statistics
        rs.avg_daily_qty_last_30d,
        rs.avg_daily_qty_last_90d,
        rs.avg_daily_qty_last_365d,
        rs.qty_last_30d,
        rs.qty_last_90d,
        rs.qty_last_365d,
        
        -- Add confidence level based on data quality
        case
            when rs.qty_last_365d > 100 and rs.avg_daily_qty_last_30d > 0 then 'High'
            when rs.qty_last_90d > 30 and rs.avg_daily_qty_last_30d > 0 then 'Medium'
            when rs.qty_last_30d > 0 then 'Low'
            else 'Very Low'
        end as forecast_confidence,
        
        -- Generate forecast timestamp
        current_timestamp() as generated_at,
        
        -- Add tenant_id
        a.tenant_id
        
    from "dbt_mercurios_dev"."main_staging"."stg_prohandel__articles" a
    cross join forecast_dates d
    left join recent_stats rs on a.article_id = rs.article_id
    left join seasonality s on a.article_id = s.article_id and dayofweek(d.date_day) = s.day_of_week
    left join monthly_seasonality ms on a.article_id = ms.article_id and month(d.date_day) = ms.month_of_year
    where rs.avg_daily_qty_last_90d > 0  -- Only forecast for items with recent sales
)

select * from demand_forecast
    );
  
  
[0m13:04:56.728885 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m13:04:56.729141 [debug] [Thread-1 (]: On model.mercurios.demand_forecast: ROLLBACK
[0m13:04:56.731529 [debug] [Thread-1 (]: Failed to rollback 'model.mercurios.demand_forecast'
[0m13:04:56.731878 [debug] [Thread-2 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "node_id": "model.mercurios.inventory_status"} */

  
    
    

    create  table
      "dbt_mercurios_dev"."main_marts_inventory"."inventory_status__dbt_tmp"
  
    as (
      

with inventory_metrics as (
    select * from "dbt_mercurios_dev"."main_intermediate"."int_inventory_with_metrics"
),

inventory_status as (
    select
        -- Primary keys and identifiers
        inventory_id,
        article_id,
        warehouse_id,
        article_number,
        
        -- Article details
        description,
        category,
        subcategory,
        brand,
        supplier,
        price_tier,
        
        -- Inventory metrics
        quantity,
        stock_level,
        needs_reorder,
        days_of_supply_30d,
        days_of_supply_90d,
        turnover_rate_30d,
        turnover_rate_90d,
        stockout_risk,
        
        -- Sales metrics
        quantity_sold_30d,
        quantity_sold_90d,
        num_orders_30d,
        num_orders_90d,
        
        -- Financial metrics
        purchase_price,
        retail_price,
        profit_margin,
        profit_margin_percent,
        inventory_value,
        potential_revenue,
        
        -- Flags
        is_excess_inventory,
        is_slow_moving,
        
        -- Calculated fields
        case
            when stockout_risk = 'Stockout' then 1
            when stockout_risk = 'Critical' then 2
            when stockout_risk = 'Warning' then 3
            else 4
        end as stockout_risk_priority,
        
        case
            when is_excess_inventory then inventory_value else 0
        end as excess_inventory_value,
        
        case
            when is_slow_moving then inventory_value else 0
        end as slow_moving_value,
        
        -- Reorder quantity recommendation
        case
            -- If no sales, recommend minimum stock
            when quantity_sold_90d = 0 then 
                greatest(5 - quantity, 0)
            -- If sales exist, calculate based on days of supply target
            when days_of_supply_90d is not null then
                greatest(
                    ceil((quantity_sold_90d / 90.0) * 30) - quantity, -- 30 days supply
                    0
                )
            else 0
        end as recommended_reorder_quantity,
        
        -- ABC Analysis (based on sales volume and value)
        case
            when quantity_sold_90d > 0 and 
                 quantity_sold_90d * retail_price >= 
                 percentile_cont(0.8) within group (order by nullif(quantity_sold_90d * retail_price, 0)) 
                 over (partition by warehouse_id) then 'A'
            when quantity_sold_90d > 0 and 
                 quantity_sold_90d * retail_price >= 
                 percentile_cont(0.5) within group (order by nullif(quantity_sold_90d * retail_price, 0)) 
                 over (partition by warehouse_id) then 'B'
            when quantity_sold_90d > 0 then 'C'
            else 'D' -- No sales
        end as abc_class,
        
        -- Last update timestamp
        _fivetran_synced as last_updated,
        
        -- Add tenant_id
        tenant_id
    from inventory_metrics
)

select * from inventory_status
    );
  
  
[0m13:04:56.732186 [debug] [Thread-1 (]: On model.mercurios.demand_forecast: Close
[0m13:04:56.732426 [debug] [Thread-2 (]: DuckDB adapter: Rolling back transaction.
[0m13:04:56.733338 [debug] [Thread-2 (]: On model.mercurios.inventory_status: ROLLBACK
[0m13:04:56.734180 [debug] [Thread-1 (]: Runtime Error in model demand_forecast (models/marts/inventory/demand_forecast.sql)
  Parser Error: syntax error at or near "table"
[0m13:04:56.735442 [debug] [Thread-2 (]: Failed to rollback 'model.mercurios.inventory_status'
[0m13:04:56.736370 [debug] [Thread-2 (]: On model.mercurios.inventory_status: Close
[0m13:04:56.736635 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ac2fd2ff-d7c5-4156-97c4-1d40d82a69cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11399c810>]}
[0m13:04:56.736977 [error] [Thread-1 (]: 1 of 5 ERROR creating sql table model main_marts_inventory.demand_forecast ..... [[31mERROR[0m in 0.04s]
[0m13:04:56.738375 [debug] [Thread-2 (]: Runtime Error in model inventory_status (models/marts/inventory/inventory_status.sql)
  Catalog Error: Table with name int_inventory_with_metrics does not exist!
  Did you mean "information_schema.table_constraints"?
  
  LINE 14:     select * from "dbt_mercurios_dev"."main_intermediate"."int_inventory_with...
                             ^
[0m13:04:56.738670 [debug] [Thread-1 (]: Finished running node model.mercurios.demand_forecast
[0m13:04:56.738928 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ac2fd2ff-d7c5-4156-97c4-1d40d82a69cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11412c250>]}
[0m13:04:56.739203 [debug] [Thread-7 (]: Marking all children of 'model.mercurios.demand_forecast' to be skipped because of status 'error'.  Reason: Runtime Error in model demand_forecast (models/marts/inventory/demand_forecast.sql)
  Parser Error: syntax error at or near "table".
[0m13:04:56.739639 [error] [Thread-2 (]: 2 of 5 ERROR creating sql table model main_marts_inventory.inventory_status .... [[31mERROR[0m in 0.04s]
[0m13:04:56.740293 [debug] [Thread-2 (]: Finished running node model.mercurios.inventory_status
[0m13:04:56.740539 [debug] [Thread-7 (]: Marking all children of 'model.mercurios.inventory_status' to be skipped because of status 'error'.  Reason: Runtime Error in model inventory_status (models/marts/inventory/inventory_status.sql)
  Catalog Error: Table with name int_inventory_with_metrics does not exist!
  Did you mean "information_schema.table_constraints"?
  
  LINE 14:     select * from "dbt_mercurios_dev"."main_intermediate"."int_inventory_with...
                             ^.
[0m13:04:56.740948 [debug] [Thread-4 (]: Began running node model.mercurios.reorder_recommendations
[0m13:04:56.741210 [info ] [Thread-4 (]: 3 of 5 SKIP relation main_marts_inventory.reorder_recommendations .............. [[33mSKIP[0m]
[0m13:04:56.741481 [debug] [Thread-4 (]: Finished running node model.mercurios.reorder_recommendations
[0m13:04:56.741676 [debug] [Thread-4 (]: Began running node model.mercurios.stock_levels
[0m13:04:56.741851 [info ] [Thread-4 (]: 4 of 5 SKIP relation main_marts_inventory.stock_levels ......................... [[33mSKIP[0m]
[0m13:04:56.742209 [debug] [Thread-4 (]: Finished running node model.mercurios.stock_levels
[0m13:04:56.742719 [debug] [Thread-1 (]: Began running node model.mercurios.tenant_inventory_dashboard
[0m13:04:56.742993 [info ] [Thread-1 (]: 5 of 5 SKIP relation main_marts_inventory.tenant_inventory_dashboard ........... [[33mSKIP[0m]
[0m13:04:56.743205 [debug] [Thread-1 (]: Finished running node model.mercurios.tenant_inventory_dashboard
[0m13:04:56.743891 [debug] [MainThread]: Using duckdb connection "master"
[0m13:04:56.744089 [debug] [MainThread]: On master: BEGIN
[0m13:04:56.744227 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m13:04:56.744557 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m13:04:56.744712 [debug] [MainThread]: On master: COMMIT
[0m13:04:56.744853 [debug] [MainThread]: Using duckdb connection "master"
[0m13:04:56.744986 [debug] [MainThread]: On master: COMMIT
[0m13:04:56.745226 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m13:04:56.745365 [debug] [MainThread]: On master: Close
[0m13:04:56.745565 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:04:56.745697 [debug] [MainThread]: Connection 'model.mercurios.demand_forecast' was properly closed.
[0m13:04:56.745821 [debug] [MainThread]: Connection 'model.mercurios.inventory_status' was properly closed.
[0m13:04:56.745943 [debug] [MainThread]: Connection 'list_dbt_mercurios_dev_main_marts_inventory' was properly closed.
[0m13:04:56.746239 [info ] [MainThread]: 
[0m13:04:56.746408 [info ] [MainThread]: Finished running 5 table models in 0 hours 0 minutes and 0.16 seconds (0.16s).
[0m13:04:56.746787 [debug] [MainThread]: Command end result
[0m13:04:56.762024 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/target/manifest.json
[0m13:04:56.763069 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/target/semantic_manifest.json
[0m13:04:56.766131 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/target/run_results.json
[0m13:04:56.766343 [info ] [MainThread]: 
[0m13:04:56.766530 [info ] [MainThread]: [31mCompleted with 2 errors, 0 partial successes, and 0 warnings:[0m
[0m13:04:56.766681 [info ] [MainThread]: 
[0m13:04:56.766854 [error] [MainThread]:   Runtime Error in model demand_forecast (models/marts/inventory/demand_forecast.sql)
  Parser Error: syntax error at or near "table"
[0m13:04:56.766993 [info ] [MainThread]: 
[0m13:04:56.767172 [error] [MainThread]:   Runtime Error in model inventory_status (models/marts/inventory/inventory_status.sql)
  Catalog Error: Table with name int_inventory_with_metrics does not exist!
  Did you mean "information_schema.table_constraints"?
  
  LINE 14:     select * from "dbt_mercurios_dev"."main_intermediate"."int_inventory_with...
                             ^
[0m13:04:56.767326 [info ] [MainThread]: 
[0m13:04:56.767479 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=2 SKIP=3 TOTAL=5
[0m13:04:56.768301 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 0.61533, "process_in_blocks": "0", "process_kernel_time": 0.248388, "process_mem_max_rss": "150650880", "process_out_blocks": "0", "process_user_time": 1.17126}
[0m13:04:56.768506 [debug] [MainThread]: Command `dbt run` failed at 13:04:56.768468 after 0.62 seconds
[0m13:04:56.768715 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1046a20d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112a52dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1046a1f90>]}
[0m13:04:56.768905 [debug] [MainThread]: Flushing usage events
[0m13:04:57.284315 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:04:58.532533 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1137f04d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113a447d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113a67550>]}


============================== 13:04:58.535300 | 39e2cdce-906e-4cd9-96f4-e2f7c92d5606 ==============================
[0m13:04:58.535300 [info ] [MainThread]: Running with dbt=1.9.2
[0m13:04:58.535678 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/juliusrechenbach/API ProHandelTest/dbt_mercurios', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'invocation_command': 'dbt test', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m13:04:58.671771 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '39e2cdce-906e-4cd9-96f4-e2f7c92d5606', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113c96890>]}
[0m13:04:58.708295 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '39e2cdce-906e-4cd9-96f4-e2f7c92d5606', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113db71d0>]}
[0m13:04:58.710565 [info ] [MainThread]: Registered adapter: duckdb=1.9.2
[0m13:04:58.844341 [debug] [MainThread]: checksum: 12b12750b70de726cfd89136b8e24afc3f3e77597a97bff40ab7e5f9b39d5e18, vars: {}, profile: , target: , version: 1.9.2
[0m13:04:58.909841 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m13:04:58.910183 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m13:04:58.913719 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.mercurios.marts.sales
[0m13:04:58.933910 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '39e2cdce-906e-4cd9-96f4-e2f7c92d5606', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11518e210>]}
[0m13:04:59.034983 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/target/manifest.json
[0m13:04:59.037012 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/target/semantic_manifest.json
[0m13:04:59.066594 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '39e2cdce-906e-4cd9-96f4-e2f7c92d5606', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1154d3f10>]}
[0m13:04:59.067153 [info ] [MainThread]: Found 9 models, 17 data tests, 3 sources, 540 macros
[0m13:04:59.068192 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '39e2cdce-906e-4cd9-96f4-e2f7c92d5606', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x115069090>]}
[0m13:04:59.071020 [info ] [MainThread]: 
[0m13:04:59.071601 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m13:04:59.072107 [info ] [MainThread]: 
[0m13:04:59.072869 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m13:04:59.076630 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_dbt_mercurios_dev_main_staging'
[0m13:04:59.077359 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_dbt_mercurios_dev_main_intermediate'
[0m13:04:59.083235 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_dbt_mercurios_dev_main_marts_inventory'
[0m13:04:59.174758 [debug] [ThreadPool]: Using duckdb connection "list_dbt_mercurios_dev_main_staging"
[0m13:04:59.175053 [debug] [ThreadPool]: Using duckdb connection "list_dbt_mercurios_dev_main_intermediate"
[0m13:04:59.175270 [debug] [ThreadPool]: On list_dbt_mercurios_dev_main_staging: BEGIN
[0m13:04:59.175536 [debug] [ThreadPool]: Using duckdb connection "list_dbt_mercurios_dev_main_marts_inventory"
[0m13:04:59.175807 [debug] [ThreadPool]: On list_dbt_mercurios_dev_main_intermediate: BEGIN
[0m13:04:59.176015 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:04:59.176380 [debug] [ThreadPool]: On list_dbt_mercurios_dev_main_marts_inventory: BEGIN
[0m13:04:59.176549 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:04:59.176886 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:04:59.184362 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m13:04:59.184612 [debug] [ThreadPool]: SQL status: OK in 0.009 seconds
[0m13:04:59.184997 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m13:04:59.185233 [debug] [ThreadPool]: Using duckdb connection "list_dbt_mercurios_dev_main_intermediate"
[0m13:04:59.185393 [debug] [ThreadPool]: Using duckdb connection "list_dbt_mercurios_dev_main_staging"
[0m13:04:59.185570 [debug] [ThreadPool]: Using duckdb connection "list_dbt_mercurios_dev_main_marts_inventory"
[0m13:04:59.185732 [debug] [ThreadPool]: On list_dbt_mercurios_dev_main_intermediate: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "list_dbt_mercurios_dev_main_intermediate"} */
select
      'dbt_mercurios_dev' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_intermediate'
    and lower(table_catalog) = 'dbt_mercurios_dev'
  
[0m13:04:59.185910 [debug] [ThreadPool]: On list_dbt_mercurios_dev_main_staging: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "list_dbt_mercurios_dev_main_staging"} */
select
      'dbt_mercurios_dev' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_staging'
    and lower(table_catalog) = 'dbt_mercurios_dev'
  
[0m13:04:59.186078 [debug] [ThreadPool]: On list_dbt_mercurios_dev_main_marts_inventory: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "list_dbt_mercurios_dev_main_marts_inventory"} */
select
      'dbt_mercurios_dev' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_marts_inventory'
    and lower(table_catalog) = 'dbt_mercurios_dev'
  
[0m13:04:59.197082 [debug] [ThreadPool]: SQL status: OK in 0.011 seconds
[0m13:04:59.197401 [debug] [ThreadPool]: SQL status: OK in 0.011 seconds
[0m13:04:59.197645 [debug] [ThreadPool]: SQL status: OK in 0.011 seconds
[0m13:04:59.198588 [debug] [ThreadPool]: On list_dbt_mercurios_dev_main_staging: ROLLBACK
[0m13:04:59.199325 [debug] [ThreadPool]: On list_dbt_mercurios_dev_main_marts_inventory: ROLLBACK
[0m13:04:59.200103 [debug] [ThreadPool]: On list_dbt_mercurios_dev_main_intermediate: ROLLBACK
[0m13:04:59.200876 [debug] [ThreadPool]: Failed to rollback 'list_dbt_mercurios_dev_main_marts_inventory'
[0m13:04:59.201096 [debug] [ThreadPool]: On list_dbt_mercurios_dev_main_marts_inventory: Close
[0m13:04:59.201389 [debug] [ThreadPool]: Failed to rollback 'list_dbt_mercurios_dev_main_staging'
[0m13:04:59.201580 [debug] [ThreadPool]: On list_dbt_mercurios_dev_main_staging: Close
[0m13:04:59.201897 [debug] [ThreadPool]: Failed to rollback 'list_dbt_mercurios_dev_main_intermediate'
[0m13:04:59.202325 [debug] [ThreadPool]: On list_dbt_mercurios_dev_main_intermediate: Close
[0m13:04:59.202769 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '39e2cdce-906e-4cd9-96f4-e2f7c92d5606', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x115011790>]}
[0m13:04:59.203053 [debug] [MainThread]: Using duckdb connection "master"
[0m13:04:59.203211 [debug] [MainThread]: On master: BEGIN
[0m13:04:59.203355 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:04:59.203809 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m13:04:59.203999 [debug] [MainThread]: On master: COMMIT
[0m13:04:59.204154 [debug] [MainThread]: Using duckdb connection "master"
[0m13:04:59.204293 [debug] [MainThread]: On master: COMMIT
[0m13:04:59.204558 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m13:04:59.204778 [debug] [MainThread]: On master: Close
[0m13:04:59.205812 [debug] [Thread-1 (]: Began running node test.mercurios.source_not_null_prohandel_article_article_id.a3a021f44e
[0m13:04:59.206302 [debug] [Thread-2 (]: Began running node test.mercurios.source_not_null_prohandel_article_article_number.bc7d7b092e
[0m13:04:59.206051 [info ] [Thread-1 (]: 1 of 17 START test source_not_null_prohandel_article_article_id ................ [RUN]
[0m13:04:59.206595 [info ] [Thread-2 (]: 2 of 17 START test source_not_null_prohandel_article_article_number ............ [RUN]
[0m13:04:59.207001 [debug] [Thread-3 (]: Began running node test.mercurios.source_not_null_prohandel_inventory_article_id.b5efc266f9
[0m13:04:59.207291 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_dbt_mercurios_dev_main_staging, now test.mercurios.source_not_null_prohandel_article_article_id.a3a021f44e)
[0m13:04:59.207517 [debug] [Thread-4 (]: Began running node test.mercurios.source_not_null_prohandel_inventory_inventory_id.8764c20f3f
[0m13:04:59.207714 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_dbt_mercurios_dev_main_intermediate, now test.mercurios.source_not_null_prohandel_article_article_number.bc7d7b092e)
[0m13:04:59.208007 [info ] [Thread-3 (]: 3 of 17 START test source_not_null_prohandel_inventory_article_id .............. [RUN]
[0m13:04:59.208222 [debug] [Thread-1 (]: Began compiling node test.mercurios.source_not_null_prohandel_article_article_id.a3a021f44e
[0m13:04:59.208409 [info ] [Thread-4 (]: 4 of 17 START test source_not_null_prohandel_inventory_inventory_id ............ [RUN]
[0m13:04:59.208695 [debug] [Thread-2 (]: Began compiling node test.mercurios.source_not_null_prohandel_article_article_number.bc7d7b092e
[0m13:04:59.209006 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_dbt_mercurios_dev_main_marts_inventory, now test.mercurios.source_not_null_prohandel_inventory_article_id.b5efc266f9)
[0m13:04:59.215740 [debug] [Thread-4 (]: Acquiring new duckdb connection 'test.mercurios.source_not_null_prohandel_inventory_inventory_id.8764c20f3f'
[0m13:04:59.219124 [debug] [Thread-1 (]: Writing injected SQL for node "test.mercurios.source_not_null_prohandel_article_article_id.a3a021f44e"
[0m13:04:59.221186 [debug] [Thread-2 (]: Writing injected SQL for node "test.mercurios.source_not_null_prohandel_article_article_number.bc7d7b092e"
[0m13:04:59.221536 [debug] [Thread-3 (]: Began compiling node test.mercurios.source_not_null_prohandel_inventory_article_id.b5efc266f9
[0m13:04:59.221822 [debug] [Thread-4 (]: Began compiling node test.mercurios.source_not_null_prohandel_inventory_inventory_id.8764c20f3f
[0m13:04:59.224518 [debug] [Thread-3 (]: Writing injected SQL for node "test.mercurios.source_not_null_prohandel_inventory_article_id.b5efc266f9"
[0m13:04:59.227534 [debug] [Thread-4 (]: Writing injected SQL for node "test.mercurios.source_not_null_prohandel_inventory_inventory_id.8764c20f3f"
[0m13:04:59.227992 [debug] [Thread-1 (]: Began executing node test.mercurios.source_not_null_prohandel_article_article_id.a3a021f44e
[0m13:04:59.228275 [debug] [Thread-2 (]: Began executing node test.mercurios.source_not_null_prohandel_article_article_number.bc7d7b092e
[0m13:04:59.234692 [debug] [Thread-3 (]: Began executing node test.mercurios.source_not_null_prohandel_inventory_article_id.b5efc266f9
[0m13:04:59.236941 [debug] [Thread-1 (]: Writing runtime sql for node "test.mercurios.source_not_null_prohandel_article_article_id.a3a021f44e"
[0m13:04:59.240125 [debug] [Thread-2 (]: Writing runtime sql for node "test.mercurios.source_not_null_prohandel_article_article_number.bc7d7b092e"
[0m13:04:59.240595 [debug] [Thread-4 (]: Began executing node test.mercurios.source_not_null_prohandel_inventory_inventory_id.8764c20f3f
[0m13:04:59.242723 [debug] [Thread-3 (]: Writing runtime sql for node "test.mercurios.source_not_null_prohandel_inventory_article_id.b5efc266f9"
[0m13:04:59.244690 [debug] [Thread-4 (]: Writing runtime sql for node "test.mercurios.source_not_null_prohandel_inventory_inventory_id.8764c20f3f"
[0m13:04:59.245171 [debug] [Thread-2 (]: Using duckdb connection "test.mercurios.source_not_null_prohandel_article_article_number.bc7d7b092e"
[0m13:04:59.245573 [debug] [Thread-1 (]: Using duckdb connection "test.mercurios.source_not_null_prohandel_article_article_id.a3a021f44e"
[0m13:04:59.245901 [debug] [Thread-3 (]: Using duckdb connection "test.mercurios.source_not_null_prohandel_inventory_article_id.b5efc266f9"
[0m13:04:59.246173 [debug] [Thread-2 (]: On test.mercurios.source_not_null_prohandel_article_article_number.bc7d7b092e: BEGIN
[0m13:04:59.246457 [debug] [Thread-1 (]: On test.mercurios.source_not_null_prohandel_article_article_id.a3a021f44e: BEGIN
[0m13:04:59.246679 [debug] [Thread-4 (]: Using duckdb connection "test.mercurios.source_not_null_prohandel_inventory_inventory_id.8764c20f3f"
[0m13:04:59.246878 [debug] [Thread-3 (]: On test.mercurios.source_not_null_prohandel_inventory_article_id.b5efc266f9: BEGIN
[0m13:04:59.247094 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m13:04:59.247284 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:04:59.247467 [debug] [Thread-4 (]: On test.mercurios.source_not_null_prohandel_inventory_inventory_id.8764c20f3f: BEGIN
[0m13:04:59.247654 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m13:04:59.248250 [debug] [Thread-2 (]: SQL status: OK in 0.001 seconds
[0m13:04:59.248508 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m13:04:59.248740 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m13:04:59.249092 [debug] [Thread-2 (]: Using duckdb connection "test.mercurios.source_not_null_prohandel_article_article_number.bc7d7b092e"
[0m13:04:59.249479 [debug] [Thread-3 (]: SQL status: OK in 0.002 seconds
[0m13:04:59.249716 [debug] [Thread-4 (]: SQL status: OK in 0.001 seconds
[0m13:04:59.249989 [debug] [Thread-1 (]: Using duckdb connection "test.mercurios.source_not_null_prohandel_article_article_id.a3a021f44e"
[0m13:04:59.250304 [debug] [Thread-2 (]: On test.mercurios.source_not_null_prohandel_article_article_number.bc7d7b092e: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "node_id": "test.mercurios.source_not_null_prohandel_article_article_number.bc7d7b092e"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select article_number
from "MERCURIOS_DATA"."RAW"."article"
where article_number is null



      
    ) dbt_internal_test
[0m13:04:59.250603 [debug] [Thread-3 (]: Using duckdb connection "test.mercurios.source_not_null_prohandel_inventory_article_id.b5efc266f9"
[0m13:04:59.250849 [debug] [Thread-4 (]: Using duckdb connection "test.mercurios.source_not_null_prohandel_inventory_inventory_id.8764c20f3f"
[0m13:04:59.251168 [debug] [Thread-1 (]: On test.mercurios.source_not_null_prohandel_article_article_id.a3a021f44e: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "node_id": "test.mercurios.source_not_null_prohandel_article_article_id.a3a021f44e"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select article_id
from "MERCURIOS_DATA"."RAW"."article"
where article_id is null



      
    ) dbt_internal_test
[0m13:04:59.251618 [debug] [Thread-3 (]: On test.mercurios.source_not_null_prohandel_inventory_article_id.b5efc266f9: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "node_id": "test.mercurios.source_not_null_prohandel_inventory_article_id.b5efc266f9"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select article_id
from "MERCURIOS_DATA"."RAW"."inventory"
where article_id is null



      
    ) dbt_internal_test
[0m13:04:59.252029 [debug] [Thread-2 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "node_id": "test.mercurios.source_not_null_prohandel_article_article_number.bc7d7b092e"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select article_number
from "MERCURIOS_DATA"."RAW"."article"
where article_number is null



      
    ) dbt_internal_test
[0m13:04:59.252312 [debug] [Thread-4 (]: On test.mercurios.source_not_null_prohandel_inventory_inventory_id.8764c20f3f: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "node_id": "test.mercurios.source_not_null_prohandel_inventory_inventory_id.8764c20f3f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select inventory_id
from "MERCURIOS_DATA"."RAW"."inventory"
where inventory_id is null



      
    ) dbt_internal_test
[0m13:04:59.252870 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "node_id": "test.mercurios.source_not_null_prohandel_article_article_id.a3a021f44e"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select article_id
from "MERCURIOS_DATA"."RAW"."article"
where article_id is null



      
    ) dbt_internal_test
[0m13:04:59.253124 [debug] [Thread-2 (]: DuckDB adapter: Rolling back transaction.
[0m13:04:59.253443 [debug] [Thread-3 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "node_id": "test.mercurios.source_not_null_prohandel_inventory_article_id.b5efc266f9"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select article_id
from "MERCURIOS_DATA"."RAW"."inventory"
where article_id is null



      
    ) dbt_internal_test
[0m13:04:59.253807 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m13:04:59.254144 [debug] [Thread-4 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "node_id": "test.mercurios.source_not_null_prohandel_inventory_inventory_id.8764c20f3f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select inventory_id
from "MERCURIOS_DATA"."RAW"."inventory"
where inventory_id is null



      
    ) dbt_internal_test
[0m13:04:59.254482 [debug] [Thread-2 (]: On test.mercurios.source_not_null_prohandel_article_article_number.bc7d7b092e: ROLLBACK
[0m13:04:59.254733 [debug] [Thread-3 (]: DuckDB adapter: Rolling back transaction.
[0m13:04:59.255001 [debug] [Thread-1 (]: On test.mercurios.source_not_null_prohandel_article_article_id.a3a021f44e: ROLLBACK
[0m13:04:59.255218 [debug] [Thread-4 (]: DuckDB adapter: Rolling back transaction.
[0m13:04:59.256303 [debug] [Thread-3 (]: On test.mercurios.source_not_null_prohandel_inventory_article_id.b5efc266f9: ROLLBACK
[0m13:04:59.257415 [debug] [Thread-4 (]: On test.mercurios.source_not_null_prohandel_inventory_inventory_id.8764c20f3f: ROLLBACK
[0m13:04:59.263450 [debug] [Thread-2 (]: Failed to rollback 'test.mercurios.source_not_null_prohandel_article_article_number.bc7d7b092e'
[0m13:04:59.264113 [debug] [Thread-2 (]: On test.mercurios.source_not_null_prohandel_article_article_number.bc7d7b092e: Close
[0m13:04:59.264984 [debug] [Thread-4 (]: Failed to rollback 'test.mercurios.source_not_null_prohandel_inventory_inventory_id.8764c20f3f'
[0m13:04:59.266906 [debug] [Thread-3 (]: Failed to rollback 'test.mercurios.source_not_null_prohandel_inventory_article_id.b5efc266f9'
[0m13:04:59.267796 [debug] [Thread-1 (]: Failed to rollback 'test.mercurios.source_not_null_prohandel_article_article_id.a3a021f44e'
[0m13:04:59.267998 [debug] [Thread-4 (]: On test.mercurios.source_not_null_prohandel_inventory_inventory_id.8764c20f3f: Close
[0m13:04:59.269102 [debug] [Thread-2 (]: Runtime Error in test source_not_null_prohandel_article_article_number (models/staging/src_prohandel.yml)
  Binder Error: Catalog "MERCURIOS_DATA" does not exist!
[0m13:04:59.269383 [debug] [Thread-3 (]: On test.mercurios.source_not_null_prohandel_inventory_article_id.b5efc266f9: Close
[0m13:04:59.269700 [debug] [Thread-1 (]: On test.mercurios.source_not_null_prohandel_article_article_id.a3a021f44e: Close
[0m13:04:59.270061 [error] [Thread-2 (]: 2 of 17 ERROR source_not_null_prohandel_article_article_number ................. [[31mERROR[0m in 0.06s]
[0m13:04:59.272617 [debug] [Thread-4 (]: Runtime Error in test source_not_null_prohandel_inventory_inventory_id (models/staging/src_prohandel.yml)
  Binder Error: Catalog "MERCURIOS_DATA" does not exist!
[0m13:04:59.273481 [debug] [Thread-3 (]: Runtime Error in test source_not_null_prohandel_inventory_article_id (models/staging/src_prohandel.yml)
  Binder Error: Catalog "MERCURIOS_DATA" does not exist!
[0m13:04:59.274533 [debug] [Thread-2 (]: Finished running node test.mercurios.source_not_null_prohandel_article_article_number.bc7d7b092e
[0m13:04:59.275303 [debug] [Thread-1 (]: Runtime Error in test source_not_null_prohandel_article_article_id (models/staging/src_prohandel.yml)
  Binder Error: Catalog "MERCURIOS_DATA" does not exist!
[0m13:04:59.275675 [error] [Thread-4 (]: 4 of 17 ERROR source_not_null_prohandel_inventory_inventory_id ................. [[31mERROR[0m in 0.06s]
[0m13:04:59.276077 [error] [Thread-3 (]: 3 of 17 ERROR source_not_null_prohandel_inventory_article_id ................... [[31mERROR[0m in 0.07s]
[0m13:04:59.276474 [debug] [Thread-2 (]: Began running node test.mercurios.source_not_null_prohandel_inventory_quantity.ddfd3d3568
[0m13:04:59.276811 [debug] [Thread-7 (]: Marking all children of 'test.mercurios.source_not_null_prohandel_article_article_number.bc7d7b092e' to be skipped because of status 'error'.  Reason: Runtime Error in test source_not_null_prohandel_article_article_number (models/staging/src_prohandel.yml)
  Binder Error: Catalog "MERCURIOS_DATA" does not exist!.
[0m13:04:59.277151 [error] [Thread-1 (]: 1 of 17 ERROR source_not_null_prohandel_article_article_id ..................... [[31mERROR[0m in 0.07s]
[0m13:04:59.277618 [debug] [Thread-4 (]: Finished running node test.mercurios.source_not_null_prohandel_inventory_inventory_id.8764c20f3f
[0m13:04:59.277948 [debug] [Thread-3 (]: Finished running node test.mercurios.source_not_null_prohandel_inventory_article_id.b5efc266f9
[0m13:04:59.278184 [info ] [Thread-2 (]: 5 of 17 START test source_not_null_prohandel_inventory_quantity ................ [RUN]
[0m13:04:59.279101 [debug] [Thread-1 (]: Finished running node test.mercurios.source_not_null_prohandel_article_article_id.a3a021f44e
[0m13:04:59.279341 [debug] [Thread-4 (]: Began running node test.mercurios.source_not_null_prohandel_inventory_warehouse_id.6307156ecb
[0m13:04:59.279550 [debug] [Thread-3 (]: Began running node test.mercurios.source_not_null_prohandel_sale_article_id.ed4013e08f
[0m13:04:59.279747 [debug] [Thread-7 (]: Marking all children of 'test.mercurios.source_not_null_prohandel_inventory_inventory_id.8764c20f3f' to be skipped because of status 'error'.  Reason: Runtime Error in test source_not_null_prohandel_inventory_inventory_id (models/staging/src_prohandel.yml)
  Binder Error: Catalog "MERCURIOS_DATA" does not exist!.
[0m13:04:59.279994 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly test.mercurios.source_not_null_prohandel_article_article_number.bc7d7b092e, now test.mercurios.source_not_null_prohandel_inventory_quantity.ddfd3d3568)
[0m13:04:59.280192 [debug] [Thread-1 (]: Began running node test.mercurios.source_not_null_prohandel_sale_order_id.5242416524
[0m13:04:59.280378 [info ] [Thread-4 (]: 6 of 17 START test source_not_null_prohandel_inventory_warehouse_id ............ [RUN]
[0m13:04:59.280577 [info ] [Thread-3 (]: 7 of 17 START test source_not_null_prohandel_sale_article_id ................... [RUN]
[0m13:04:59.281038 [debug] [Thread-7 (]: Marking all children of 'test.mercurios.source_not_null_prohandel_inventory_article_id.b5efc266f9' to be skipped because of status 'error'.  Reason: Runtime Error in test source_not_null_prohandel_inventory_article_id (models/staging/src_prohandel.yml)
  Binder Error: Catalog "MERCURIOS_DATA" does not exist!.
[0m13:04:59.281250 [debug] [Thread-2 (]: Began compiling node test.mercurios.source_not_null_prohandel_inventory_quantity.ddfd3d3568
[0m13:04:59.281423 [info ] [Thread-1 (]: 8 of 17 START test source_not_null_prohandel_sale_order_id ..................... [RUN]
[0m13:04:59.281633 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly test.mercurios.source_not_null_prohandel_inventory_inventory_id.8764c20f3f, now test.mercurios.source_not_null_prohandel_inventory_warehouse_id.6307156ecb)
[0m13:04:59.281992 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly test.mercurios.source_not_null_prohandel_inventory_article_id.b5efc266f9, now test.mercurios.source_not_null_prohandel_sale_article_id.ed4013e08f)
[0m13:04:59.282273 [debug] [Thread-7 (]: Marking all children of 'test.mercurios.source_not_null_prohandel_article_article_id.a3a021f44e' to be skipped because of status 'error'.  Reason: Runtime Error in test source_not_null_prohandel_article_article_id (models/staging/src_prohandel.yml)
  Binder Error: Catalog "MERCURIOS_DATA" does not exist!.
[0m13:04:59.284896 [debug] [Thread-2 (]: Writing injected SQL for node "test.mercurios.source_not_null_prohandel_inventory_quantity.ddfd3d3568"
[0m13:04:59.285389 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.mercurios.source_not_null_prohandel_article_article_id.a3a021f44e, now test.mercurios.source_not_null_prohandel_sale_order_id.5242416524)
[0m13:04:59.285720 [debug] [Thread-4 (]: Began compiling node test.mercurios.source_not_null_prohandel_inventory_warehouse_id.6307156ecb
[0m13:04:59.286032 [debug] [Thread-3 (]: Began compiling node test.mercurios.source_not_null_prohandel_sale_article_id.ed4013e08f
[0m13:04:59.286583 [debug] [Thread-1 (]: Began compiling node test.mercurios.source_not_null_prohandel_sale_order_id.5242416524
[0m13:04:59.290552 [debug] [Thread-4 (]: Writing injected SQL for node "test.mercurios.source_not_null_prohandel_inventory_warehouse_id.6307156ecb"
[0m13:04:59.290927 [debug] [Thread-2 (]: Began executing node test.mercurios.source_not_null_prohandel_inventory_quantity.ddfd3d3568
[0m13:04:59.293147 [debug] [Thread-3 (]: Writing injected SQL for node "test.mercurios.source_not_null_prohandel_sale_article_id.ed4013e08f"
[0m13:04:59.295852 [debug] [Thread-1 (]: Writing injected SQL for node "test.mercurios.source_not_null_prohandel_sale_order_id.5242416524"
[0m13:04:59.297565 [debug] [Thread-2 (]: Writing runtime sql for node "test.mercurios.source_not_null_prohandel_inventory_quantity.ddfd3d3568"
[0m13:04:59.297987 [debug] [Thread-4 (]: Began executing node test.mercurios.source_not_null_prohandel_inventory_warehouse_id.6307156ecb
[0m13:04:59.299722 [debug] [Thread-4 (]: Writing runtime sql for node "test.mercurios.source_not_null_prohandel_inventory_warehouse_id.6307156ecb"
[0m13:04:59.299964 [debug] [Thread-3 (]: Began executing node test.mercurios.source_not_null_prohandel_sale_article_id.ed4013e08f
[0m13:04:59.300430 [debug] [Thread-1 (]: Began executing node test.mercurios.source_not_null_prohandel_sale_order_id.5242416524
[0m13:04:59.301756 [debug] [Thread-3 (]: Writing runtime sql for node "test.mercurios.source_not_null_prohandel_sale_article_id.ed4013e08f"
[0m13:04:59.302056 [debug] [Thread-2 (]: Using duckdb connection "test.mercurios.source_not_null_prohandel_inventory_quantity.ddfd3d3568"
[0m13:04:59.303801 [debug] [Thread-1 (]: Writing runtime sql for node "test.mercurios.source_not_null_prohandel_sale_order_id.5242416524"
[0m13:04:59.304157 [debug] [Thread-4 (]: Using duckdb connection "test.mercurios.source_not_null_prohandel_inventory_warehouse_id.6307156ecb"
[0m13:04:59.304406 [debug] [Thread-2 (]: On test.mercurios.source_not_null_prohandel_inventory_quantity.ddfd3d3568: BEGIN
[0m13:04:59.304686 [debug] [Thread-4 (]: On test.mercurios.source_not_null_prohandel_inventory_warehouse_id.6307156ecb: BEGIN
[0m13:04:59.305010 [debug] [Thread-3 (]: Using duckdb connection "test.mercurios.source_not_null_prohandel_sale_article_id.ed4013e08f"
[0m13:04:59.305245 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m13:04:59.305461 [debug] [Thread-1 (]: Using duckdb connection "test.mercurios.source_not_null_prohandel_sale_order_id.5242416524"
[0m13:04:59.305699 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m13:04:59.305972 [debug] [Thread-3 (]: On test.mercurios.source_not_null_prohandel_sale_article_id.ed4013e08f: BEGIN
[0m13:04:59.306376 [debug] [Thread-1 (]: On test.mercurios.source_not_null_prohandel_sale_order_id.5242416524: BEGIN
[0m13:04:59.306713 [debug] [Thread-2 (]: SQL status: OK in 0.001 seconds
[0m13:04:59.307018 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m13:04:59.307226 [debug] [Thread-4 (]: SQL status: OK in 0.002 seconds
[0m13:04:59.307443 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:04:59.307649 [debug] [Thread-2 (]: Using duckdb connection "test.mercurios.source_not_null_prohandel_inventory_quantity.ddfd3d3568"
[0m13:04:59.307940 [debug] [Thread-4 (]: Using duckdb connection "test.mercurios.source_not_null_prohandel_inventory_warehouse_id.6307156ecb"
[0m13:04:59.308129 [debug] [Thread-3 (]: SQL status: OK in 0.001 seconds
[0m13:04:59.308381 [debug] [Thread-2 (]: On test.mercurios.source_not_null_prohandel_inventory_quantity.ddfd3d3568: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "node_id": "test.mercurios.source_not_null_prohandel_inventory_quantity.ddfd3d3568"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select quantity
from "MERCURIOS_DATA"."RAW"."inventory"
where quantity is null



      
    ) dbt_internal_test
[0m13:04:59.308727 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m13:04:59.308959 [debug] [Thread-4 (]: On test.mercurios.source_not_null_prohandel_inventory_warehouse_id.6307156ecb: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "node_id": "test.mercurios.source_not_null_prohandel_inventory_warehouse_id.6307156ecb"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select warehouse_id
from "MERCURIOS_DATA"."RAW"."inventory"
where warehouse_id is null



      
    ) dbt_internal_test
[0m13:04:59.309207 [debug] [Thread-3 (]: Using duckdb connection "test.mercurios.source_not_null_prohandel_sale_article_id.ed4013e08f"
[0m13:04:59.309614 [debug] [Thread-1 (]: Using duckdb connection "test.mercurios.source_not_null_prohandel_sale_order_id.5242416524"
[0m13:04:59.309937 [debug] [Thread-2 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "node_id": "test.mercurios.source_not_null_prohandel_inventory_quantity.ddfd3d3568"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select quantity
from "MERCURIOS_DATA"."RAW"."inventory"
where quantity is null



      
    ) dbt_internal_test
[0m13:04:59.310401 [debug] [Thread-3 (]: On test.mercurios.source_not_null_prohandel_sale_article_id.ed4013e08f: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "node_id": "test.mercurios.source_not_null_prohandel_sale_article_id.ed4013e08f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select article_id
from "MERCURIOS_DATA"."RAW"."sale"
where article_id is null



      
    ) dbt_internal_test
[0m13:04:59.310706 [debug] [Thread-4 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "node_id": "test.mercurios.source_not_null_prohandel_inventory_warehouse_id.6307156ecb"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select warehouse_id
from "MERCURIOS_DATA"."RAW"."inventory"
where warehouse_id is null



      
    ) dbt_internal_test
[0m13:04:59.311030 [debug] [Thread-1 (]: On test.mercurios.source_not_null_prohandel_sale_order_id.5242416524: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "node_id": "test.mercurios.source_not_null_prohandel_sale_order_id.5242416524"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_id
from "MERCURIOS_DATA"."RAW"."sale"
where order_id is null



      
    ) dbt_internal_test
[0m13:04:59.311269 [debug] [Thread-2 (]: DuckDB adapter: Rolling back transaction.
[0m13:04:59.311654 [debug] [Thread-4 (]: DuckDB adapter: Rolling back transaction.
[0m13:04:59.311951 [debug] [Thread-3 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "node_id": "test.mercurios.source_not_null_prohandel_sale_article_id.ed4013e08f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select article_id
from "MERCURIOS_DATA"."RAW"."sale"
where article_id is null



      
    ) dbt_internal_test
[0m13:04:59.312491 [debug] [Thread-2 (]: On test.mercurios.source_not_null_prohandel_inventory_quantity.ddfd3d3568: ROLLBACK
[0m13:04:59.312855 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "node_id": "test.mercurios.source_not_null_prohandel_sale_order_id.5242416524"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_id
from "MERCURIOS_DATA"."RAW"."sale"
where order_id is null



      
    ) dbt_internal_test
[0m13:04:59.313195 [debug] [Thread-4 (]: On test.mercurios.source_not_null_prohandel_inventory_warehouse_id.6307156ecb: ROLLBACK
[0m13:04:59.313541 [debug] [Thread-3 (]: DuckDB adapter: Rolling back transaction.
[0m13:04:59.314394 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m13:04:59.315447 [debug] [Thread-3 (]: On test.mercurios.source_not_null_prohandel_sale_article_id.ed4013e08f: ROLLBACK
[0m13:04:59.315928 [debug] [Thread-1 (]: On test.mercurios.source_not_null_prohandel_sale_order_id.5242416524: ROLLBACK
[0m13:04:59.316800 [debug] [Thread-2 (]: Failed to rollback 'test.mercurios.source_not_null_prohandel_inventory_quantity.ddfd3d3568'
[0m13:04:59.318327 [debug] [Thread-4 (]: Failed to rollback 'test.mercurios.source_not_null_prohandel_inventory_warehouse_id.6307156ecb'
[0m13:04:59.319808 [debug] [Thread-1 (]: Failed to rollback 'test.mercurios.source_not_null_prohandel_sale_order_id.5242416524'
[0m13:04:59.320062 [debug] [Thread-2 (]: On test.mercurios.source_not_null_prohandel_inventory_quantity.ddfd3d3568: Close
[0m13:04:59.321778 [debug] [Thread-3 (]: Failed to rollback 'test.mercurios.source_not_null_prohandel_sale_article_id.ed4013e08f'
[0m13:04:59.322073 [debug] [Thread-4 (]: On test.mercurios.source_not_null_prohandel_inventory_warehouse_id.6307156ecb: Close
[0m13:04:59.322372 [debug] [Thread-1 (]: On test.mercurios.source_not_null_prohandel_sale_order_id.5242416524: Close
[0m13:04:59.322673 [debug] [Thread-3 (]: On test.mercurios.source_not_null_prohandel_sale_article_id.ed4013e08f: Close
[0m13:04:59.324990 [debug] [Thread-2 (]: Runtime Error in test source_not_null_prohandel_inventory_quantity (models/staging/src_prohandel.yml)
  Binder Error: Catalog "MERCURIOS_DATA" does not exist!
[0m13:04:59.325803 [debug] [Thread-4 (]: Runtime Error in test source_not_null_prohandel_inventory_warehouse_id (models/staging/src_prohandel.yml)
  Binder Error: Catalog "MERCURIOS_DATA" does not exist!
[0m13:04:59.327868 [debug] [Thread-1 (]: Runtime Error in test source_not_null_prohandel_sale_order_id (models/staging/src_prohandel.yml)
  Binder Error: Catalog "MERCURIOS_DATA" does not exist!
[0m13:04:59.328739 [debug] [Thread-3 (]: Runtime Error in test source_not_null_prohandel_sale_article_id (models/staging/src_prohandel.yml)
  Binder Error: Catalog "MERCURIOS_DATA" does not exist!
[0m13:04:59.329094 [error] [Thread-2 (]: 5 of 17 ERROR source_not_null_prohandel_inventory_quantity ..................... [[31mERROR[0m in 0.05s]
[0m13:04:59.333333 [error] [Thread-4 (]: 6 of 17 ERROR source_not_null_prohandel_inventory_warehouse_id ................. [[31mERROR[0m in 0.05s]
[0m13:04:59.333672 [error] [Thread-1 (]: 8 of 17 ERROR source_not_null_prohandel_sale_order_id .......................... [[31mERROR[0m in 0.05s]
[0m13:04:59.334010 [error] [Thread-3 (]: 7 of 17 ERROR source_not_null_prohandel_sale_article_id ........................ [[31mERROR[0m in 0.05s]
[0m13:04:59.334803 [debug] [Thread-2 (]: Finished running node test.mercurios.source_not_null_prohandel_inventory_quantity.ddfd3d3568
[0m13:04:59.335214 [debug] [Thread-4 (]: Finished running node test.mercurios.source_not_null_prohandel_inventory_warehouse_id.6307156ecb
[0m13:04:59.335596 [debug] [Thread-1 (]: Finished running node test.mercurios.source_not_null_prohandel_sale_order_id.5242416524
[0m13:04:59.335855 [debug] [Thread-3 (]: Finished running node test.mercurios.source_not_null_prohandel_sale_article_id.ed4013e08f
[0m13:04:59.336122 [debug] [Thread-2 (]: Began running node test.mercurios.source_not_null_prohandel_sale_price.3f2611cfb8
[0m13:04:59.336419 [debug] [Thread-7 (]: Marking all children of 'test.mercurios.source_not_null_prohandel_inventory_quantity.ddfd3d3568' to be skipped because of status 'error'.  Reason: Runtime Error in test source_not_null_prohandel_inventory_quantity (models/staging/src_prohandel.yml)
  Binder Error: Catalog "MERCURIOS_DATA" does not exist!.
[0m13:04:59.336680 [debug] [Thread-4 (]: Began running node test.mercurios.source_not_null_prohandel_sale_quantity.e6b3fcca5f
[0m13:04:59.336945 [debug] [Thread-1 (]: Began running node test.mercurios.source_not_null_prohandel_sale_sale_date.fe13d0a52e
[0m13:04:59.337236 [debug] [Thread-3 (]: Began running node test.mercurios.source_not_null_prohandel_sale_sale_id.d7df7f53a6
[0m13:04:59.337480 [info ] [Thread-2 (]: 9 of 17 START test source_not_null_prohandel_sale_price ........................ [RUN]
[0m13:04:59.337844 [debug] [Thread-7 (]: Marking all children of 'test.mercurios.source_not_null_prohandel_inventory_warehouse_id.6307156ecb' to be skipped because of status 'error'.  Reason: Runtime Error in test source_not_null_prohandel_inventory_warehouse_id (models/staging/src_prohandel.yml)
  Binder Error: Catalog "MERCURIOS_DATA" does not exist!.
[0m13:04:59.338061 [info ] [Thread-4 (]: 10 of 17 START test source_not_null_prohandel_sale_quantity .................... [RUN]
[0m13:04:59.338274 [info ] [Thread-1 (]: 11 of 17 START test source_not_null_prohandel_sale_sale_date ................... [RUN]
[0m13:04:59.338502 [info ] [Thread-3 (]: 12 of 17 START test source_not_null_prohandel_sale_sale_id ..................... [RUN]
[0m13:04:59.338804 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly test.mercurios.source_not_null_prohandel_inventory_quantity.ddfd3d3568, now test.mercurios.source_not_null_prohandel_sale_price.3f2611cfb8)
[0m13:04:59.339084 [debug] [Thread-7 (]: Marking all children of 'test.mercurios.source_not_null_prohandel_sale_order_id.5242416524' to be skipped because of status 'error'.  Reason: Runtime Error in test source_not_null_prohandel_sale_order_id (models/staging/src_prohandel.yml)
  Binder Error: Catalog "MERCURIOS_DATA" does not exist!.
[0m13:04:59.339310 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly test.mercurios.source_not_null_prohandel_inventory_warehouse_id.6307156ecb, now test.mercurios.source_not_null_prohandel_sale_quantity.e6b3fcca5f)
[0m13:04:59.339542 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.mercurios.source_not_null_prohandel_sale_order_id.5242416524, now test.mercurios.source_not_null_prohandel_sale_sale_date.fe13d0a52e)
[0m13:04:59.339740 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly test.mercurios.source_not_null_prohandel_sale_article_id.ed4013e08f, now test.mercurios.source_not_null_prohandel_sale_sale_id.d7df7f53a6)
[0m13:04:59.339943 [debug] [Thread-2 (]: Began compiling node test.mercurios.source_not_null_prohandel_sale_price.3f2611cfb8
[0m13:04:59.340191 [debug] [Thread-7 (]: Marking all children of 'test.mercurios.source_not_null_prohandel_sale_article_id.ed4013e08f' to be skipped because of status 'error'.  Reason: Runtime Error in test source_not_null_prohandel_sale_article_id (models/staging/src_prohandel.yml)
  Binder Error: Catalog "MERCURIOS_DATA" does not exist!.
[0m13:04:59.340390 [debug] [Thread-4 (]: Began compiling node test.mercurios.source_not_null_prohandel_sale_quantity.e6b3fcca5f
[0m13:04:59.340572 [debug] [Thread-1 (]: Began compiling node test.mercurios.source_not_null_prohandel_sale_sale_date.fe13d0a52e
[0m13:04:59.340890 [debug] [Thread-3 (]: Began compiling node test.mercurios.source_not_null_prohandel_sale_sale_id.d7df7f53a6
[0m13:04:59.343633 [debug] [Thread-2 (]: Writing injected SQL for node "test.mercurios.source_not_null_prohandel_sale_price.3f2611cfb8"
[0m13:04:59.346464 [debug] [Thread-4 (]: Writing injected SQL for node "test.mercurios.source_not_null_prohandel_sale_quantity.e6b3fcca5f"
[0m13:04:59.348727 [debug] [Thread-1 (]: Writing injected SQL for node "test.mercurios.source_not_null_prohandel_sale_sale_date.fe13d0a52e"
[0m13:04:59.351861 [debug] [Thread-3 (]: Writing injected SQL for node "test.mercurios.source_not_null_prohandel_sale_sale_id.d7df7f53a6"
[0m13:04:59.352654 [debug] [Thread-1 (]: Began executing node test.mercurios.source_not_null_prohandel_sale_sale_date.fe13d0a52e
[0m13:04:59.354175 [debug] [Thread-1 (]: Writing runtime sql for node "test.mercurios.source_not_null_prohandel_sale_sale_date.fe13d0a52e"
[0m13:04:59.354442 [debug] [Thread-4 (]: Began executing node test.mercurios.source_not_null_prohandel_sale_quantity.e6b3fcca5f
[0m13:04:59.354659 [debug] [Thread-2 (]: Began executing node test.mercurios.source_not_null_prohandel_sale_price.3f2611cfb8
[0m13:04:59.354911 [debug] [Thread-3 (]: Began executing node test.mercurios.source_not_null_prohandel_sale_sale_id.d7df7f53a6
[0m13:04:59.356271 [debug] [Thread-4 (]: Writing runtime sql for node "test.mercurios.source_not_null_prohandel_sale_quantity.e6b3fcca5f"
[0m13:04:59.357548 [debug] [Thread-2 (]: Writing runtime sql for node "test.mercurios.source_not_null_prohandel_sale_price.3f2611cfb8"
[0m13:04:59.358802 [debug] [Thread-3 (]: Writing runtime sql for node "test.mercurios.source_not_null_prohandel_sale_sale_id.d7df7f53a6"
[0m13:04:59.359029 [debug] [Thread-1 (]: Using duckdb connection "test.mercurios.source_not_null_prohandel_sale_sale_date.fe13d0a52e"
[0m13:04:59.359432 [debug] [Thread-1 (]: On test.mercurios.source_not_null_prohandel_sale_sale_date.fe13d0a52e: BEGIN
[0m13:04:59.359648 [debug] [Thread-4 (]: Using duckdb connection "test.mercurios.source_not_null_prohandel_sale_quantity.e6b3fcca5f"
[0m13:04:59.359892 [debug] [Thread-2 (]: Using duckdb connection "test.mercurios.source_not_null_prohandel_sale_price.3f2611cfb8"
[0m13:04:59.360083 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:04:59.360303 [debug] [Thread-3 (]: Using duckdb connection "test.mercurios.source_not_null_prohandel_sale_sale_id.d7df7f53a6"
[0m13:04:59.360517 [debug] [Thread-4 (]: On test.mercurios.source_not_null_prohandel_sale_quantity.e6b3fcca5f: BEGIN
[0m13:04:59.360714 [debug] [Thread-2 (]: On test.mercurios.source_not_null_prohandel_sale_price.3f2611cfb8: BEGIN
[0m13:04:59.361058 [debug] [Thread-3 (]: On test.mercurios.source_not_null_prohandel_sale_sale_id.d7df7f53a6: BEGIN
[0m13:04:59.361303 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m13:04:59.361500 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m13:04:59.361691 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m13:04:59.361899 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m13:04:59.362159 [debug] [Thread-1 (]: Using duckdb connection "test.mercurios.source_not_null_prohandel_sale_sale_date.fe13d0a52e"
[0m13:04:59.362379 [debug] [Thread-4 (]: SQL status: OK in 0.001 seconds
[0m13:04:59.362550 [debug] [Thread-2 (]: SQL status: OK in 0.001 seconds
[0m13:04:59.362815 [debug] [Thread-1 (]: On test.mercurios.source_not_null_prohandel_sale_sale_date.fe13d0a52e: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "node_id": "test.mercurios.source_not_null_prohandel_sale_sale_date.fe13d0a52e"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select sale_date
from "MERCURIOS_DATA"."RAW"."sale"
where sale_date is null



      
    ) dbt_internal_test
[0m13:04:59.363053 [debug] [Thread-3 (]: SQL status: OK in 0.001 seconds
[0m13:04:59.363281 [debug] [Thread-4 (]: Using duckdb connection "test.mercurios.source_not_null_prohandel_sale_quantity.e6b3fcca5f"
[0m13:04:59.363513 [debug] [Thread-2 (]: Using duckdb connection "test.mercurios.source_not_null_prohandel_sale_price.3f2611cfb8"
[0m13:04:59.363822 [debug] [Thread-3 (]: Using duckdb connection "test.mercurios.source_not_null_prohandel_sale_sale_id.d7df7f53a6"
[0m13:04:59.364055 [debug] [Thread-4 (]: On test.mercurios.source_not_null_prohandel_sale_quantity.e6b3fcca5f: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "node_id": "test.mercurios.source_not_null_prohandel_sale_quantity.e6b3fcca5f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select quantity
from "MERCURIOS_DATA"."RAW"."sale"
where quantity is null



      
    ) dbt_internal_test
[0m13:04:59.364325 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "node_id": "test.mercurios.source_not_null_prohandel_sale_sale_date.fe13d0a52e"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select sale_date
from "MERCURIOS_DATA"."RAW"."sale"
where sale_date is null



      
    ) dbt_internal_test
[0m13:04:59.364546 [debug] [Thread-2 (]: On test.mercurios.source_not_null_prohandel_sale_price.3f2611cfb8: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "node_id": "test.mercurios.source_not_null_prohandel_sale_price.3f2611cfb8"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select price
from "MERCURIOS_DATA"."RAW"."sale"
where price is null



      
    ) dbt_internal_test
[0m13:04:59.364771 [debug] [Thread-3 (]: On test.mercurios.source_not_null_prohandel_sale_sale_id.d7df7f53a6: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "node_id": "test.mercurios.source_not_null_prohandel_sale_sale_id.d7df7f53a6"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select sale_id
from "MERCURIOS_DATA"."RAW"."sale"
where sale_id is null



      
    ) dbt_internal_test
[0m13:04:59.365062 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m13:04:59.365293 [debug] [Thread-4 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "node_id": "test.mercurios.source_not_null_prohandel_sale_quantity.e6b3fcca5f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select quantity
from "MERCURIOS_DATA"."RAW"."sale"
where quantity is null



      
    ) dbt_internal_test
[0m13:04:59.365701 [debug] [Thread-2 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "node_id": "test.mercurios.source_not_null_prohandel_sale_price.3f2611cfb8"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select price
from "MERCURIOS_DATA"."RAW"."sale"
where price is null



      
    ) dbt_internal_test
[0m13:04:59.366012 [debug] [Thread-1 (]: On test.mercurios.source_not_null_prohandel_sale_sale_date.fe13d0a52e: ROLLBACK
[0m13:04:59.366257 [debug] [Thread-3 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "node_id": "test.mercurios.source_not_null_prohandel_sale_sale_id.d7df7f53a6"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select sale_id
from "MERCURIOS_DATA"."RAW"."sale"
where sale_id is null



      
    ) dbt_internal_test
[0m13:04:59.366458 [debug] [Thread-4 (]: DuckDB adapter: Rolling back transaction.
[0m13:04:59.366644 [debug] [Thread-2 (]: DuckDB adapter: Rolling back transaction.
[0m13:04:59.367419 [debug] [Thread-3 (]: DuckDB adapter: Rolling back transaction.
[0m13:04:59.367782 [debug] [Thread-4 (]: On test.mercurios.source_not_null_prohandel_sale_quantity.e6b3fcca5f: ROLLBACK
[0m13:04:59.368667 [debug] [Thread-1 (]: Failed to rollback 'test.mercurios.source_not_null_prohandel_sale_sale_date.fe13d0a52e'
[0m13:04:59.368943 [debug] [Thread-2 (]: On test.mercurios.source_not_null_prohandel_sale_price.3f2611cfb8: ROLLBACK
[0m13:04:59.369216 [debug] [Thread-3 (]: On test.mercurios.source_not_null_prohandel_sale_sale_id.d7df7f53a6: ROLLBACK
[0m13:04:59.370388 [debug] [Thread-1 (]: On test.mercurios.source_not_null_prohandel_sale_sale_date.fe13d0a52e: Close
[0m13:04:59.372788 [debug] [Thread-4 (]: Failed to rollback 'test.mercurios.source_not_null_prohandel_sale_quantity.e6b3fcca5f'
[0m13:04:59.373729 [debug] [Thread-2 (]: Failed to rollback 'test.mercurios.source_not_null_prohandel_sale_price.3f2611cfb8'
[0m13:04:59.375040 [debug] [Thread-1 (]: Runtime Error in test source_not_null_prohandel_sale_sale_date (models/staging/src_prohandel.yml)
  Binder Error: Catalog "MERCURIOS_DATA" does not exist!
[0m13:04:59.375237 [debug] [Thread-4 (]: On test.mercurios.source_not_null_prohandel_sale_quantity.e6b3fcca5f: Close
[0m13:04:59.375947 [debug] [Thread-3 (]: Failed to rollback 'test.mercurios.source_not_null_prohandel_sale_sale_id.d7df7f53a6'
[0m13:04:59.376124 [debug] [Thread-2 (]: On test.mercurios.source_not_null_prohandel_sale_price.3f2611cfb8: Close
[0m13:04:59.376360 [error] [Thread-1 (]: 11 of 17 ERROR source_not_null_prohandel_sale_sale_date ........................ [[31mERROR[0m in 0.04s]
[0m13:04:59.377621 [debug] [Thread-4 (]: Runtime Error in test source_not_null_prohandel_sale_quantity (models/staging/src_prohandel.yml)
  Binder Error: Catalog "MERCURIOS_DATA" does not exist!
[0m13:04:59.377813 [debug] [Thread-3 (]: On test.mercurios.source_not_null_prohandel_sale_sale_id.d7df7f53a6: Close
[0m13:04:59.378832 [debug] [Thread-1 (]: Finished running node test.mercurios.source_not_null_prohandel_sale_sale_date.fe13d0a52e
[0m13:04:59.379142 [error] [Thread-4 (]: 10 of 17 ERROR source_not_null_prohandel_sale_quantity ......................... [[31mERROR[0m in 0.04s]
[0m13:04:59.380002 [debug] [Thread-2 (]: Runtime Error in test source_not_null_prohandel_sale_price (models/staging/src_prohandel.yml)
  Binder Error: Catalog "MERCURIOS_DATA" does not exist!
[0m13:04:59.381332 [debug] [Thread-3 (]: Runtime Error in test source_not_null_prohandel_sale_sale_id (models/staging/src_prohandel.yml)
  Binder Error: Catalog "MERCURIOS_DATA" does not exist!
[0m13:04:59.381579 [debug] [Thread-1 (]: Began running node test.mercurios.source_relationships_prohandel_inventory_article_id__article_id__source_prohandel_article_.e4c4fdb4dc
[0m13:04:59.381825 [debug] [Thread-4 (]: Finished running node test.mercurios.source_not_null_prohandel_sale_quantity.e6b3fcca5f
[0m13:04:59.382176 [debug] [Thread-7 (]: Marking all children of 'test.mercurios.source_not_null_prohandel_sale_sale_date.fe13d0a52e' to be skipped because of status 'error'.  Reason: Runtime Error in test source_not_null_prohandel_sale_sale_date (models/staging/src_prohandel.yml)
  Binder Error: Catalog "MERCURIOS_DATA" does not exist!.
[0m13:04:59.382492 [error] [Thread-2 (]: 9 of 17 ERROR source_not_null_prohandel_sale_price ............................. [[31mERROR[0m in 0.04s]
[0m13:04:59.382740 [error] [Thread-3 (]: 12 of 17 ERROR source_not_null_prohandel_sale_sale_id .......................... [[31mERROR[0m in 0.04s]
[0m13:04:59.382952 [info ] [Thread-1 (]: 13 of 17 START test source_relationships_prohandel_inventory_article_id__article_id__source_prohandel_article_  [RUN]
[0m13:04:59.383169 [debug] [Thread-4 (]: Began running node test.mercurios.source_relationships_prohandel_sale_article_id__article_id__source_prohandel_article_.88a3868b27
[0m13:04:59.383411 [debug] [Thread-7 (]: Marking all children of 'test.mercurios.source_not_null_prohandel_sale_quantity.e6b3fcca5f' to be skipped because of status 'error'.  Reason: Runtime Error in test source_not_null_prohandel_sale_quantity (models/staging/src_prohandel.yml)
  Binder Error: Catalog "MERCURIOS_DATA" does not exist!.
[0m13:04:59.383749 [debug] [Thread-2 (]: Finished running node test.mercurios.source_not_null_prohandel_sale_price.3f2611cfb8
[0m13:04:59.384072 [debug] [Thread-3 (]: Finished running node test.mercurios.source_not_null_prohandel_sale_sale_id.d7df7f53a6
[0m13:04:59.384307 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.mercurios.source_not_null_prohandel_sale_sale_date.fe13d0a52e, now test.mercurios.source_relationships_prohandel_inventory_article_id__article_id__source_prohandel_article_.e4c4fdb4dc)
[0m13:04:59.384500 [info ] [Thread-4 (]: 14 of 17 START test source_relationships_prohandel_sale_article_id__article_id__source_prohandel_article_  [RUN]
[0m13:04:59.384800 [debug] [Thread-2 (]: Began running node test.mercurios.source_unique_prohandel_article_article_id.c50d1ebb23
[0m13:04:59.385075 [debug] [Thread-7 (]: Marking all children of 'test.mercurios.source_not_null_prohandel_sale_price.3f2611cfb8' to be skipped because of status 'error'.  Reason: Runtime Error in test source_not_null_prohandel_sale_price (models/staging/src_prohandel.yml)
  Binder Error: Catalog "MERCURIOS_DATA" does not exist!.
[0m13:04:59.385298 [debug] [Thread-3 (]: Began running node test.mercurios.source_unique_prohandel_inventory_inventory_id.fbb9d1ce4d
[0m13:04:59.385540 [debug] [Thread-1 (]: Began compiling node test.mercurios.source_relationships_prohandel_inventory_article_id__article_id__source_prohandel_article_.e4c4fdb4dc
[0m13:04:59.385846 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly test.mercurios.source_not_null_prohandel_sale_quantity.e6b3fcca5f, now test.mercurios.source_relationships_prohandel_sale_article_id__article_id__source_prohandel_article_.88a3868b27)
[0m13:04:59.386203 [info ] [Thread-2 (]: 15 of 17 START test source_unique_prohandel_article_article_id ................. [RUN]
[0m13:04:59.386500 [debug] [Thread-7 (]: Marking all children of 'test.mercurios.source_not_null_prohandel_sale_sale_id.d7df7f53a6' to be skipped because of status 'error'.  Reason: Runtime Error in test source_not_null_prohandel_sale_sale_id (models/staging/src_prohandel.yml)
  Binder Error: Catalog "MERCURIOS_DATA" does not exist!.
[0m13:04:59.386699 [info ] [Thread-3 (]: 16 of 17 START test source_unique_prohandel_inventory_inventory_id ............. [RUN]
[0m13:04:59.391037 [debug] [Thread-1 (]: Writing injected SQL for node "test.mercurios.source_relationships_prohandel_inventory_article_id__article_id__source_prohandel_article_.e4c4fdb4dc"
[0m13:04:59.391315 [debug] [Thread-4 (]: Began compiling node test.mercurios.source_relationships_prohandel_sale_article_id__article_id__source_prohandel_article_.88a3868b27
[0m13:04:59.391543 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly test.mercurios.source_not_null_prohandel_sale_price.3f2611cfb8, now test.mercurios.source_unique_prohandel_article_article_id.c50d1ebb23)
[0m13:04:59.391790 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly test.mercurios.source_not_null_prohandel_sale_sale_id.d7df7f53a6, now test.mercurios.source_unique_prohandel_inventory_inventory_id.fbb9d1ce4d)
[0m13:04:59.394410 [debug] [Thread-4 (]: Writing injected SQL for node "test.mercurios.source_relationships_prohandel_sale_article_id__article_id__source_prohandel_article_.88a3868b27"
[0m13:04:59.394631 [debug] [Thread-2 (]: Began compiling node test.mercurios.source_unique_prohandel_article_article_id.c50d1ebb23
[0m13:04:59.394955 [debug] [Thread-3 (]: Began compiling node test.mercurios.source_unique_prohandel_inventory_inventory_id.fbb9d1ce4d
[0m13:04:59.395198 [debug] [Thread-1 (]: Began executing node test.mercurios.source_relationships_prohandel_inventory_article_id__article_id__source_prohandel_article_.e4c4fdb4dc
[0m13:04:59.399022 [debug] [Thread-2 (]: Writing injected SQL for node "test.mercurios.source_unique_prohandel_article_article_id.c50d1ebb23"
[0m13:04:59.401120 [debug] [Thread-3 (]: Writing injected SQL for node "test.mercurios.source_unique_prohandel_inventory_inventory_id.fbb9d1ce4d"
[0m13:04:59.402809 [debug] [Thread-1 (]: Writing runtime sql for node "test.mercurios.source_relationships_prohandel_inventory_article_id__article_id__source_prohandel_article_.e4c4fdb4dc"
[0m13:04:59.403067 [debug] [Thread-4 (]: Began executing node test.mercurios.source_relationships_prohandel_sale_article_id__article_id__source_prohandel_article_.88a3868b27
[0m13:04:59.406015 [debug] [Thread-4 (]: Writing runtime sql for node "test.mercurios.source_relationships_prohandel_sale_article_id__article_id__source_prohandel_article_.88a3868b27"
[0m13:04:59.406293 [debug] [Thread-3 (]: Began executing node test.mercurios.source_unique_prohandel_inventory_inventory_id.fbb9d1ce4d
[0m13:04:59.406478 [debug] [Thread-2 (]: Began executing node test.mercurios.source_unique_prohandel_article_article_id.c50d1ebb23
[0m13:04:59.406769 [debug] [Thread-1 (]: Using duckdb connection "test.mercurios.source_relationships_prohandel_inventory_article_id__article_id__source_prohandel_article_.e4c4fdb4dc"
[0m13:04:59.408084 [debug] [Thread-3 (]: Writing runtime sql for node "test.mercurios.source_unique_prohandel_inventory_inventory_id.fbb9d1ce4d"
[0m13:04:59.409341 [debug] [Thread-2 (]: Writing runtime sql for node "test.mercurios.source_unique_prohandel_article_article_id.c50d1ebb23"
[0m13:04:59.409563 [debug] [Thread-1 (]: On test.mercurios.source_relationships_prohandel_inventory_article_id__article_id__source_prohandel_article_.e4c4fdb4dc: BEGIN
[0m13:04:59.409788 [debug] [Thread-4 (]: Using duckdb connection "test.mercurios.source_relationships_prohandel_sale_article_id__article_id__source_prohandel_article_.88a3868b27"
[0m13:04:59.410064 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:04:59.410300 [debug] [Thread-4 (]: On test.mercurios.source_relationships_prohandel_sale_article_id__article_id__source_prohandel_article_.88a3868b27: BEGIN
[0m13:04:59.410654 [debug] [Thread-2 (]: Using duckdb connection "test.mercurios.source_unique_prohandel_article_article_id.c50d1ebb23"
[0m13:04:59.410847 [debug] [Thread-3 (]: Using duckdb connection "test.mercurios.source_unique_prohandel_inventory_inventory_id.fbb9d1ce4d"
[0m13:04:59.411020 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m13:04:59.411236 [debug] [Thread-2 (]: On test.mercurios.source_unique_prohandel_article_article_id.c50d1ebb23: BEGIN
[0m13:04:59.411452 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m13:04:59.411661 [debug] [Thread-3 (]: On test.mercurios.source_unique_prohandel_inventory_inventory_id.fbb9d1ce4d: BEGIN
[0m13:04:59.412017 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m13:04:59.412269 [debug] [Thread-4 (]: SQL status: OK in 0.001 seconds
[0m13:04:59.412465 [debug] [Thread-1 (]: Using duckdb connection "test.mercurios.source_relationships_prohandel_inventory_article_id__article_id__source_prohandel_article_.e4c4fdb4dc"
[0m13:04:59.412660 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m13:04:59.412943 [debug] [Thread-4 (]: Using duckdb connection "test.mercurios.source_relationships_prohandel_sale_article_id__article_id__source_prohandel_article_.88a3868b27"
[0m13:04:59.413168 [debug] [Thread-1 (]: On test.mercurios.source_relationships_prohandel_inventory_article_id__article_id__source_prohandel_article_.e4c4fdb4dc: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "node_id": "test.mercurios.source_relationships_prohandel_inventory_article_id__article_id__source_prohandel_article_.e4c4fdb4dc"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select article_id as from_field
    from "MERCURIOS_DATA"."RAW"."inventory"
    where article_id is not null
),

parent as (
    select article_id as to_field
    from "MERCURIOS_DATA"."RAW"."article"
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m13:04:59.413354 [debug] [Thread-2 (]: SQL status: OK in 0.001 seconds
[0m13:04:59.413621 [debug] [Thread-4 (]: On test.mercurios.source_relationships_prohandel_sale_article_id__article_id__source_prohandel_article_.88a3868b27: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "node_id": "test.mercurios.source_relationships_prohandel_sale_article_id__article_id__source_prohandel_article_.88a3868b27"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select article_id as from_field
    from "MERCURIOS_DATA"."RAW"."sale"
    where article_id is not null
),

parent as (
    select article_id as to_field
    from "MERCURIOS_DATA"."RAW"."article"
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m13:04:59.413829 [debug] [Thread-3 (]: SQL status: OK in 0.001 seconds
[0m13:04:59.414098 [debug] [Thread-2 (]: Using duckdb connection "test.mercurios.source_unique_prohandel_article_article_id.c50d1ebb23"
[0m13:04:59.414383 [debug] [Thread-3 (]: Using duckdb connection "test.mercurios.source_unique_prohandel_inventory_inventory_id.fbb9d1ce4d"
[0m13:04:59.414654 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "node_id": "test.mercurios.source_relationships_prohandel_inventory_article_id__article_id__source_prohandel_article_.e4c4fdb4dc"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select article_id as from_field
    from "MERCURIOS_DATA"."RAW"."inventory"
    where article_id is not null
),

parent as (
    select article_id as to_field
    from "MERCURIOS_DATA"."RAW"."article"
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m13:04:59.414927 [debug] [Thread-4 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "node_id": "test.mercurios.source_relationships_prohandel_sale_article_id__article_id__source_prohandel_article_.88a3868b27"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select article_id as from_field
    from "MERCURIOS_DATA"."RAW"."sale"
    where article_id is not null
),

parent as (
    select article_id as to_field
    from "MERCURIOS_DATA"."RAW"."article"
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
[0m13:04:59.415152 [debug] [Thread-2 (]: On test.mercurios.source_unique_prohandel_article_article_id.c50d1ebb23: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "node_id": "test.mercurios.source_unique_prohandel_article_article_id.c50d1ebb23"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    article_id as unique_field,
    count(*) as n_records

from "MERCURIOS_DATA"."RAW"."article"
where article_id is not null
group by article_id
having count(*) > 1



      
    ) dbt_internal_test
[0m13:04:59.415381 [debug] [Thread-3 (]: On test.mercurios.source_unique_prohandel_inventory_inventory_id.fbb9d1ce4d: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "node_id": "test.mercurios.source_unique_prohandel_inventory_inventory_id.fbb9d1ce4d"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    inventory_id as unique_field,
    count(*) as n_records

from "MERCURIOS_DATA"."RAW"."inventory"
where inventory_id is not null
group by inventory_id
having count(*) > 1



      
    ) dbt_internal_test
[0m13:04:59.415605 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m13:04:59.415791 [debug] [Thread-4 (]: DuckDB adapter: Rolling back transaction.
[0m13:04:59.416186 [debug] [Thread-2 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "node_id": "test.mercurios.source_unique_prohandel_article_article_id.c50d1ebb23"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    article_id as unique_field,
    count(*) as n_records

from "MERCURIOS_DATA"."RAW"."article"
where article_id is not null
group by article_id
having count(*) > 1



      
    ) dbt_internal_test
[0m13:04:59.416445 [debug] [Thread-3 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "node_id": "test.mercurios.source_unique_prohandel_inventory_inventory_id.fbb9d1ce4d"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    inventory_id as unique_field,
    count(*) as n_records

from "MERCURIOS_DATA"."RAW"."inventory"
where inventory_id is not null
group by inventory_id
having count(*) > 1



      
    ) dbt_internal_test
[0m13:04:59.416736 [debug] [Thread-1 (]: On test.mercurios.source_relationships_prohandel_inventory_article_id__article_id__source_prohandel_article_.e4c4fdb4dc: ROLLBACK
[0m13:04:59.416994 [debug] [Thread-4 (]: On test.mercurios.source_relationships_prohandel_sale_article_id__article_id__source_prohandel_article_.88a3868b27: ROLLBACK
[0m13:04:59.417175 [debug] [Thread-2 (]: DuckDB adapter: Rolling back transaction.
[0m13:04:59.417354 [debug] [Thread-3 (]: DuckDB adapter: Rolling back transaction.
[0m13:04:59.418845 [debug] [Thread-2 (]: On test.mercurios.source_unique_prohandel_article_article_id.c50d1ebb23: ROLLBACK
[0m13:04:59.419437 [debug] [Thread-3 (]: On test.mercurios.source_unique_prohandel_inventory_inventory_id.fbb9d1ce4d: ROLLBACK
[0m13:04:59.421108 [debug] [Thread-1 (]: Failed to rollback 'test.mercurios.source_relationships_prohandel_inventory_article_id__article_id__source_prohandel_article_.e4c4fdb4dc'
[0m13:04:59.421858 [debug] [Thread-4 (]: Failed to rollback 'test.mercurios.source_relationships_prohandel_sale_article_id__article_id__source_prohandel_article_.88a3868b27'
[0m13:04:59.422566 [debug] [Thread-2 (]: Failed to rollback 'test.mercurios.source_unique_prohandel_article_article_id.c50d1ebb23'
[0m13:04:59.423306 [debug] [Thread-1 (]: On test.mercurios.source_relationships_prohandel_inventory_article_id__article_id__source_prohandel_article_.e4c4fdb4dc: Close
[0m13:04:59.423552 [debug] [Thread-4 (]: On test.mercurios.source_relationships_prohandel_sale_article_id__article_id__source_prohandel_article_.88a3868b27: Close
[0m13:04:59.423744 [debug] [Thread-2 (]: On test.mercurios.source_unique_prohandel_article_article_id.c50d1ebb23: Close
[0m13:04:59.424510 [debug] [Thread-3 (]: Failed to rollback 'test.mercurios.source_unique_prohandel_inventory_inventory_id.fbb9d1ce4d'
[0m13:04:59.426632 [debug] [Thread-4 (]: Runtime Error in test source_relationships_prohandel_sale_article_id__article_id__source_prohandel_article_ (models/staging/src_prohandel.yml)
  Binder Error: Catalog "MERCURIOS_DATA" does not exist!
[0m13:04:59.427664 [debug] [Thread-1 (]: Runtime Error in test source_relationships_prohandel_inventory_article_id__article_id__source_prohandel_article_ (models/staging/src_prohandel.yml)
  Binder Error: Catalog "MERCURIOS_DATA" does not exist!
[0m13:04:59.428552 [debug] [Thread-3 (]: On test.mercurios.source_unique_prohandel_inventory_inventory_id.fbb9d1ce4d: Close
[0m13:04:59.429387 [debug] [Thread-2 (]: Runtime Error in test source_unique_prohandel_article_article_id (models/staging/src_prohandel.yml)
  Binder Error: Catalog "MERCURIOS_DATA" does not exist!
[0m13:04:59.429661 [error] [Thread-4 (]: 14 of 17 ERROR source_relationships_prohandel_sale_article_id__article_id__source_prohandel_article_  [[31mERROR[0m in 0.04s]
[0m13:04:59.429923 [error] [Thread-1 (]: 13 of 17 ERROR source_relationships_prohandel_inventory_article_id__article_id__source_prohandel_article_  [[31mERROR[0m in 0.05s]
[0m13:04:59.431306 [debug] [Thread-3 (]: Runtime Error in test source_unique_prohandel_inventory_inventory_id (models/staging/src_prohandel.yml)
  Binder Error: Catalog "MERCURIOS_DATA" does not exist!
[0m13:04:59.431558 [error] [Thread-2 (]: 15 of 17 ERROR source_unique_prohandel_article_article_id ...................... [[31mERROR[0m in 0.04s]
[0m13:04:59.431877 [debug] [Thread-4 (]: Finished running node test.mercurios.source_relationships_prohandel_sale_article_id__article_id__source_prohandel_article_.88a3868b27
[0m13:04:59.432134 [debug] [Thread-1 (]: Finished running node test.mercurios.source_relationships_prohandel_inventory_article_id__article_id__source_prohandel_article_.e4c4fdb4dc
[0m13:04:59.432358 [error] [Thread-3 (]: 16 of 17 ERROR source_unique_prohandel_inventory_inventory_id .................. [[31mERROR[0m in 0.04s]
[0m13:04:59.432650 [debug] [Thread-2 (]: Finished running node test.mercurios.source_unique_prohandel_article_article_id.c50d1ebb23
[0m13:04:59.432877 [debug] [Thread-4 (]: Began running node test.mercurios.source_unique_prohandel_sale_sale_id.07716b2762
[0m13:04:59.433129 [debug] [Thread-7 (]: Marking all children of 'test.mercurios.source_relationships_prohandel_sale_article_id__article_id__source_prohandel_article_.88a3868b27' to be skipped because of status 'error'.  Reason: Runtime Error in test source_relationships_prohandel_sale_article_id__article_id__source_prohandel_article_ (models/staging/src_prohandel.yml)
  Binder Error: Catalog "MERCURIOS_DATA" does not exist!.
[0m13:04:59.433434 [debug] [Thread-3 (]: Finished running node test.mercurios.source_unique_prohandel_inventory_inventory_id.fbb9d1ce4d
[0m13:04:59.433707 [info ] [Thread-4 (]: 17 of 17 START test source_unique_prohandel_sale_sale_id ....................... [RUN]
[0m13:04:59.434086 [debug] [Thread-7 (]: Marking all children of 'test.mercurios.source_relationships_prohandel_inventory_article_id__article_id__source_prohandel_article_.e4c4fdb4dc' to be skipped because of status 'error'.  Reason: Runtime Error in test source_relationships_prohandel_inventory_article_id__article_id__source_prohandel_article_ (models/staging/src_prohandel.yml)
  Binder Error: Catalog "MERCURIOS_DATA" does not exist!.
[0m13:04:59.434542 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly test.mercurios.source_relationships_prohandel_sale_article_id__article_id__source_prohandel_article_.88a3868b27, now test.mercurios.source_unique_prohandel_sale_sale_id.07716b2762)
[0m13:04:59.434960 [debug] [Thread-7 (]: Marking all children of 'test.mercurios.source_unique_prohandel_article_article_id.c50d1ebb23' to be skipped because of status 'error'.  Reason: Runtime Error in test source_unique_prohandel_article_article_id (models/staging/src_prohandel.yml)
  Binder Error: Catalog "MERCURIOS_DATA" does not exist!.
[0m13:04:59.435159 [debug] [Thread-4 (]: Began compiling node test.mercurios.source_unique_prohandel_sale_sale_id.07716b2762
[0m13:04:59.435535 [debug] [Thread-7 (]: Marking all children of 'test.mercurios.source_unique_prohandel_inventory_inventory_id.fbb9d1ce4d' to be skipped because of status 'error'.  Reason: Runtime Error in test source_unique_prohandel_inventory_inventory_id (models/staging/src_prohandel.yml)
  Binder Error: Catalog "MERCURIOS_DATA" does not exist!.
[0m13:04:59.438286 [debug] [Thread-4 (]: Writing injected SQL for node "test.mercurios.source_unique_prohandel_sale_sale_id.07716b2762"
[0m13:04:59.438993 [debug] [Thread-4 (]: Began executing node test.mercurios.source_unique_prohandel_sale_sale_id.07716b2762
[0m13:04:59.440719 [debug] [Thread-4 (]: Writing runtime sql for node "test.mercurios.source_unique_prohandel_sale_sale_id.07716b2762"
[0m13:04:59.441279 [debug] [Thread-4 (]: Using duckdb connection "test.mercurios.source_unique_prohandel_sale_sale_id.07716b2762"
[0m13:04:59.441760 [debug] [Thread-4 (]: On test.mercurios.source_unique_prohandel_sale_sale_id.07716b2762: BEGIN
[0m13:04:59.442059 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m13:04:59.442671 [debug] [Thread-4 (]: SQL status: OK in 0.001 seconds
[0m13:04:59.442904 [debug] [Thread-4 (]: Using duckdb connection "test.mercurios.source_unique_prohandel_sale_sale_id.07716b2762"
[0m13:04:59.443097 [debug] [Thread-4 (]: On test.mercurios.source_unique_prohandel_sale_sale_id.07716b2762: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "node_id": "test.mercurios.source_unique_prohandel_sale_sale_id.07716b2762"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    sale_id as unique_field,
    count(*) as n_records

from "MERCURIOS_DATA"."RAW"."sale"
where sale_id is not null
group by sale_id
having count(*) > 1



      
    ) dbt_internal_test
[0m13:04:59.443639 [debug] [Thread-4 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "node_id": "test.mercurios.source_unique_prohandel_sale_sale_id.07716b2762"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    sale_id as unique_field,
    count(*) as n_records

from "MERCURIOS_DATA"."RAW"."sale"
where sale_id is not null
group by sale_id
having count(*) > 1



      
    ) dbt_internal_test
[0m13:04:59.443903 [debug] [Thread-4 (]: DuckDB adapter: Rolling back transaction.
[0m13:04:59.444223 [debug] [Thread-4 (]: On test.mercurios.source_unique_prohandel_sale_sale_id.07716b2762: ROLLBACK
[0m13:04:59.445639 [debug] [Thread-4 (]: Failed to rollback 'test.mercurios.source_unique_prohandel_sale_sale_id.07716b2762'
[0m13:04:59.445828 [debug] [Thread-4 (]: On test.mercurios.source_unique_prohandel_sale_sale_id.07716b2762: Close
[0m13:04:59.447152 [debug] [Thread-4 (]: Runtime Error in test source_unique_prohandel_sale_sale_id (models/staging/src_prohandel.yml)
  Binder Error: Catalog "MERCURIOS_DATA" does not exist!
[0m13:04:59.447393 [error] [Thread-4 (]: 17 of 17 ERROR source_unique_prohandel_sale_sale_id ............................ [[31mERROR[0m in 0.01s]
[0m13:04:59.447648 [debug] [Thread-4 (]: Finished running node test.mercurios.source_unique_prohandel_sale_sale_id.07716b2762
[0m13:04:59.447902 [debug] [Thread-7 (]: Marking all children of 'test.mercurios.source_unique_prohandel_sale_sale_id.07716b2762' to be skipped because of status 'error'.  Reason: Runtime Error in test source_unique_prohandel_sale_sale_id (models/staging/src_prohandel.yml)
  Binder Error: Catalog "MERCURIOS_DATA" does not exist!.
[0m13:04:59.448778 [debug] [MainThread]: Using duckdb connection "master"
[0m13:04:59.448974 [debug] [MainThread]: On master: BEGIN
[0m13:04:59.449165 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m13:04:59.449481 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m13:04:59.449636 [debug] [MainThread]: On master: COMMIT
[0m13:04:59.449780 [debug] [MainThread]: Using duckdb connection "master"
[0m13:04:59.449918 [debug] [MainThread]: On master: COMMIT
[0m13:04:59.450212 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m13:04:59.450514 [debug] [MainThread]: On master: Close
[0m13:04:59.450765 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:04:59.450911 [debug] [MainThread]: Connection 'test.mercurios.source_relationships_prohandel_inventory_article_id__article_id__source_prohandel_article_.e4c4fdb4dc' was properly closed.
[0m13:04:59.451050 [debug] [MainThread]: Connection 'test.mercurios.source_unique_prohandel_article_article_id.c50d1ebb23' was properly closed.
[0m13:04:59.451181 [debug] [MainThread]: Connection 'test.mercurios.source_unique_prohandel_inventory_inventory_id.fbb9d1ce4d' was properly closed.
[0m13:04:59.451308 [debug] [MainThread]: Connection 'test.mercurios.source_unique_prohandel_sale_sale_id.07716b2762' was properly closed.
[0m13:04:59.451500 [info ] [MainThread]: 
[0m13:04:59.451674 [info ] [MainThread]: Finished running 17 data tests in 0 hours 0 minutes and 0.38 seconds (0.38s).
[0m13:04:59.453156 [debug] [MainThread]: Command end result
[0m13:04:59.538842 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/target/manifest.json
[0m13:04:59.543110 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/target/semantic_manifest.json
[0m13:04:59.547926 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/target/run_results.json
[0m13:04:59.548174 [info ] [MainThread]: 
[0m13:04:59.548405 [info ] [MainThread]: [31mCompleted with 17 errors, 0 partial successes, and 0 warnings:[0m
[0m13:04:59.548584 [info ] [MainThread]: 
[0m13:04:59.548781 [error] [MainThread]:   Runtime Error in test source_not_null_prohandel_article_article_number (models/staging/src_prohandel.yml)
  Binder Error: Catalog "MERCURIOS_DATA" does not exist!
[0m13:04:59.548938 [info ] [MainThread]: 
[0m13:04:59.549111 [error] [MainThread]:   Runtime Error in test source_not_null_prohandel_inventory_inventory_id (models/staging/src_prohandel.yml)
  Binder Error: Catalog "MERCURIOS_DATA" does not exist!
[0m13:04:59.549256 [info ] [MainThread]: 
[0m13:04:59.549425 [error] [MainThread]:   Runtime Error in test source_not_null_prohandel_inventory_article_id (models/staging/src_prohandel.yml)
  Binder Error: Catalog "MERCURIOS_DATA" does not exist!
[0m13:04:59.549573 [info ] [MainThread]: 
[0m13:04:59.549738 [error] [MainThread]:   Runtime Error in test source_not_null_prohandel_article_article_id (models/staging/src_prohandel.yml)
  Binder Error: Catalog "MERCURIOS_DATA" does not exist!
[0m13:04:59.549882 [info ] [MainThread]: 
[0m13:04:59.550045 [error] [MainThread]:   Runtime Error in test source_not_null_prohandel_inventory_quantity (models/staging/src_prohandel.yml)
  Binder Error: Catalog "MERCURIOS_DATA" does not exist!
[0m13:04:59.551210 [info ] [MainThread]: 
[0m13:04:59.551461 [error] [MainThread]:   Runtime Error in test source_not_null_prohandel_inventory_warehouse_id (models/staging/src_prohandel.yml)
  Binder Error: Catalog "MERCURIOS_DATA" does not exist!
[0m13:04:59.551623 [info ] [MainThread]: 
[0m13:04:59.551800 [error] [MainThread]:   Runtime Error in test source_not_null_prohandel_sale_order_id (models/staging/src_prohandel.yml)
  Binder Error: Catalog "MERCURIOS_DATA" does not exist!
[0m13:04:59.551954 [info ] [MainThread]: 
[0m13:04:59.552124 [error] [MainThread]:   Runtime Error in test source_not_null_prohandel_sale_article_id (models/staging/src_prohandel.yml)
  Binder Error: Catalog "MERCURIOS_DATA" does not exist!
[0m13:04:59.552268 [info ] [MainThread]: 
[0m13:04:59.552434 [error] [MainThread]:   Runtime Error in test source_not_null_prohandel_sale_sale_date (models/staging/src_prohandel.yml)
  Binder Error: Catalog "MERCURIOS_DATA" does not exist!
[0m13:04:59.552577 [info ] [MainThread]: 
[0m13:04:59.552739 [error] [MainThread]:   Runtime Error in test source_not_null_prohandel_sale_quantity (models/staging/src_prohandel.yml)
  Binder Error: Catalog "MERCURIOS_DATA" does not exist!
[0m13:04:59.552890 [info ] [MainThread]: 
[0m13:04:59.553055 [error] [MainThread]:   Runtime Error in test source_not_null_prohandel_sale_price (models/staging/src_prohandel.yml)
  Binder Error: Catalog "MERCURIOS_DATA" does not exist!
[0m13:04:59.553198 [info ] [MainThread]: 
[0m13:04:59.553363 [error] [MainThread]:   Runtime Error in test source_not_null_prohandel_sale_sale_id (models/staging/src_prohandel.yml)
  Binder Error: Catalog "MERCURIOS_DATA" does not exist!
[0m13:04:59.553709 [info ] [MainThread]: 
[0m13:04:59.554165 [error] [MainThread]:   Runtime Error in test source_relationships_prohandel_sale_article_id__article_id__source_prohandel_article_ (models/staging/src_prohandel.yml)
  Binder Error: Catalog "MERCURIOS_DATA" does not exist!
[0m13:04:59.554366 [info ] [MainThread]: 
[0m13:04:59.554558 [error] [MainThread]:   Runtime Error in test source_relationships_prohandel_inventory_article_id__article_id__source_prohandel_article_ (models/staging/src_prohandel.yml)
  Binder Error: Catalog "MERCURIOS_DATA" does not exist!
[0m13:04:59.554712 [info ] [MainThread]: 
[0m13:04:59.554891 [error] [MainThread]:   Runtime Error in test source_unique_prohandel_article_article_id (models/staging/src_prohandel.yml)
  Binder Error: Catalog "MERCURIOS_DATA" does not exist!
[0m13:04:59.555044 [info ] [MainThread]: 
[0m13:04:59.555211 [error] [MainThread]:   Runtime Error in test source_unique_prohandel_inventory_inventory_id (models/staging/src_prohandel.yml)
  Binder Error: Catalog "MERCURIOS_DATA" does not exist!
[0m13:04:59.557101 [info ] [MainThread]: 
[0m13:04:59.557366 [error] [MainThread]:   Runtime Error in test source_unique_prohandel_sale_sale_id (models/staging/src_prohandel.yml)
  Binder Error: Catalog "MERCURIOS_DATA" does not exist!
[0m13:04:59.557728 [info ] [MainThread]: 
[0m13:04:59.557961 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=17 SKIP=0 TOTAL=17
[0m13:04:59.560924 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": false, "command_wall_clock_time": 1.0767066, "process_in_blocks": "0", "process_kernel_time": 0.29074, "process_mem_max_rss": "146407424", "process_out_blocks": "0", "process_user_time": 1.394244}
[0m13:04:59.561168 [debug] [MainThread]: Command `dbt test` failed at 13:04:59.561127 after 1.08 seconds
[0m13:04:59.561408 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113a47490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113a45f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1139e4790>]}
[0m13:04:59.561723 [debug] [MainThread]: Flushing usage events
[0m13:05:00.145701 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:05:01.138054 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1133e5210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11346a9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11346b150>]}


============================== 13:05:01.140474 | fcfa8915-7e49-4bd9-b91e-7e265bc0fda2 ==============================
[0m13:05:01.140474 [info ] [MainThread]: Running with dbt=1.9.2
[0m13:05:01.140812 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/logs', 'debug': 'False', 'profiles_dir': '/Users/juliusrechenbach/API ProHandelTest/dbt_mercurios', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt docs generate', 'send_anonymous_usage_stats': 'True'}
[0m13:05:01.274985 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'fcfa8915-7e49-4bd9-b91e-7e265bc0fda2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113582610>]}
[0m13:05:01.313408 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'fcfa8915-7e49-4bd9-b91e-7e265bc0fda2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1049e25d0>]}
[0m13:05:01.317717 [info ] [MainThread]: Registered adapter: duckdb=1.9.2
[0m13:05:01.379247 [debug] [MainThread]: checksum: 12b12750b70de726cfd89136b8e24afc3f3e77597a97bff40ab7e5f9b39d5e18, vars: {}, profile: , target: , version: 1.9.2
[0m13:05:01.473051 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m13:05:01.474170 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m13:05:01.493669 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.mercurios.marts.sales
[0m13:05:01.578432 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'fcfa8915-7e49-4bd9-b91e-7e265bc0fda2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1134f8c10>]}
[0m13:05:01.592527 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'fcfa8915-7e49-4bd9-b91e-7e265bc0fda2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1137585d0>]}
[0m13:05:01.594129 [info ] [MainThread]: Found 9 models, 17 data tests, 3 sources, 540 macros
[0m13:05:01.594856 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'fcfa8915-7e49-4bd9-b91e-7e265bc0fda2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11349b490>]}
[0m13:05:01.597368 [info ] [MainThread]: 
[0m13:05:01.597756 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m13:05:01.597938 [info ] [MainThread]: 
[0m13:05:01.598276 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m13:05:01.602879 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_dbt_mercurios_dev_main_staging'
[0m13:05:01.603424 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_dbt_mercurios_dev_main_intermediate'
[0m13:05:01.604043 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_dbt_mercurios_dev_main_marts_inventory'
[0m13:05:01.635938 [debug] [ThreadPool]: Using duckdb connection "list_dbt_mercurios_dev_main_staging"
[0m13:05:01.636275 [debug] [ThreadPool]: Using duckdb connection "list_dbt_mercurios_dev_main_intermediate"
[0m13:05:01.636548 [debug] [ThreadPool]: Using duckdb connection "list_dbt_mercurios_dev_main_marts_inventory"
[0m13:05:01.636732 [debug] [ThreadPool]: On list_dbt_mercurios_dev_main_staging: BEGIN
[0m13:05:01.636995 [debug] [ThreadPool]: On list_dbt_mercurios_dev_main_intermediate: BEGIN
[0m13:05:01.637220 [debug] [ThreadPool]: On list_dbt_mercurios_dev_main_marts_inventory: BEGIN
[0m13:05:01.637404 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:05:01.637589 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:05:01.637796 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:05:01.645116 [debug] [ThreadPool]: SQL status: OK in 0.007 seconds
[0m13:05:01.645366 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m13:05:01.645622 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m13:05:01.645861 [debug] [ThreadPool]: Using duckdb connection "list_dbt_mercurios_dev_main_intermediate"
[0m13:05:01.646078 [debug] [ThreadPool]: Using duckdb connection "list_dbt_mercurios_dev_main_staging"
[0m13:05:01.646241 [debug] [ThreadPool]: Using duckdb connection "list_dbt_mercurios_dev_main_marts_inventory"
[0m13:05:01.646466 [debug] [ThreadPool]: On list_dbt_mercurios_dev_main_intermediate: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "list_dbt_mercurios_dev_main_intermediate"} */
select
      'dbt_mercurios_dev' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_intermediate'
    and lower(table_catalog) = 'dbt_mercurios_dev'
  
[0m13:05:01.646724 [debug] [ThreadPool]: On list_dbt_mercurios_dev_main_staging: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "list_dbt_mercurios_dev_main_staging"} */
select
      'dbt_mercurios_dev' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_staging'
    and lower(table_catalog) = 'dbt_mercurios_dev'
  
[0m13:05:01.646911 [debug] [ThreadPool]: On list_dbt_mercurios_dev_main_marts_inventory: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "list_dbt_mercurios_dev_main_marts_inventory"} */
select
      'dbt_mercurios_dev' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main_marts_inventory'
    and lower(table_catalog) = 'dbt_mercurios_dev'
  
[0m13:05:01.657507 [debug] [ThreadPool]: SQL status: OK in 0.010 seconds
[0m13:05:01.657825 [debug] [ThreadPool]: SQL status: OK in 0.011 seconds
[0m13:05:01.658029 [debug] [ThreadPool]: SQL status: OK in 0.011 seconds
[0m13:05:01.658874 [debug] [ThreadPool]: On list_dbt_mercurios_dev_main_marts_inventory: ROLLBACK
[0m13:05:01.659567 [debug] [ThreadPool]: On list_dbt_mercurios_dev_main_staging: ROLLBACK
[0m13:05:01.660330 [debug] [ThreadPool]: On list_dbt_mercurios_dev_main_intermediate: ROLLBACK
[0m13:05:01.661122 [debug] [ThreadPool]: Failed to rollback 'list_dbt_mercurios_dev_main_marts_inventory'
[0m13:05:01.661447 [debug] [ThreadPool]: Failed to rollback 'list_dbt_mercurios_dev_main_staging'
[0m13:05:01.661630 [debug] [ThreadPool]: On list_dbt_mercurios_dev_main_marts_inventory: Close
[0m13:05:01.661958 [debug] [ThreadPool]: Failed to rollback 'list_dbt_mercurios_dev_main_intermediate'
[0m13:05:01.662183 [debug] [ThreadPool]: On list_dbt_mercurios_dev_main_staging: Close
[0m13:05:01.662840 [debug] [ThreadPool]: On list_dbt_mercurios_dev_main_intermediate: Close
[0m13:05:01.663713 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'fcfa8915-7e49-4bd9-b91e-7e265bc0fda2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113889550>]}
[0m13:05:01.665597 [debug] [Thread-1 (]: Began running node model.mercurios.stg_prohandel__articles
[0m13:05:01.665865 [debug] [Thread-2 (]: Began running node model.mercurios.stg_prohandel__inventory
[0m13:05:01.666100 [debug] [Thread-3 (]: Began running node model.mercurios.stg_prohandel__sales
[0m13:05:01.666263 [debug] [Thread-4 (]: Began running node test.mercurios.source_not_null_prohandel_article_article_id.a3a021f44e
[0m13:05:01.666475 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_dbt_mercurios_dev_main_staging, now model.mercurios.stg_prohandel__articles)
[0m13:05:01.666672 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_dbt_mercurios_dev_main_intermediate, now model.mercurios.stg_prohandel__inventory)
[0m13:05:01.666865 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_dbt_mercurios_dev_main_marts_inventory, now model.mercurios.stg_prohandel__sales)
[0m13:05:01.667126 [debug] [Thread-4 (]: Acquiring new duckdb connection 'test.mercurios.source_not_null_prohandel_article_article_id.a3a021f44e'
[0m13:05:01.667325 [debug] [Thread-1 (]: Began compiling node model.mercurios.stg_prohandel__articles
[0m13:05:01.667501 [debug] [Thread-2 (]: Began compiling node model.mercurios.stg_prohandel__inventory
[0m13:05:01.667665 [debug] [Thread-3 (]: Began compiling node model.mercurios.stg_prohandel__sales
[0m13:05:01.667872 [debug] [Thread-4 (]: Began compiling node test.mercurios.source_not_null_prohandel_article_article_id.a3a021f44e
[0m13:05:01.672381 [debug] [Thread-1 (]: Writing injected SQL for node "model.mercurios.stg_prohandel__articles"
[0m13:05:01.674280 [debug] [Thread-2 (]: Writing injected SQL for node "model.mercurios.stg_prohandel__inventory"
[0m13:05:01.675714 [debug] [Thread-3 (]: Writing injected SQL for node "model.mercurios.stg_prohandel__sales"
[0m13:05:01.681938 [debug] [Thread-4 (]: Writing injected SQL for node "test.mercurios.source_not_null_prohandel_article_article_id.a3a021f44e"
[0m13:05:01.682630 [debug] [Thread-2 (]: Began executing node model.mercurios.stg_prohandel__inventory
[0m13:05:01.683041 [debug] [Thread-2 (]: Finished running node model.mercurios.stg_prohandel__inventory
[0m13:05:01.683254 [debug] [Thread-2 (]: Began running node test.mercurios.source_not_null_prohandel_article_article_number.bc7d7b092e
[0m13:05:01.683499 [debug] [Thread-1 (]: Began executing node model.mercurios.stg_prohandel__articles
[0m13:05:01.683931 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.mercurios.stg_prohandel__inventory, now test.mercurios.source_not_null_prohandel_article_article_number.bc7d7b092e)
[0m13:05:01.684203 [debug] [Thread-3 (]: Began executing node model.mercurios.stg_prohandel__sales
[0m13:05:01.684419 [debug] [Thread-4 (]: Began executing node test.mercurios.source_not_null_prohandel_article_article_id.a3a021f44e
[0m13:05:01.684849 [debug] [Thread-1 (]: Finished running node model.mercurios.stg_prohandel__articles
[0m13:05:01.685078 [debug] [Thread-2 (]: Began compiling node test.mercurios.source_not_null_prohandel_article_article_number.bc7d7b092e
[0m13:05:01.685374 [debug] [Thread-3 (]: Finished running node model.mercurios.stg_prohandel__sales
[0m13:05:01.685733 [debug] [Thread-4 (]: Finished running node test.mercurios.source_not_null_prohandel_article_article_id.a3a021f44e
[0m13:05:01.685990 [debug] [Thread-1 (]: Began running node test.mercurios.source_not_null_prohandel_inventory_article_id.b5efc266f9
[0m13:05:01.688215 [debug] [Thread-2 (]: Writing injected SQL for node "test.mercurios.source_not_null_prohandel_article_article_number.bc7d7b092e"
[0m13:05:01.688606 [debug] [Thread-3 (]: Began running node test.mercurios.source_not_null_prohandel_inventory_inventory_id.8764c20f3f
[0m13:05:01.688963 [debug] [Thread-4 (]: Began running node test.mercurios.source_not_null_prohandel_inventory_quantity.ddfd3d3568
[0m13:05:01.689240 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.mercurios.stg_prohandel__articles, now test.mercurios.source_not_null_prohandel_inventory_article_id.b5efc266f9)
[0m13:05:01.689511 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.mercurios.stg_prohandel__sales, now test.mercurios.source_not_null_prohandel_inventory_inventory_id.8764c20f3f)
[0m13:05:01.689829 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly test.mercurios.source_not_null_prohandel_article_article_id.a3a021f44e, now test.mercurios.source_not_null_prohandel_inventory_quantity.ddfd3d3568)
[0m13:05:01.690071 [debug] [Thread-1 (]: Began compiling node test.mercurios.source_not_null_prohandel_inventory_article_id.b5efc266f9
[0m13:05:01.690287 [debug] [Thread-2 (]: Began executing node test.mercurios.source_not_null_prohandel_article_article_number.bc7d7b092e
[0m13:05:01.690544 [debug] [Thread-3 (]: Began compiling node test.mercurios.source_not_null_prohandel_inventory_inventory_id.8764c20f3f
[0m13:05:01.690772 [debug] [Thread-4 (]: Began compiling node test.mercurios.source_not_null_prohandel_inventory_quantity.ddfd3d3568
[0m13:05:01.728298 [debug] [Thread-1 (]: Writing injected SQL for node "test.mercurios.source_not_null_prohandel_inventory_article_id.b5efc266f9"
[0m13:05:01.728931 [debug] [Thread-2 (]: Finished running node test.mercurios.source_not_null_prohandel_article_article_number.bc7d7b092e
[0m13:05:01.731316 [debug] [Thread-3 (]: Writing injected SQL for node "test.mercurios.source_not_null_prohandel_inventory_inventory_id.8764c20f3f"
[0m13:05:01.733341 [debug] [Thread-4 (]: Writing injected SQL for node "test.mercurios.source_not_null_prohandel_inventory_quantity.ddfd3d3568"
[0m13:05:01.733774 [debug] [Thread-2 (]: Began running node test.mercurios.source_not_null_prohandel_inventory_warehouse_id.6307156ecb
[0m13:05:01.734147 [debug] [Thread-1 (]: Began executing node test.mercurios.source_not_null_prohandel_inventory_article_id.b5efc266f9
[0m13:05:01.734504 [debug] [Thread-3 (]: Began executing node test.mercurios.source_not_null_prohandel_inventory_inventory_id.8764c20f3f
[0m13:05:01.734764 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly test.mercurios.source_not_null_prohandel_article_article_number.bc7d7b092e, now test.mercurios.source_not_null_prohandel_inventory_warehouse_id.6307156ecb)
[0m13:05:01.735251 [debug] [Thread-1 (]: Finished running node test.mercurios.source_not_null_prohandel_inventory_article_id.b5efc266f9
[0m13:05:01.735713 [debug] [Thread-3 (]: Finished running node test.mercurios.source_not_null_prohandel_inventory_inventory_id.8764c20f3f
[0m13:05:01.735987 [debug] [Thread-4 (]: Began executing node test.mercurios.source_not_null_prohandel_inventory_quantity.ddfd3d3568
[0m13:05:01.736249 [debug] [Thread-2 (]: Began compiling node test.mercurios.source_not_null_prohandel_inventory_warehouse_id.6307156ecb
[0m13:05:01.736456 [debug] [Thread-1 (]: Began running node test.mercurios.source_not_null_prohandel_sale_article_id.ed4013e08f
[0m13:05:01.736821 [debug] [Thread-3 (]: Began running node test.mercurios.source_not_null_prohandel_sale_order_id.5242416524
[0m13:05:01.737342 [debug] [Thread-4 (]: Finished running node test.mercurios.source_not_null_prohandel_inventory_quantity.ddfd3d3568
[0m13:05:01.739648 [debug] [Thread-2 (]: Writing injected SQL for node "test.mercurios.source_not_null_prohandel_inventory_warehouse_id.6307156ecb"
[0m13:05:01.740028 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.mercurios.source_not_null_prohandel_inventory_article_id.b5efc266f9, now test.mercurios.source_not_null_prohandel_sale_article_id.ed4013e08f)
[0m13:05:01.740319 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly test.mercurios.source_not_null_prohandel_inventory_inventory_id.8764c20f3f, now test.mercurios.source_not_null_prohandel_sale_order_id.5242416524)
[0m13:05:01.740561 [debug] [Thread-4 (]: Began running node test.mercurios.source_not_null_prohandel_sale_price.3f2611cfb8
[0m13:05:01.740856 [debug] [Thread-1 (]: Began compiling node test.mercurios.source_not_null_prohandel_sale_article_id.ed4013e08f
[0m13:05:01.741077 [debug] [Thread-3 (]: Began compiling node test.mercurios.source_not_null_prohandel_sale_order_id.5242416524
[0m13:05:01.741309 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly test.mercurios.source_not_null_prohandel_inventory_quantity.ddfd3d3568, now test.mercurios.source_not_null_prohandel_sale_price.3f2611cfb8)
[0m13:05:01.741488 [debug] [Thread-2 (]: Began executing node test.mercurios.source_not_null_prohandel_inventory_warehouse_id.6307156ecb
[0m13:05:01.743977 [debug] [Thread-1 (]: Writing injected SQL for node "test.mercurios.source_not_null_prohandel_sale_article_id.ed4013e08f"
[0m13:05:01.746327 [debug] [Thread-3 (]: Writing injected SQL for node "test.mercurios.source_not_null_prohandel_sale_order_id.5242416524"
[0m13:05:01.746627 [debug] [Thread-4 (]: Began compiling node test.mercurios.source_not_null_prohandel_sale_price.3f2611cfb8
[0m13:05:01.747033 [debug] [Thread-2 (]: Finished running node test.mercurios.source_not_null_prohandel_inventory_warehouse_id.6307156ecb
[0m13:05:01.749322 [debug] [Thread-4 (]: Writing injected SQL for node "test.mercurios.source_not_null_prohandel_sale_price.3f2611cfb8"
[0m13:05:01.749639 [debug] [Thread-2 (]: Began running node test.mercurios.source_not_null_prohandel_sale_quantity.e6b3fcca5f
[0m13:05:01.749890 [debug] [Thread-1 (]: Began executing node test.mercurios.source_not_null_prohandel_sale_article_id.ed4013e08f
[0m13:05:01.750074 [debug] [Thread-3 (]: Began executing node test.mercurios.source_not_null_prohandel_sale_order_id.5242416524
[0m13:05:01.750344 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly test.mercurios.source_not_null_prohandel_inventory_warehouse_id.6307156ecb, now test.mercurios.source_not_null_prohandel_sale_quantity.e6b3fcca5f)
[0m13:05:01.750686 [debug] [Thread-1 (]: Finished running node test.mercurios.source_not_null_prohandel_sale_article_id.ed4013e08f
[0m13:05:01.751041 [debug] [Thread-3 (]: Finished running node test.mercurios.source_not_null_prohandel_sale_order_id.5242416524
[0m13:05:01.751211 [debug] [Thread-4 (]: Began executing node test.mercurios.source_not_null_prohandel_sale_price.3f2611cfb8
[0m13:05:01.751390 [debug] [Thread-2 (]: Began compiling node test.mercurios.source_not_null_prohandel_sale_quantity.e6b3fcca5f
[0m13:05:01.751595 [debug] [Thread-1 (]: Began running node test.mercurios.source_not_null_prohandel_sale_sale_date.fe13d0a52e
[0m13:05:01.751824 [debug] [Thread-3 (]: Began running node test.mercurios.source_not_null_prohandel_sale_sale_id.d7df7f53a6
[0m13:05:01.752190 [debug] [Thread-4 (]: Finished running node test.mercurios.source_not_null_prohandel_sale_price.3f2611cfb8
[0m13:05:01.754337 [debug] [Thread-2 (]: Writing injected SQL for node "test.mercurios.source_not_null_prohandel_sale_quantity.e6b3fcca5f"
[0m13:05:01.754592 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.mercurios.source_not_null_prohandel_sale_article_id.ed4013e08f, now test.mercurios.source_not_null_prohandel_sale_sale_date.fe13d0a52e)
[0m13:05:01.754863 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly test.mercurios.source_not_null_prohandel_sale_order_id.5242416524, now test.mercurios.source_not_null_prohandel_sale_sale_id.d7df7f53a6)
[0m13:05:01.755115 [debug] [Thread-4 (]: Began running node test.mercurios.source_relationships_prohandel_inventory_article_id__article_id__source_prohandel_article_.e4c4fdb4dc
[0m13:05:01.755360 [debug] [Thread-1 (]: Began compiling node test.mercurios.source_not_null_prohandel_sale_sale_date.fe13d0a52e
[0m13:05:01.755547 [debug] [Thread-3 (]: Began compiling node test.mercurios.source_not_null_prohandel_sale_sale_id.d7df7f53a6
[0m13:05:01.755753 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly test.mercurios.source_not_null_prohandel_sale_price.3f2611cfb8, now test.mercurios.source_relationships_prohandel_inventory_article_id__article_id__source_prohandel_article_.e4c4fdb4dc)
[0m13:05:01.755929 [debug] [Thread-2 (]: Began executing node test.mercurios.source_not_null_prohandel_sale_quantity.e6b3fcca5f
[0m13:05:01.758268 [debug] [Thread-1 (]: Writing injected SQL for node "test.mercurios.source_not_null_prohandel_sale_sale_date.fe13d0a52e"
[0m13:05:01.760459 [debug] [Thread-3 (]: Writing injected SQL for node "test.mercurios.source_not_null_prohandel_sale_sale_id.d7df7f53a6"
[0m13:05:01.760689 [debug] [Thread-4 (]: Began compiling node test.mercurios.source_relationships_prohandel_inventory_article_id__article_id__source_prohandel_article_.e4c4fdb4dc
[0m13:05:01.761032 [debug] [Thread-2 (]: Finished running node test.mercurios.source_not_null_prohandel_sale_quantity.e6b3fcca5f
[0m13:05:01.766805 [debug] [Thread-4 (]: Writing injected SQL for node "test.mercurios.source_relationships_prohandel_inventory_article_id__article_id__source_prohandel_article_.e4c4fdb4dc"
[0m13:05:01.767251 [debug] [Thread-2 (]: Began running node test.mercurios.source_relationships_prohandel_sale_article_id__article_id__source_prohandel_article_.88a3868b27
[0m13:05:01.767536 [debug] [Thread-3 (]: Began executing node test.mercurios.source_not_null_prohandel_sale_sale_id.d7df7f53a6
[0m13:05:01.767761 [debug] [Thread-1 (]: Began executing node test.mercurios.source_not_null_prohandel_sale_sale_date.fe13d0a52e
[0m13:05:01.768099 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly test.mercurios.source_not_null_prohandel_sale_quantity.e6b3fcca5f, now test.mercurios.source_relationships_prohandel_sale_article_id__article_id__source_prohandel_article_.88a3868b27)
[0m13:05:01.768458 [debug] [Thread-3 (]: Finished running node test.mercurios.source_not_null_prohandel_sale_sale_id.d7df7f53a6
[0m13:05:01.768635 [debug] [Thread-4 (]: Began executing node test.mercurios.source_relationships_prohandel_inventory_article_id__article_id__source_prohandel_article_.e4c4fdb4dc
[0m13:05:01.769018 [debug] [Thread-1 (]: Finished running node test.mercurios.source_not_null_prohandel_sale_sale_date.fe13d0a52e
[0m13:05:01.769239 [debug] [Thread-2 (]: Began compiling node test.mercurios.source_relationships_prohandel_sale_article_id__article_id__source_prohandel_article_.88a3868b27
[0m13:05:01.769466 [debug] [Thread-3 (]: Began running node test.mercurios.source_unique_prohandel_article_article_id.c50d1ebb23
[0m13:05:01.769801 [debug] [Thread-4 (]: Finished running node test.mercurios.source_relationships_prohandel_inventory_article_id__article_id__source_prohandel_article_.e4c4fdb4dc
[0m13:05:01.770022 [debug] [Thread-1 (]: Began running node test.mercurios.source_unique_prohandel_inventory_inventory_id.fbb9d1ce4d
[0m13:05:01.772875 [debug] [Thread-2 (]: Writing injected SQL for node "test.mercurios.source_relationships_prohandel_sale_article_id__article_id__source_prohandel_article_.88a3868b27"
[0m13:05:01.773213 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly test.mercurios.source_not_null_prohandel_sale_sale_id.d7df7f53a6, now test.mercurios.source_unique_prohandel_article_article_id.c50d1ebb23)
[0m13:05:01.773456 [debug] [Thread-4 (]: Began running node test.mercurios.source_unique_prohandel_sale_sale_id.07716b2762
[0m13:05:01.773669 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.mercurios.source_not_null_prohandel_sale_sale_date.fe13d0a52e, now test.mercurios.source_unique_prohandel_inventory_inventory_id.fbb9d1ce4d)
[0m13:05:01.773927 [debug] [Thread-3 (]: Began compiling node test.mercurios.source_unique_prohandel_article_article_id.c50d1ebb23
[0m13:05:01.774233 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly test.mercurios.source_relationships_prohandel_inventory_article_id__article_id__source_prohandel_article_.e4c4fdb4dc, now test.mercurios.source_unique_prohandel_sale_sale_id.07716b2762)
[0m13:05:01.774451 [debug] [Thread-1 (]: Began compiling node test.mercurios.source_unique_prohandel_inventory_inventory_id.fbb9d1ce4d
[0m13:05:01.774647 [debug] [Thread-2 (]: Began executing node test.mercurios.source_relationships_prohandel_sale_article_id__article_id__source_prohandel_article_.88a3868b27
[0m13:05:01.777911 [debug] [Thread-3 (]: Writing injected SQL for node "test.mercurios.source_unique_prohandel_article_article_id.c50d1ebb23"
[0m13:05:01.778194 [debug] [Thread-4 (]: Began compiling node test.mercurios.source_unique_prohandel_sale_sale_id.07716b2762
[0m13:05:01.780525 [debug] [Thread-1 (]: Writing injected SQL for node "test.mercurios.source_unique_prohandel_inventory_inventory_id.fbb9d1ce4d"
[0m13:05:01.781018 [debug] [Thread-2 (]: Finished running node test.mercurios.source_relationships_prohandel_sale_article_id__article_id__source_prohandel_article_.88a3868b27
[0m13:05:01.783363 [debug] [Thread-4 (]: Writing injected SQL for node "test.mercurios.source_unique_prohandel_sale_sale_id.07716b2762"
[0m13:05:01.783725 [debug] [Thread-2 (]: Began running node model.mercurios.demand_forecast
[0m13:05:01.783973 [debug] [Thread-3 (]: Began executing node test.mercurios.source_unique_prohandel_article_article_id.c50d1ebb23
[0m13:05:01.784229 [debug] [Thread-1 (]: Began executing node test.mercurios.source_unique_prohandel_inventory_inventory_id.fbb9d1ce4d
[0m13:05:01.784453 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly test.mercurios.source_relationships_prohandel_sale_article_id__article_id__source_prohandel_article_.88a3868b27, now model.mercurios.demand_forecast)
[0m13:05:01.784834 [debug] [Thread-3 (]: Finished running node test.mercurios.source_unique_prohandel_article_article_id.c50d1ebb23
[0m13:05:01.785007 [debug] [Thread-4 (]: Began executing node test.mercurios.source_unique_prohandel_sale_sale_id.07716b2762
[0m13:05:01.785293 [debug] [Thread-1 (]: Finished running node test.mercurios.source_unique_prohandel_inventory_inventory_id.fbb9d1ce4d
[0m13:05:01.785465 [debug] [Thread-2 (]: Began compiling node model.mercurios.demand_forecast
[0m13:05:01.785654 [debug] [Thread-3 (]: Began running node model.mercurios.int_inventory_with_metrics
[0m13:05:01.785953 [debug] [Thread-4 (]: Finished running node test.mercurios.source_unique_prohandel_sale_sale_id.07716b2762
[0m13:05:01.788658 [debug] [Thread-2 (]: Writing injected SQL for node "model.mercurios.demand_forecast"
[0m13:05:01.788899 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly test.mercurios.source_unique_prohandel_article_article_id.c50d1ebb23, now model.mercurios.int_inventory_with_metrics)
[0m13:05:01.789180 [debug] [Thread-3 (]: Began compiling node model.mercurios.int_inventory_with_metrics
[0m13:05:01.791420 [debug] [Thread-3 (]: Writing injected SQL for node "model.mercurios.int_inventory_with_metrics"
[0m13:05:01.791791 [debug] [Thread-2 (]: Began executing node model.mercurios.demand_forecast
[0m13:05:01.792182 [debug] [Thread-2 (]: Finished running node model.mercurios.demand_forecast
[0m13:05:01.792354 [debug] [Thread-3 (]: Began executing node model.mercurios.int_inventory_with_metrics
[0m13:05:01.792712 [debug] [Thread-3 (]: Finished running node model.mercurios.int_inventory_with_metrics
[0m13:05:01.793109 [debug] [Thread-1 (]: Began running node model.mercurios.inventory_status
[0m13:05:01.793495 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.mercurios.source_unique_prohandel_inventory_inventory_id.fbb9d1ce4d, now model.mercurios.inventory_status)
[0m13:05:01.793682 [debug] [Thread-1 (]: Began compiling node model.mercurios.inventory_status
[0m13:05:01.795662 [debug] [Thread-1 (]: Writing injected SQL for node "model.mercurios.inventory_status"
[0m13:05:01.796051 [debug] [Thread-1 (]: Began executing node model.mercurios.inventory_status
[0m13:05:01.796357 [debug] [Thread-1 (]: Finished running node model.mercurios.inventory_status
[0m13:05:01.796669 [debug] [Thread-2 (]: Began running node model.mercurios.reorder_recommendations
[0m13:05:01.796877 [debug] [Thread-3 (]: Began running node model.mercurios.stock_levels
[0m13:05:01.797109 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.mercurios.demand_forecast, now model.mercurios.reorder_recommendations)
[0m13:05:01.797316 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.mercurios.int_inventory_with_metrics, now model.mercurios.stock_levels)
[0m13:05:01.797496 [debug] [Thread-2 (]: Began compiling node model.mercurios.reorder_recommendations
[0m13:05:01.797702 [debug] [Thread-3 (]: Began compiling node model.mercurios.stock_levels
[0m13:05:01.800026 [debug] [Thread-2 (]: Writing injected SQL for node "model.mercurios.reorder_recommendations"
[0m13:05:01.801803 [debug] [Thread-3 (]: Writing injected SQL for node "model.mercurios.stock_levels"
[0m13:05:01.802666 [debug] [Thread-3 (]: Began executing node model.mercurios.stock_levels
[0m13:05:01.803017 [debug] [Thread-3 (]: Finished running node model.mercurios.stock_levels
[0m13:05:01.803257 [debug] [Thread-2 (]: Began executing node model.mercurios.reorder_recommendations
[0m13:05:01.803605 [debug] [Thread-2 (]: Finished running node model.mercurios.reorder_recommendations
[0m13:05:01.803960 [debug] [Thread-1 (]: Began running node model.mercurios.tenant_inventory_dashboard
[0m13:05:01.804227 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.mercurios.inventory_status, now model.mercurios.tenant_inventory_dashboard)
[0m13:05:01.804446 [debug] [Thread-1 (]: Began compiling node model.mercurios.tenant_inventory_dashboard
[0m13:05:01.808226 [debug] [Thread-1 (]: Writing injected SQL for node "model.mercurios.tenant_inventory_dashboard"
[0m13:05:01.808657 [debug] [Thread-1 (]: Began executing node model.mercurios.tenant_inventory_dashboard
[0m13:05:01.808966 [debug] [Thread-1 (]: Finished running node model.mercurios.tenant_inventory_dashboard
[0m13:05:01.809461 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:05:01.809614 [debug] [MainThread]: Connection 'model.mercurios.tenant_inventory_dashboard' was properly closed.
[0m13:05:01.809748 [debug] [MainThread]: Connection 'model.mercurios.reorder_recommendations' was properly closed.
[0m13:05:01.809876 [debug] [MainThread]: Connection 'model.mercurios.stock_levels' was properly closed.
[0m13:05:01.810003 [debug] [MainThread]: Connection 'test.mercurios.source_unique_prohandel_sale_sale_id.07716b2762' was properly closed.
[0m13:05:01.811408 [debug] [MainThread]: Command end result
[0m13:05:01.858158 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/target/manifest.json
[0m13:05:01.859432 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/target/semantic_manifest.json
[0m13:05:01.863654 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/target/run_results.json
[0m13:05:01.865607 [debug] [MainThread]: Acquiring new duckdb connection 'generate_catalog'
[0m13:05:01.865877 [info ] [MainThread]: Building catalog
[0m13:05:01.870708 [debug] [ThreadPool]: Acquiring new duckdb connection 'dbt_mercurios_dev.information_schema'
[0m13:05:01.871042 [debug] [ThreadPool]: Acquiring new duckdb connection 'MERCURIOS_DATA.information_schema'
[0m13:05:01.875220 [debug] [ThreadPool]: Using duckdb connection "dbt_mercurios_dev.information_schema"
[0m13:05:01.876753 [debug] [ThreadPool]: Using duckdb connection "MERCURIOS_DATA.information_schema"
[0m13:05:01.877110 [debug] [ThreadPool]: On dbt_mercurios_dev.information_schema: BEGIN
[0m13:05:01.877300 [debug] [ThreadPool]: On MERCURIOS_DATA.information_schema: BEGIN
[0m13:05:01.877544 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:05:01.877700 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:05:01.878166 [debug] [ThreadPool]: SQL status: OK in 0.001 seconds
[0m13:05:01.878336 [debug] [ThreadPool]: Using duckdb connection "dbt_mercurios_dev.information_schema"
[0m13:05:01.878676 [debug] [ThreadPool]: On dbt_mercurios_dev.information_schema: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "dbt_mercurios_dev.information_schema"} */
with relations AS (
      select
        t.table_name
        , t.database_name
        , t.schema_name
        , 'BASE TABLE' as table_type
        , t.comment as table_comment
      from duckdb_tables() t
      WHERE t.database_name = 'dbt_mercurios_dev'
      UNION ALL
      SELECT v.view_name as table_name
      , v.database_name
      , v.schema_name
      , 'VIEW' as table_type
      , v.comment as table_comment
      from duckdb_views() v
      WHERE v.database_name = 'dbt_mercurios_dev'
    )
    select
        'dbt_mercurios_dev' as table_database,
        r.schema_name as table_schema,
        r.table_name,
        r.table_type,
        r.table_comment,
        c.column_name,
        c.column_index as column_index,
        c.data_type as column_type,
        c.comment as column_comment,
        '' as table_owner
    FROM relations r JOIN duckdb_columns() c ON r.schema_name = c.schema_name AND r.table_name = c.table_name
    WHERE (upper(r.schema_name) = upper('main_staging') or upper(r.schema_name) = upper('main_intermediate') or upper(r.schema_name) = upper('main_marts_inventory'))
    ORDER BY
        r.schema_name,
        r.table_name,
        c.column_index
[0m13:05:01.879069 [debug] [ThreadPool]: SQL status: OK in 0.001 seconds
[0m13:05:01.879267 [debug] [ThreadPool]: Using duckdb connection "MERCURIOS_DATA.information_schema"
[0m13:05:01.879487 [debug] [ThreadPool]: On MERCURIOS_DATA.information_schema: /* {"app": "dbt", "dbt_version": "1.9.2", "profile_name": "mercurios", "target_name": "dev", "connection_name": "MERCURIOS_DATA.information_schema"} */
with relations AS (
      select
        t.table_name
        , t.database_name
        , t.schema_name
        , 'BASE TABLE' as table_type
        , t.comment as table_comment
      from duckdb_tables() t
      WHERE t.database_name = 'dbt_mercurios_dev'
      UNION ALL
      SELECT v.view_name as table_name
      , v.database_name
      , v.schema_name
      , 'VIEW' as table_type
      , v.comment as table_comment
      from duckdb_views() v
      WHERE v.database_name = 'dbt_mercurios_dev'
    )
    select
        'dbt_mercurios_dev' as table_database,
        r.schema_name as table_schema,
        r.table_name,
        r.table_type,
        r.table_comment,
        c.column_name,
        c.column_index as column_index,
        c.data_type as column_type,
        c.comment as column_comment,
        '' as table_owner
    FROM relations r JOIN duckdb_columns() c ON r.schema_name = c.schema_name AND r.table_name = c.table_name
    WHERE (upper(r.schema_name) = upper('raw'))
    ORDER BY
        r.schema_name,
        r.table_name,
        c.column_index
[0m13:05:01.884391 [debug] [ThreadPool]: SQL status: OK in 0.005 seconds
[0m13:05:01.884704 [debug] [ThreadPool]: SQL status: OK in 0.005 seconds
[0m13:05:01.885899 [debug] [ThreadPool]: On dbt_mercurios_dev.information_schema: ROLLBACK
[0m13:05:01.887135 [debug] [ThreadPool]: On MERCURIOS_DATA.information_schema: ROLLBACK
[0m13:05:01.887542 [debug] [ThreadPool]: Failed to rollback 'dbt_mercurios_dev.information_schema'
[0m13:05:01.887812 [debug] [ThreadPool]: Failed to rollback 'MERCURIOS_DATA.information_schema'
[0m13:05:01.888080 [debug] [ThreadPool]: On dbt_mercurios_dev.information_schema: Close
[0m13:05:01.888255 [debug] [ThreadPool]: On MERCURIOS_DATA.information_schema: Close
[0m13:05:01.890627 [debug] [MainThread]: Wrote artifact CatalogArtifact to /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/target/catalog.json
[0m13:05:01.906981 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/target/manifest.json
[0m13:05:01.908165 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/target/semantic_manifest.json
[0m13:05:01.908345 [info ] [MainThread]: Catalog written to /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/target/catalog.json
[0m13:05:01.909261 [debug] [MainThread]: Resource report: {"command_name": "generate", "command_success": true, "command_wall_clock_time": 0.8167651, "process_in_blocks": "0", "process_kernel_time": 0.248849, "process_mem_max_rss": "157876224", "process_out_blocks": "0", "process_user_time": 1.269269}
[0m13:05:01.909480 [debug] [MainThread]: Command `dbt docs generate` succeeded at 13:05:01.909442 after 0.82 seconds
[0m13:05:01.909648 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m13:05:01.909783 [debug] [MainThread]: Connection 'dbt_mercurios_dev.information_schema' was properly closed.
[0m13:05:01.909909 [debug] [MainThread]: Connection 'MERCURIOS_DATA.information_schema' was properly closed.
[0m13:05:01.910070 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112dadf50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1046d6050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111d34710>]}
[0m13:05:01.910274 [debug] [MainThread]: Flushing usage events
[0m13:05:02.423980 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:05:03.534027 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10844e790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10844e2d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108462a10>]}


============================== 13:05:03.536575 | 614a7c50-5ea8-4bec-a878-04fd1d2c7f83 ==============================
[0m13:05:03.536575 [info ] [MainThread]: Running with dbt=1.9.2
[0m13:05:03.536912 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/juliusrechenbach/API ProHandelTest/dbt_mercurios', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt docs serve', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m13:05:03.666368 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '614a7c50-5ea8-4bec-a878-04fd1d2c7f83', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107e54690>]}
[0m13:05:03.701768 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '614a7c50-5ea8-4bec-a878-04fd1d2c7f83', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10150a910>]}
[0m14:16:58.206549 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105cda810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d6e510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d6ec90>]}


============================== 14:16:58.210001 | 83a87e44-4c75-4f77-9df4-424d2d351739 ==============================
[0m14:16:58.210001 [info ] [MainThread]: Running with dbt=1.9.2
[0m14:16:58.210363 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/juliusrechenbach/API ProHandelTest/dbt_mercurios', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt debug', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:16:58.220323 [info ] [MainThread]: dbt version: 1.9.2
[0m14:16:58.220634 [info ] [MainThread]: python version: 3.11.1
[0m14:16:58.220821 [info ] [MainThread]: python path: /Users/juliusrechenbach/API ProHandelTest/.venv/bin/python
[0m14:16:58.220979 [info ] [MainThread]: os info: macOS-15.3.1-arm64-arm-64bit
[0m14:16:59.144523 [info ] [MainThread]: Using profiles dir at /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios
[0m14:16:59.144889 [info ] [MainThread]: Using profiles.yml file at /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/profiles.yml
[0m14:16:59.145061 [info ] [MainThread]: Using dbt_project.yml file at /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/dbt_project.yml
[0m14:16:59.145485 [info ] [MainThread]: adapter type: snowflake
[0m14:16:59.145688 [info ] [MainThread]: adapter version: 1.9.1
[0m14:16:59.201282 [info ] [MainThread]: Configuration:
[0m14:16:59.201659 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m14:16:59.201972 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m14:16:59.202181 [info ] [MainThread]: Required dependencies:
[0m14:16:59.202385 [debug] [MainThread]: Executing "git --help"
[0m14:16:59.236013 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m14:16:59.236825 [debug] [MainThread]: STDERR: "b''"
[0m14:16:59.237083 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m14:16:59.237292 [info ] [MainThread]: Connection:
[0m14:16:59.237511 [info ] [MainThread]:   account: VRXDFZX-ZZ95717
[0m14:16:59.237661 [info ] [MainThread]:   user: JULIUSRECHENBACH
[0m14:16:59.237807 [info ] [MainThread]:   database: MERCURIOS_DATA
[0m14:16:59.237945 [info ] [MainThread]:   warehouse: MERCURIOS_DEV_WH
[0m14:16:59.238081 [info ] [MainThread]:   role: MERCURIOS_DEVELOPER
[0m14:16:59.238215 [info ] [MainThread]:   schema: staging
[0m14:16:59.238351 [info ] [MainThread]:   authenticator: None
[0m14:16:59.238487 [info ] [MainThread]:   oauth_client_id: None
[0m14:16:59.238623 [info ] [MainThread]:   query_tag: dbt_mercurios_dev
[0m14:16:59.238762 [info ] [MainThread]:   client_session_keep_alive: True
[0m14:16:59.238898 [info ] [MainThread]:   host: None
[0m14:16:59.239032 [info ] [MainThread]:   port: None
[0m14:16:59.239168 [info ] [MainThread]:   proxy_host: None
[0m14:16:59.239303 [info ] [MainThread]:   proxy_port: None
[0m14:16:59.239436 [info ] [MainThread]:   protocol: None
[0m14:16:59.239569 [info ] [MainThread]:   connect_retries: 3
[0m14:16:59.239698 [info ] [MainThread]:   connect_timeout: 30
[0m14:16:59.239827 [info ] [MainThread]:   retry_on_database_errors: True
[0m14:16:59.239960 [info ] [MainThread]:   retry_all: False
[0m14:16:59.240089 [info ] [MainThread]:   insecure_mode: False
[0m14:16:59.240220 [info ] [MainThread]:   reuse_connections: True
[0m14:16:59.240592 [info ] [MainThread]: Registered adapter: snowflake=1.9.1
[0m14:16:59.342283 [debug] [MainThread]: Acquiring new snowflake connection 'debug'
[0m14:16:59.376049 [debug] [MainThread]: Using snowflake connection "debug"
[0m14:16:59.376308 [debug] [MainThread]: On debug: select 1 as id
[0m14:16:59.376472 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:16:59.376737 [debug] [MainThread]: Snowflake adapter: Error running SQL: select 1 as id
[0m14:16:59.376889 [debug] [MainThread]: Snowflake adapter: Rolling back transaction.
[0m14:16:59.377079 [info ] [MainThread]:   Connection test: [[31mERROR[0m]

[0m14:16:59.377248 [info ] [MainThread]: [31m1 check failed:[0m
[0m14:16:59.377399 [info ] [MainThread]: dbt was unable to connect to the specified database.
The database returned the following error:

  >Database Error
  [Errno 2] No such file or directory: '~/.ssh/snowflake/rsa_key.p8'

Check your database credentials and try again. For more information, visit:
https://docs.getdbt.com/docs/configure-your-profile


[0m14:16:59.407067 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 1.2471428, "process_in_blocks": "0", "process_kernel_time": 0.668244, "process_mem_max_rss": "172081152", "process_out_blocks": "0", "process_user_time": 2.911079}
[0m14:16:59.407454 [debug] [MainThread]: Command `dbt debug` failed at 14:16:59.407392 after 1.25 seconds
[0m14:16:59.407714 [debug] [MainThread]: Connection 'debug' was left open.
[0m14:16:59.407882 [debug] [MainThread]: On debug: No close available on handle
[0m14:16:59.408091 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105a12810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105cfaa90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fd8d7d0>]}
[0m14:16:59.408346 [debug] [MainThread]: Flushing usage events
[0m14:16:59.997775 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:17:25.221337 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1105de490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1105de550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1104009d0>]}


============================== 14:17:25.224453 | d05cd817-82ed-4748-b3a6-4ec26b3cc99d ==============================
[0m14:17:25.224453 [info ] [MainThread]: Running with dbt=1.9.2
[0m14:17:25.224791 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/juliusrechenbach/API ProHandelTest/dbt_mercurios', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'invocation_command': 'dbt debug', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m14:17:25.232799 [info ] [MainThread]: dbt version: 1.9.2
[0m14:17:25.233075 [info ] [MainThread]: python version: 3.11.1
[0m14:17:25.233270 [info ] [MainThread]: python path: /Users/juliusrechenbach/API ProHandelTest/.venv/bin/python
[0m14:17:25.233481 [info ] [MainThread]: os info: macOS-15.3.1-arm64-arm-64bit
[0m14:17:25.761177 [info ] [MainThread]: Using profiles dir at /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios
[0m14:17:25.761567 [info ] [MainThread]: Using profiles.yml file at /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/profiles.yml
[0m14:17:25.761775 [info ] [MainThread]: Using dbt_project.yml file at /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/dbt_project.yml
[0m14:17:25.762306 [info ] [MainThread]: adapter type: snowflake
[0m14:17:25.762559 [info ] [MainThread]: adapter version: 1.9.1
[0m14:17:25.893295 [info ] [MainThread]: Configuration:
[0m14:17:25.893621 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m14:17:25.893779 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m14:17:25.893922 [info ] [MainThread]: Required dependencies:
[0m14:17:25.894101 [debug] [MainThread]: Executing "git --help"
[0m14:17:25.912201 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m14:17:25.913213 [debug] [MainThread]: STDERR: "b''"
[0m14:17:25.913528 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m14:17:25.913728 [info ] [MainThread]: Connection:
[0m14:17:25.913931 [info ] [MainThread]:   account: VRXDFZX-ZZ95717
[0m14:17:25.914078 [info ] [MainThread]:   user: JULIUSRECHENBACH
[0m14:17:25.914226 [info ] [MainThread]:   database: MERCURIOS_DATA
[0m14:17:25.914372 [info ] [MainThread]:   warehouse: MERCURIOS_DEV_WH
[0m14:17:25.914503 [info ] [MainThread]:   role: MERCURIOS_DEVELOPER
[0m14:17:25.914634 [info ] [MainThread]:   schema: staging
[0m14:17:25.914763 [info ] [MainThread]:   authenticator: None
[0m14:17:25.915028 [info ] [MainThread]:   oauth_client_id: None
[0m14:17:25.915225 [info ] [MainThread]:   query_tag: dbt_mercurios_dev
[0m14:17:25.915381 [info ] [MainThread]:   client_session_keep_alive: True
[0m14:17:25.915532 [info ] [MainThread]:   host: None
[0m14:17:25.915682 [info ] [MainThread]:   port: None
[0m14:17:25.915826 [info ] [MainThread]:   proxy_host: None
[0m14:17:25.915969 [info ] [MainThread]:   proxy_port: None
[0m14:17:25.916180 [info ] [MainThread]:   protocol: None
[0m14:17:25.916338 [info ] [MainThread]:   connect_retries: 3
[0m14:17:25.916479 [info ] [MainThread]:   connect_timeout: 30
[0m14:17:25.916617 [info ] [MainThread]:   retry_on_database_errors: True
[0m14:17:25.916756 [info ] [MainThread]:   retry_all: False
[0m14:17:25.916896 [info ] [MainThread]:   insecure_mode: False
[0m14:17:25.917033 [info ] [MainThread]:   reuse_connections: True
[0m14:17:25.917456 [info ] [MainThread]: Registered adapter: snowflake=1.9.1
[0m14:17:26.001786 [debug] [MainThread]: Acquiring new snowflake connection 'debug'
[0m14:17:26.027612 [debug] [MainThread]: Using snowflake connection "debug"
[0m14:17:26.027853 [debug] [MainThread]: On debug: select 1 as id
[0m14:17:26.028004 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:17:26.520183 [debug] [MainThread]: Snowflake adapter: Got a retryable error when attempting to open a snowflake connection.
3 attempts remaining. Retrying in 30 seconds.
Error:
250001 (08001): Failed to connect to DB: VRXDFZX-ZZ95717.snowflakecomputing.com:443. JWT token is invalid. [31001b34-9c17-4abe-8eb1-295e67e3fa81]
[0m14:17:56.844385 [debug] [MainThread]: Snowflake adapter: Got a retryable error when attempting to open a snowflake connection.
2 attempts remaining. Retrying in 30 seconds.
Error:
250001 (08001): Failed to connect to DB: VRXDFZX-ZZ95717.snowflakecomputing.com:443. JWT token is invalid. [ae3e1373-5a98-4844-a5ac-b5f15a92b53b]
[0m14:18:27.192099 [debug] [MainThread]: Snowflake adapter: Got a retryable error when attempting to open a snowflake connection.
1 attempts remaining. Retrying in 30 seconds.
Error:
250001 (08001): Failed to connect to DB: VRXDFZX-ZZ95717.snowflakecomputing.com:443. JWT token is invalid. [e2c05e9c-deeb-44ee-830f-42659f51d39d]
[0m14:18:57.560340 [debug] [MainThread]: Snowflake adapter: Error running SQL: select 1 as id
[0m14:18:57.560920 [debug] [MainThread]: Snowflake adapter: Rolling back transaction.
[0m14:18:57.561384 [info ] [MainThread]:   Connection test: [[31mERROR[0m]

[0m14:18:57.561618 [info ] [MainThread]: [31m1 check failed:[0m
[0m14:18:57.561786 [info ] [MainThread]: dbt was unable to connect to the specified database.
The database returned the following error:

  >Database Error
  250001 (08001): Failed to connect to DB: VRXDFZX-ZZ95717.snowflakecomputing.com:443. JWT token is invalid. [515405e6-43ba-44ea-9dbd-378dd4c76270]

Check your database credentials and try again. For more information, visit:
https://docs.getdbt.com/docs/configure-your-profile


[0m14:18:57.571445 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 92.39428, "process_in_blocks": "0", "process_kernel_time": 1.986993, "process_mem_max_rss": "181714944", "process_out_blocks": "0", "process_user_time": 2.221448}
[0m14:18:57.572735 [debug] [MainThread]: Command `dbt debug` failed at 14:18:57.572583 after 92.40 seconds
[0m14:18:57.573358 [debug] [MainThread]: Connection 'debug' was left open.
[0m14:18:57.573754 [debug] [MainThread]: On debug: No close available on handle
[0m14:18:57.574288 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110400610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103182050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10712a210>]}
[0m14:18:57.574700 [debug] [MainThread]: Flushing usage events
[0m14:18:58.142954 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:36:36.031939 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1120e8c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112150890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11216ef90>]}


============================== 14:36:36.035939 | fbde1441-8cbd-47bb-9c8f-d92b24091408 ==============================
[0m14:36:36.035939 [info ] [MainThread]: Running with dbt=1.9.2
[0m14:36:36.036399 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/logs', 'profiles_dir': '/Users/juliusrechenbach/API ProHandelTest/dbt_mercurios', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt debug', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m14:36:36.048134 [info ] [MainThread]: dbt version: 1.9.2
[0m14:36:36.048543 [info ] [MainThread]: python version: 3.11.1
[0m14:36:36.048822 [info ] [MainThread]: python path: /Users/juliusrechenbach/API ProHandelTest/.venv/bin/python
[0m14:36:36.048999 [info ] [MainThread]: os info: macOS-15.3.1-arm64-arm-64bit
[0m14:36:37.124750 [info ] [MainThread]: Using profiles dir at /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios
[0m14:36:37.125135 [info ] [MainThread]: Using profiles.yml file at /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/profiles.yml
[0m14:36:37.125306 [info ] [MainThread]: Using dbt_project.yml file at /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/dbt_project.yml
[0m14:36:37.125856 [info ] [MainThread]: adapter type: snowflake
[0m14:36:37.126162 [info ] [MainThread]: adapter version: 1.9.1
[0m14:36:37.185744 [info ] [MainThread]: Configuration:
[0m14:36:37.186109 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m14:36:37.186290 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m14:36:37.186445 [info ] [MainThread]: Required dependencies:
[0m14:36:37.186642 [debug] [MainThread]: Executing "git --help"
[0m14:36:37.206502 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m14:36:37.207204 [debug] [MainThread]: STDERR: "b''"
[0m14:36:37.207437 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m14:36:37.207642 [info ] [MainThread]: Connection:
[0m14:36:37.207866 [info ] [MainThread]:   account: VRXDFZX-ZZ95717
[0m14:36:37.208019 [info ] [MainThread]:   user: JULIUSRECHENBACH
[0m14:36:37.208165 [info ] [MainThread]:   database: MERCURIOS_DATA
[0m14:36:37.208307 [info ] [MainThread]:   warehouse: MERCURIOS_DEV_WH
[0m14:36:37.208444 [info ] [MainThread]:   role: MERCURIOS_DEVELOPER
[0m14:36:37.208581 [info ] [MainThread]:   schema: staging
[0m14:36:37.208720 [info ] [MainThread]:   authenticator: None
[0m14:36:37.208859 [info ] [MainThread]:   oauth_client_id: None
[0m14:36:37.208998 [info ] [MainThread]:   query_tag: dbt_mercurios_dev
[0m14:36:37.209380 [info ] [MainThread]:   client_session_keep_alive: True
[0m14:36:37.209604 [info ] [MainThread]:   host: None
[0m14:36:37.209854 [info ] [MainThread]:   port: None
[0m14:36:37.210003 [info ] [MainThread]:   proxy_host: None
[0m14:36:37.210153 [info ] [MainThread]:   proxy_port: None
[0m14:36:37.210293 [info ] [MainThread]:   protocol: None
[0m14:36:37.210435 [info ] [MainThread]:   connect_retries: 3
[0m14:36:37.210573 [info ] [MainThread]:   connect_timeout: 30
[0m14:36:37.210711 [info ] [MainThread]:   retry_on_database_errors: True
[0m14:36:37.210850 [info ] [MainThread]:   retry_all: False
[0m14:36:37.210983 [info ] [MainThread]:   insecure_mode: False
[0m14:36:37.211118 [info ] [MainThread]:   reuse_connections: True
[0m14:36:37.211510 [info ] [MainThread]: Registered adapter: snowflake=1.9.1
[0m14:36:37.323927 [debug] [MainThread]: Acquiring new snowflake connection 'debug'
[0m14:36:37.363126 [debug] [MainThread]: Using snowflake connection "debug"
[0m14:36:37.363406 [debug] [MainThread]: On debug: select 1 as id
[0m14:36:37.363603 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:36:37.861687 [debug] [MainThread]: Snowflake adapter: Got a retryable error when attempting to open a snowflake connection.
3 attempts remaining. Retrying in 30 seconds.
Error:
250001 (08001): Failed to connect to DB: VRXDFZX-ZZ95717.snowflakecomputing.com:443. JWT token is invalid. [447be7c5-7ec8-4568-9630-50190183f062]
[0m14:37:08.147956 [debug] [MainThread]: Snowflake adapter: Got a retryable error when attempting to open a snowflake connection.
2 attempts remaining. Retrying in 30 seconds.
Error:
250001 (08001): Failed to connect to DB: VRXDFZX-ZZ95717.snowflakecomputing.com:443. JWT token is invalid. [935c431f-9846-4153-abd4-faed2571517b]
[0m14:37:38.540024 [debug] [MainThread]: Snowflake adapter: Got a retryable error when attempting to open a snowflake connection.
1 attempts remaining. Retrying in 30 seconds.
Error:
250001 (08001): Failed to connect to DB: VRXDFZX-ZZ95717.snowflakecomputing.com:443. JWT token is invalid. [d44d9dab-21ea-4063-8398-0f31cdf5c030]
[0m14:38:08.848652 [debug] [MainThread]: Snowflake adapter: Error running SQL: select 1 as id
[0m14:38:08.849622 [debug] [MainThread]: Snowflake adapter: Rolling back transaction.
[0m14:38:08.850195 [info ] [MainThread]:   Connection test: [[31mERROR[0m]

[0m14:38:08.850437 [info ] [MainThread]: [31m1 check failed:[0m
[0m14:38:08.850607 [info ] [MainThread]: dbt was unable to connect to the specified database.
The database returned the following error:

  >Database Error
  250001 (08001): Failed to connect to DB: VRXDFZX-ZZ95717.snowflakecomputing.com:443. JWT token is invalid. [b21387cf-f987-460a-88b4-0e841c87cf8a]

Check your database credentials and try again. For more information, visit:
https://docs.getdbt.com/docs/configure-your-profile


[0m14:38:08.884122 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 92.90539, "process_in_blocks": "0", "process_kernel_time": 1.010322, "process_mem_max_rss": "179208192", "process_out_blocks": "0", "process_user_time": 3.214885}
[0m14:38:08.884648 [debug] [MainThread]: Command `dbt debug` failed at 14:38:08.884561 after 92.91 seconds
[0m14:38:08.884992 [debug] [MainThread]: Connection 'debug' was left open.
[0m14:38:08.885172 [debug] [MainThread]: On debug: No close available on handle
[0m14:38:08.885580 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10519e0d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10519d7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1314bd690>]}
[0m14:38:08.886014 [debug] [MainThread]: Flushing usage events
[0m14:38:09.401527 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:38:29.946098 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107bdfd90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107c6a090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107c6a790>]}


============================== 14:38:29.950636 | 13966f0b-b281-43b4-ae16-df7f12b64806 ==============================
[0m14:38:29.950636 [info ] [MainThread]: Running with dbt=1.9.2
[0m14:38:29.951066 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/logs', 'debug': 'False', 'profiles_dir': '/Users/juliusrechenbach/API ProHandelTest/dbt_mercurios', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt debug', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m14:38:29.963134 [info ] [MainThread]: dbt version: 1.9.2
[0m14:38:29.963495 [info ] [MainThread]: python version: 3.11.1
[0m14:38:29.963726 [info ] [MainThread]: python path: /Users/juliusrechenbach/API ProHandelTest/.venv/bin/python
[0m14:38:29.963908 [info ] [MainThread]: os info: macOS-15.3.1-arm64-arm-64bit
[0m14:38:31.113142 [info ] [MainThread]: Using profiles dir at /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios
[0m14:38:31.114317 [info ] [MainThread]: Using profiles.yml file at /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/profiles.yml
[0m14:38:31.114561 [info ] [MainThread]: Using dbt_project.yml file at /Users/juliusrechenbach/API ProHandelTest/dbt_mercurios/dbt_project.yml
[0m14:38:31.114989 [info ] [MainThread]: adapter type: snowflake
[0m14:38:31.115221 [info ] [MainThread]: adapter version: 1.9.1
[0m14:38:31.185106 [info ] [MainThread]: Configuration:
[0m14:38:31.185440 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m14:38:31.185611 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m14:38:31.185760 [info ] [MainThread]: Required dependencies:
[0m14:38:31.185963 [debug] [MainThread]: Executing "git --help"
[0m14:38:31.209556 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m14:38:31.210326 [debug] [MainThread]: STDERR: "b''"
[0m14:38:31.210566 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m14:38:31.210791 [info ] [MainThread]: Connection:
[0m14:38:31.210999 [info ] [MainThread]:   account: VRXDFZX-ZZ95717
[0m14:38:31.211159 [info ] [MainThread]:   user: JULIUSRECHENBACH
[0m14:38:31.211314 [info ] [MainThread]:   database: MERCURIOS_DATA
[0m14:38:31.211457 [info ] [MainThread]:   warehouse: MERCURIOS_DEV_WH
[0m14:38:31.211598 [info ] [MainThread]:   role: MERCURIOS_DEVELOPER
[0m14:38:31.211750 [info ] [MainThread]:   schema: staging
[0m14:38:31.211891 [info ] [MainThread]:   authenticator: None
[0m14:38:31.212032 [info ] [MainThread]:   oauth_client_id: None
[0m14:38:31.212173 [info ] [MainThread]:   query_tag: dbt_mercurios_dev
[0m14:38:31.212989 [info ] [MainThread]:   client_session_keep_alive: True
[0m14:38:31.213621 [info ] [MainThread]:   host: None
[0m14:38:31.214159 [info ] [MainThread]:   port: None
[0m14:38:31.214682 [info ] [MainThread]:   proxy_host: None
[0m14:38:31.215134 [info ] [MainThread]:   proxy_port: None
[0m14:38:31.215329 [info ] [MainThread]:   protocol: None
[0m14:38:31.215940 [info ] [MainThread]:   connect_retries: 3
[0m14:38:31.216315 [info ] [MainThread]:   connect_timeout: 30
[0m14:38:31.216776 [info ] [MainThread]:   retry_on_database_errors: True
[0m14:38:31.217376 [info ] [MainThread]:   retry_all: False
[0m14:38:31.217735 [info ] [MainThread]:   insecure_mode: False
[0m14:38:31.218424 [info ] [MainThread]:   reuse_connections: True
[0m14:38:31.218879 [info ] [MainThread]: Registered adapter: snowflake=1.9.1
[0m14:38:31.326725 [debug] [MainThread]: Acquiring new snowflake connection 'debug'
[0m14:38:31.356455 [debug] [MainThread]: Using snowflake connection "debug"
[0m14:38:31.356747 [debug] [MainThread]: On debug: select 1 as id
[0m14:38:31.356922 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:38:32.277535 [debug] [MainThread]: Snowflake adapter: Got a retryable error when attempting to open a snowflake connection.
3 attempts remaining. Retrying in 30 seconds.
Error:
250001 (08001): Failed to connect to DB: VRXDFZX-ZZ95717.snowflakecomputing.com:443. JWT token is invalid. [c96d042f-c464-4468-82c4-bd0ce15629ba]
[0m14:39:02.604553 [debug] [MainThread]: Snowflake adapter: Got a retryable error when attempting to open a snowflake connection.
2 attempts remaining. Retrying in 30 seconds.
Error:
250001 (08001): Failed to connect to DB: VRXDFZX-ZZ95717.snowflakecomputing.com:443. JWT token is invalid. [b0f40f21-ea06-4412-bbb0-2eb5b419e872]
[0m14:39:32.966353 [debug] [MainThread]: Snowflake adapter: Got a retryable error when attempting to open a snowflake connection.
1 attempts remaining. Retrying in 30 seconds.
Error:
250001 (08001): Failed to connect to DB: VRXDFZX-ZZ95717.snowflakecomputing.com:443. JWT token is invalid. [19c7e15f-e07c-4dda-9d0f-c333a4a06e06]
[0m14:40:03.264352 [debug] [MainThread]: Snowflake adapter: Error running SQL: select 1 as id
[0m14:40:03.264999 [debug] [MainThread]: Snowflake adapter: Rolling back transaction.
[0m14:40:03.265468 [info ] [MainThread]:   Connection test: [[31mERROR[0m]

[0m14:40:03.265702 [info ] [MainThread]: [31m1 check failed:[0m
[0m14:40:03.265867 [info ] [MainThread]: dbt was unable to connect to the specified database.
The database returned the following error:

  >Database Error
  250001 (08001): Failed to connect to DB: VRXDFZX-ZZ95717.snowflakecomputing.com:443. JWT token is invalid. [fdf5a59b-9894-48ec-9ff1-b9120f09dfad]

Check your database credentials and try again. For more information, visit:
https://docs.getdbt.com/docs/configure-your-profile


[0m14:40:03.268721 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 93.393265, "process_in_blocks": "0", "process_kernel_time": 0.64545, "process_mem_max_rss": "171393024", "process_out_blocks": "0", "process_user_time": 2.869089}
[0m14:40:03.269168 [debug] [MainThread]: Command `dbt debug` failed at 14:40:03.269080 after 93.39 seconds
[0m14:40:03.269549 [debug] [MainThread]: Connection 'debug' was left open.
[0m14:40:03.269735 [debug] [MainThread]: On debug: No close available on handle
[0m14:40:03.270072 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107c19a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107c50cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x115887c10>]}
[0m14:40:03.270431 [debug] [MainThread]: Flushing usage events
[0m14:40:03.830822 [debug] [MainThread]: An error was encountered while trying to flush usage events
